{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([[0, 0],\n",
    "           [0, 1],\n",
    "           [1, 0],\n",
    "           [1, 1]])\n",
    "y_train = np.array([[0],\n",
    "           [1],\n",
    "           [1],\n",
    "           [0]])\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        #x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        h_current = tf.math.sigmoid([tf.cast(h_i, dtype=tf.float32) for h_i in h])\n",
    "        h_current = [h_current[0]]\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "    \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "\n",
    "        h_current = tf.math.sigmoid(tf.split(h, self.hidden_layer_sizes, axis = 1))\n",
    "        h_current = [h_current[0]]\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def generate_hmc_kernel(self, x, y, step_size = pow(1000, -1/4)):\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = step_size),\n",
    "            num_adaptation_steps=int(100*0.8))\n",
    "        \n",
    "        return adaptive_hmc\n",
    "    \n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = h_current[0]\n",
    "\n",
    "        # initialize the HMC transition kernel\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = pow(1000, -1/4)),\n",
    "            num_adaptation_steps=int(100*0.8))\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_results = 1\n",
    "        num_burnin_steps = 100\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = adaptive_hmc,\n",
    "            trace_fn = None)\n",
    "\n",
    "        h_new = tf.split(samples[0], self.hidden_layer_sizes, axis = 1)\n",
    "\n",
    "        return(h_new)\n",
    "    \n",
    "    def update_weights(self, x, h, y, lr = 0.1):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "\n",
    "        logits = 0.0\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tf.math.sigmoid(logits)\n",
    "        \n",
    "        logits = self.output_layer(x)\n",
    "        probs = tf.math.sigmoid(logits)\n",
    "        #print(probs)\n",
    "        labels = tf.cast(tf.math.greater(probs, 0.5), tf.int32)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [2], n_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weight\n",
    "w_0 = np.array([[1, -1], [1, -1]], dtype = \"float32\")\n",
    "b_0 = np.array([-0.5, 1], dtype = \"float32\")\n",
    "l_0 = [w_0, b_0]\n",
    "\n",
    "w_1 = np.array([[1], [1]], dtype = \"float32\")\n",
    "b_1 = np.array([-1], dtype = \"float32\")\n",
    "l_1 = [w_1, b_1]\n",
    "\n",
    "model.fc_layers[0].set_weights(l_0)\n",
    "model.output_layer.set_weights(l_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(4, 2), dtype=int32, numpy=\n",
       "  array([[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 1],\n",
       "         [1, 0]], dtype=int32)>]]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [model.generate_hmc_kernel(images, labels) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17960621\n",
      "0.18140228\n",
      "0.1832163\n",
      "0.18504846\n",
      "0.18689895\n",
      "0.18876794\n",
      "0.19065562\n",
      "0.19256218\n",
      "0.1944878\n",
      "0.19643266\n",
      "0.198397\n",
      "0.20038097\n",
      "0.20238477\n",
      "0.20440862\n",
      "0.2064527\n",
      "0.20851722\n",
      "0.21060239\n",
      "0.21270841\n",
      "0.2148355\n",
      "0.21698385\n",
      "0.21915369\n",
      "0.22134522\n",
      "0.22355866\n",
      "0.22579426\n",
      "0.2280522\n",
      "0.23033272\n",
      "0.23263605\n",
      "0.2349624\n",
      "0.23731202\n",
      "0.23968513\n",
      "0.24208198\n",
      "0.2445028\n",
      "0.24694782\n",
      "0.2494173\n",
      "0.25191146\n",
      "0.25443056\n",
      "0.25697488\n",
      "0.2595446\n",
      "0.26214007\n",
      "0.26476148\n",
      "0.2674091\n",
      "0.2700832\n",
      "0.27278402\n",
      "0.27551186\n",
      "0.27826697\n",
      "0.28104964\n",
      "0.28386015\n",
      "0.28669876\n",
      "0.28956574\n",
      "0.2924614\n",
      "0.29538602\n",
      "0.29833987\n",
      "0.30132326\n",
      "0.3043365\n",
      "0.30737984\n",
      "0.31045362\n",
      "0.31355816\n",
      "0.31669375\n",
      "0.3198607\n",
      "0.3230593\n",
      "0.3262899\n",
      "0.3295528\n",
      "0.3328483\n",
      "0.33617678\n",
      "0.33953854\n",
      "0.34293392\n",
      "0.34636325\n",
      "0.34982687\n",
      "0.35332513\n",
      "0.35685837\n",
      "0.36042696\n",
      "0.36403123\n",
      "0.36767152\n",
      "0.37134823\n",
      "0.37506172\n",
      "0.37881234\n",
      "0.38260046\n",
      "0.38642645\n",
      "0.3902907\n",
      "0.39419362\n",
      "0.39813554\n",
      "0.4021169\n",
      "0.40613806\n",
      "0.41019943\n",
      "0.41430143\n",
      "0.41844442\n",
      "0.42262888\n",
      "0.42685518\n",
      "0.43112373\n",
      "0.43543497\n",
      "0.43978932\n",
      "0.44418722\n",
      "0.44862908\n",
      "0.45311537\n",
      "0.45764652\n",
      "0.462223\n",
      "0.4668452\n",
      "0.47151366\n",
      "0.4762288\n",
      "0.4809911\n"
     ]
    }
   ],
   "source": [
    "burnin = 100\n",
    "for i in range(burnin):\n",
    "    \n",
    "    network_new = []\n",
    "    kernels_new = []\n",
    "    \n",
    "    for (images, labels), net, hmc_kernel in zip(train_ds, network, kernels):\n",
    "        net_current = net\n",
    "        net_current = [tf.cast(net_i, dtype=tf.float32) for net_i in net_current]\n",
    "        net_current = net_current[0]\n",
    "        \n",
    "        num_results = 1\n",
    "        num_burnin_steps = 0\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = net_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            #trace_fn = lambda _, pkr: pkr.inner_results.accepted_results.new_step_size,\n",
    "            trace_fn = None,\n",
    "            return_final_kernel_results = True)\n",
    "        \n",
    "        #print(samples)\n",
    "        #print(\"__________________________________\")\n",
    "        print(samples[2][4].numpy())\n",
    "        new_step_size = samples[2][4].numpy()\n",
    "        net_new = tf.split(samples[0][0], [2], axis = 1)   \n",
    "        network_new.append(net_new)\n",
    "        \n",
    "        # build new kernel\n",
    "        ker_new = model.generate_hmc_kernel(images, labels, new_step_size)\n",
    "        kernels_new.append(ker_new)\n",
    "            \n",
    "    network = network_new\n",
    "    kernels = kernels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3995.9446\n",
      "Epoch 1/500: - 0.0845s/step - loss: 0.7127 - accuracy: 0.5000\n",
      "3956.3809\n",
      "Epoch 2/500: - 0.0630s/step - loss: 0.7127 - accuracy: 0.5000\n",
      "3917.2087\n",
      "Epoch 3/500: - 0.0559s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "3956.3809\n",
      "Epoch 4/500: - 0.0525s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "3917.2087\n",
      "Epoch 5/500: - 0.0520s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "3956.3809\n",
      "Epoch 6/500: - 0.0534s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "3995.9446\n",
      "Epoch 7/500: - 0.0521s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "4035.904\n",
      "Epoch 8/500: - 0.0506s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "4076.263\n",
      "Epoch 9/500: - 0.0495s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "4117.0254\n",
      "Epoch 10/500: - 0.0495s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "4158.196\n",
      "Epoch 11/500: - 0.0493s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "4199.778\n",
      "Epoch 12/500: - 0.0497s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "4241.7754\n",
      "Epoch 13/500: - 0.0491s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "4284.193\n",
      "Epoch 14/500: - 0.0484s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "4327.0347\n",
      "Epoch 15/500: - 0.0478s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "4370.305\n",
      "Epoch 16/500: - 0.0481s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "4414.0083\n",
      "Epoch 17/500: - 0.0482s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "4458.1484\n",
      "Epoch 18/500: - 0.0480s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "4502.73\n",
      "Epoch 19/500: - 0.0481s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "4547.7573\n",
      "Epoch 20/500: - 0.0482s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "4593.235\n",
      "Epoch 21/500: - 0.0489s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "4639.167\n",
      "Epoch 22/500: - 0.0489s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "4685.5586\n",
      "Epoch 23/500: - 0.0485s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "4732.414\n",
      "Epoch 24/500: - 0.0486s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "4779.7383\n",
      "Epoch 25/500: - 0.0497s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "4827.5356\n",
      "Epoch 26/500: - 0.0501s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "4779.7383\n",
      "Epoch 27/500: - 0.0502s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "4827.5356\n",
      "Epoch 28/500: - 0.0504s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "4875.811\n",
      "Epoch 29/500: - 0.0502s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "4924.5693\n",
      "Epoch 30/500: - 0.0500s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "4875.811\n",
      "Epoch 31/500: - 0.0497s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "4924.5693\n",
      "Epoch 32/500: - 0.0498s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "4973.815\n",
      "Epoch 33/500: - 0.0500s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "5023.553\n",
      "Epoch 34/500: - 0.0499s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "5073.7886\n",
      "Epoch 35/500: - 0.0497s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "5124.5264\n",
      "Epoch 36/500: - 0.0496s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "5073.7886\n",
      "Epoch 37/500: - 0.0501s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "5124.5264\n",
      "Epoch 38/500: - 0.0506s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "5175.7715\n",
      "Epoch 39/500: - 0.0511s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "5227.5293\n",
      "Epoch 40/500: - 0.0513s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "5175.7715\n",
      "Epoch 41/500: - 0.0519s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "5227.5293\n",
      "Epoch 42/500: - 0.0522s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "5279.8047\n",
      "Epoch 43/500: - 0.0524s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "5332.6025\n",
      "Epoch 44/500: - 0.0525s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "5385.9287\n",
      "Epoch 45/500: - 0.0527s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "5439.788\n",
      "Epoch 46/500: - 0.0525s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "5494.186\n",
      "Epoch 47/500: - 0.0522s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "5549.128\n",
      "Epoch 48/500: - 0.0521s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "5604.619\n",
      "Epoch 49/500: - 0.0519s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "5660.665\n",
      "Epoch 50/500: - 0.0519s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "5717.2715\n",
      "Epoch 51/500: - 0.0521s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "5774.4443\n",
      "Epoch 52/500: - 0.0523s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "5832.189\n",
      "Epoch 53/500: - 0.0522s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "5890.5107\n",
      "Epoch 54/500: - 0.0525s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "5949.416\n",
      "Epoch 55/500: - 0.0528s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "6008.91\n",
      "Epoch 56/500: - 0.0530s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "6068.999\n",
      "Epoch 57/500: - 0.0542s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "6129.689\n",
      "Epoch 58/500: - 0.0547s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "6190.986\n",
      "Epoch 59/500: - 0.0548s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "6252.8955\n",
      "Epoch 60/500: - 0.0548s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "6315.4243\n",
      "Epoch 61/500: - 0.0547s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "6378.5786\n",
      "Epoch 62/500: - 0.0548s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "6442.3643\n",
      "Epoch 63/500: - 0.0549s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "6506.7876\n",
      "Epoch 64/500: - 0.0549s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "6571.8555\n",
      "Epoch 65/500: - 0.0548s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "6637.5737\n",
      "Epoch 66/500: - 0.0546s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "6703.949\n",
      "Epoch 67/500: - 0.0544s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "6770.989\n",
      "Epoch 68/500: - 0.0542s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "6838.6987\n",
      "Epoch 69/500: - 0.0541s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "6907.0854\n",
      "Epoch 70/500: - 0.0540s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "6976.1562\n",
      "Epoch 71/500: - 0.0539s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "7045.918\n",
      "Epoch 72/500: - 0.0537s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "7116.377\n",
      "Epoch 73/500: - 0.0535s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "7187.5405\n",
      "Epoch 74/500: - 0.0534s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "7259.416\n",
      "Epoch 75/500: - 0.0534s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "7332.0103\n",
      "Epoch 76/500: - 0.0532s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "7405.33\n",
      "Epoch 77/500: - 0.0532s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "7479.3833\n",
      "Epoch 78/500: - 0.0533s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "7554.1772\n",
      "Epoch 79/500: - 0.0535s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "7629.7188\n",
      "Epoch 80/500: - 0.0534s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "7706.0156\n",
      "Epoch 81/500: - 0.0534s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "7783.0757\n",
      "Epoch 82/500: - 0.0535s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "7860.9062\n",
      "Epoch 83/500: - 0.0535s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "7939.515\n",
      "Epoch 84/500: - 0.0534s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "8018.91\n",
      "Epoch 85/500: - 0.0534s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "8099.099\n",
      "Epoch 86/500: - 0.0533s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "8180.09\n",
      "Epoch 87/500: - 0.0534s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "8261.891\n",
      "Epoch 88/500: - 0.0535s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "8344.51\n",
      "Epoch 89/500: - 0.0536s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "8427.955\n",
      "Epoch 90/500: - 0.0536s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "8512.234\n",
      "Epoch 91/500: - 0.0535s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "8597.356\n",
      "Epoch 92/500: - 0.0533s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "8683.33\n",
      "Epoch 93/500: - 0.0532s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "8770.163\n",
      "Epoch 94/500: - 0.0531s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "8857.864\n",
      "Epoch 95/500: - 0.0532s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "8946.442\n",
      "Epoch 96/500: - 0.0531s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "9035.906\n",
      "Epoch 97/500: - 0.0529s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "9126.266\n",
      "Epoch 98/500: - 0.0528s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "9217.528\n",
      "Epoch 99/500: - 0.0527s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "9309.703\n",
      "Epoch 100/500: - 0.0528s/step - loss: 1.9585 - accuracy: 0.5000\n",
      "9402.8\n",
      "Epoch 101/500: - 0.0529s/step - loss: 1.9385 - accuracy: 0.7500\n",
      "9496.828\n",
      "Epoch 102/500: - 0.0529s/step - loss: 1.9186 - accuracy: 0.5000\n",
      "9591.796\n",
      "Epoch 103/500: - 0.0529s/step - loss: 1.8988 - accuracy: 0.5000\n",
      "9687.714\n",
      "Epoch 104/500: - 0.0528s/step - loss: 1.8792 - accuracy: 0.5000\n",
      "9784.591\n",
      "Epoch 105/500: - 0.0528s/step - loss: 1.8598 - accuracy: 0.5000\n",
      "9882.437\n",
      "Epoch 106/500: - 0.0527s/step - loss: 1.8405 - accuracy: 0.5000\n",
      "9981.261\n",
      "Epoch 107/500: - 0.0527s/step - loss: 1.8214 - accuracy: 0.5000\n",
      "10081.073\n",
      "Epoch 108/500: - 0.0527s/step - loss: 1.8024 - accuracy: 0.5000\n",
      "10181.884\n",
      "Epoch 109/500: - 0.0528s/step - loss: 1.7835 - accuracy: 0.5000\n",
      "10283.702\n",
      "Epoch 110/500: - 0.0528s/step - loss: 0.7185 - accuracy: 0.5000\n",
      "10181.884\n",
      "Epoch 111/500: - 0.0528s/step - loss: 0.7181 - accuracy: 0.5000\n",
      "10283.702\n",
      "Epoch 112/500: - 0.0530s/step - loss: 0.7178 - accuracy: 0.5000\n",
      "10181.884\n",
      "Epoch 113/500: - 0.0532s/step - loss: 0.7175 - accuracy: 0.5000\n",
      "10081.073\n",
      "Epoch 114/500: - 0.0532s/step - loss: 0.7172 - accuracy: 0.5000\n",
      "10181.884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500: - 0.0533s/step - loss: 0.7170 - accuracy: 0.5000\n",
      "10283.702\n",
      "Epoch 116/500: - 0.0534s/step - loss: 0.7167 - accuracy: 0.5000\n",
      "10386.539\n",
      "Epoch 117/500: - 0.0534s/step - loss: 0.7165 - accuracy: 0.5000\n",
      "10490.404\n",
      "Epoch 118/500: - 0.0535s/step - loss: 0.7163 - accuracy: 0.5000\n",
      "10595.309\n",
      "Epoch 119/500: - 0.0536s/step - loss: 0.7162 - accuracy: 0.5000\n",
      "10701.262\n",
      "Epoch 120/500: - 0.0536s/step - loss: 0.7160 - accuracy: 0.5000\n",
      "10808.274\n",
      "Epoch 121/500: - 0.0537s/step - loss: 0.7158 - accuracy: 0.5000\n",
      "10916.357\n",
      "Epoch 122/500: - 0.0538s/step - loss: 0.7157 - accuracy: 0.5000\n",
      "11025.5205\n",
      "Epoch 123/500: - 0.0539s/step - loss: 0.7156 - accuracy: 0.5000\n",
      "11135.775\n",
      "Epoch 124/500: - 0.0539s/step - loss: 0.7155 - accuracy: 0.5000\n",
      "11247.133\n",
      "Epoch 125/500: - 0.0539s/step - loss: 0.7154 - accuracy: 0.5000\n",
      "11359.6045\n",
      "Epoch 126/500: - 0.0539s/step - loss: 0.7153 - accuracy: 0.5000\n",
      "11473.2\n",
      "Epoch 127/500: - 0.0540s/step - loss: 0.7152 - accuracy: 0.5000\n",
      "11587.932\n",
      "Epoch 128/500: - 0.0541s/step - loss: 0.7151 - accuracy: 0.5000\n",
      "11703.811\n",
      "Epoch 129/500: - 0.0541s/step - loss: 0.7150 - accuracy: 0.5000\n",
      "11820.849\n",
      "Epoch 130/500: - 0.0540s/step - loss: 0.7149 - accuracy: 0.5000\n",
      "11939.057\n",
      "Epoch 131/500: - 0.0540s/step - loss: 0.7148 - accuracy: 0.5000\n",
      "12058.447\n",
      "Epoch 132/500: - 0.0540s/step - loss: 0.7148 - accuracy: 0.5000\n",
      "12179.031\n",
      "Epoch 133/500: - 0.0540s/step - loss: 0.7147 - accuracy: 0.5000\n",
      "12300.821\n",
      "Epoch 134/500: - 0.0539s/step - loss: 0.7146 - accuracy: 0.5000\n",
      "12423.829\n",
      "Epoch 135/500: - 0.0539s/step - loss: 0.7146 - accuracy: 0.5000\n",
      "12548.067\n",
      "Epoch 136/500: - 0.0538s/step - loss: 0.7145 - accuracy: 0.5000\n",
      "12423.829\n",
      "Epoch 137/500: - 0.0538s/step - loss: 0.7145 - accuracy: 0.5000\n",
      "12548.067\n",
      "Epoch 138/500: - 0.0538s/step - loss: 0.7144 - accuracy: 0.5000\n",
      "12673.548\n",
      "Epoch 139/500: - 0.0537s/step - loss: 0.7144 - accuracy: 0.5000\n",
      "12800.283\n",
      "Epoch 140/500: - 0.0537s/step - loss: 0.7143 - accuracy: 0.5000\n",
      "12928.286\n",
      "Epoch 141/500: - 0.0538s/step - loss: 0.7143 - accuracy: 0.5000\n",
      "13057.569\n",
      "Epoch 142/500: - 0.0538s/step - loss: 0.7143 - accuracy: 0.5000\n",
      "13188.145\n",
      "Epoch 143/500: - 0.0538s/step - loss: 0.7142 - accuracy: 0.5000\n",
      "13320.025\n",
      "Epoch 144/500: - 0.0537s/step - loss: 0.7142 - accuracy: 0.7500\n",
      "13453.226\n",
      "Epoch 145/500: - 0.0537s/step - loss: 0.7141 - accuracy: 0.7500\n",
      "13587.758\n",
      "Epoch 146/500: - 0.0537s/step - loss: 0.7141 - accuracy: 0.7500\n",
      "13723.636\n",
      "Epoch 147/500: - 0.0537s/step - loss: 0.7141 - accuracy: 0.7500\n",
      "13860.872\n",
      "Epoch 148/500: - 0.0537s/step - loss: 0.7140 - accuracy: 0.7500\n",
      "13999.48\n",
      "Epoch 149/500: - 0.0537s/step - loss: 0.7140 - accuracy: 0.7500\n",
      "14139.476\n",
      "Epoch 150/500: - 0.0536s/step - loss: 0.7140 - accuracy: 0.7500\n",
      "14280.87\n",
      "Epoch 151/500: - 0.0536s/step - loss: 0.7139 - accuracy: 0.7500\n",
      "14423.679\n",
      "Epoch 152/500: - 0.0535s/step - loss: 0.7139 - accuracy: 0.7500\n",
      "14567.915\n",
      "Epoch 153/500: - 0.0536s/step - loss: 0.7139 - accuracy: 0.7500\n",
      "14713.594\n",
      "Epoch 154/500: - 0.0535s/step - loss: 0.7138 - accuracy: 0.2500\n",
      "14860.7295\n",
      "Epoch 155/500: - 0.0534s/step - loss: 0.7138 - accuracy: 0.2500\n",
      "15009.337\n",
      "Epoch 156/500: - 0.0534s/step - loss: 0.7138 - accuracy: 0.2500\n",
      "15159.43\n",
      "Epoch 157/500: - 0.0534s/step - loss: 0.7137 - accuracy: 0.2500\n",
      "15311.023\n",
      "Epoch 158/500: - 0.0536s/step - loss: 0.7137 - accuracy: 0.2500\n",
      "15464.134\n",
      "Epoch 159/500: - 0.0536s/step - loss: 0.7137 - accuracy: 0.2500\n",
      "15618.775\n",
      "Epoch 160/500: - 0.0537s/step - loss: 0.7137 - accuracy: 0.2500\n",
      "15774.963\n",
      "Epoch 161/500: - 0.0536s/step - loss: 0.7136 - accuracy: 0.2500\n",
      "15932.712\n",
      "Epoch 162/500: - 0.0536s/step - loss: 0.7136 - accuracy: 0.2500\n",
      "16092.039\n",
      "Epoch 163/500: - 0.0536s/step - loss: 0.7136 - accuracy: 0.5000\n",
      "16252.959\n",
      "Epoch 164/500: - 0.0535s/step - loss: 0.7135 - accuracy: 0.5000\n",
      "16415.488\n",
      "Epoch 165/500: - 0.0535s/step - loss: 0.7135 - accuracy: 0.5000\n",
      "16579.643\n",
      "Epoch 166/500: - 0.0535s/step - loss: 0.7135 - accuracy: 0.5000\n",
      "16745.44\n",
      "Epoch 167/500: - 0.0535s/step - loss: 0.7135 - accuracy: 0.5000\n",
      "16912.895\n",
      "Epoch 168/500: - 0.0535s/step - loss: 0.7134 - accuracy: 0.5000\n",
      "17082.023\n",
      "Epoch 169/500: - 0.0535s/step - loss: 0.7134 - accuracy: 0.5000\n",
      "17252.844\n",
      "Epoch 170/500: - 0.0535s/step - loss: 0.7134 - accuracy: 0.5000\n",
      "17425.371\n",
      "Epoch 171/500: - 0.0535s/step - loss: 0.7134 - accuracy: 0.5000\n",
      "17599.625\n",
      "Epoch 172/500: - 0.0535s/step - loss: 0.7133 - accuracy: 0.5000\n",
      "17775.621\n",
      "Epoch 173/500: - 0.0534s/step - loss: 0.7133 - accuracy: 0.5000\n",
      "17953.377\n",
      "Epoch 174/500: - 0.0534s/step - loss: 0.7133 - accuracy: 0.5000\n",
      "18132.91\n",
      "Epoch 175/500: - 0.0534s/step - loss: 0.7132 - accuracy: 0.5000\n",
      "18314.238\n",
      "Epoch 176/500: - 0.0534s/step - loss: 0.7132 - accuracy: 0.5000\n",
      "18497.38\n",
      "Epoch 177/500: - 0.0534s/step - loss: 0.7132 - accuracy: 0.5000\n",
      "18682.354\n",
      "Epoch 178/500: - 0.0533s/step - loss: 0.7132 - accuracy: 0.5000\n",
      "18869.178\n",
      "Epoch 179/500: - 0.0534s/step - loss: 0.7131 - accuracy: 0.5000\n",
      "19057.87\n",
      "Epoch 180/500: - 0.0534s/step - loss: 0.7131 - accuracy: 0.5000\n",
      "19248.447\n",
      "Epoch 181/500: - 0.0533s/step - loss: 0.7131 - accuracy: 0.5000\n",
      "19440.932\n",
      "Epoch 182/500: - 0.0532s/step - loss: 0.7131 - accuracy: 0.5000\n",
      "19635.34\n",
      "Epoch 183/500: - 0.0533s/step - loss: 0.7130 - accuracy: 0.5000\n",
      "19831.693\n",
      "Epoch 184/500: - 0.0532s/step - loss: 0.7130 - accuracy: 0.5000\n",
      "20030.01\n",
      "Epoch 185/500: - 0.0533s/step - loss: 0.7130 - accuracy: 0.5000\n",
      "20230.31\n",
      "Epoch 186/500: - 0.0533s/step - loss: 0.7130 - accuracy: 0.5000\n",
      "20432.613\n",
      "Epoch 187/500: - 0.0534s/step - loss: 0.7129 - accuracy: 0.5000\n",
      "20636.94\n",
      "Epoch 188/500: - 0.0534s/step - loss: 0.7129 - accuracy: 0.5000\n",
      "20843.309\n",
      "Epoch 189/500: - 0.0533s/step - loss: 0.7129 - accuracy: 0.5000\n",
      "21051.742\n",
      "Epoch 190/500: - 0.0533s/step - loss: 0.7129 - accuracy: 0.5000\n",
      "21262.26\n",
      "Epoch 191/500: - 0.0532s/step - loss: 0.7128 - accuracy: 0.5000\n",
      "21474.883\n",
      "Epoch 192/500: - 0.0532s/step - loss: 0.7128 - accuracy: 0.5000\n",
      "21689.63\n",
      "Epoch 193/500: - 0.0533s/step - loss: 0.7128 - accuracy: 0.5000\n",
      "21906.527\n",
      "Epoch 194/500: - 0.0532s/step - loss: 0.7128 - accuracy: 0.5000\n",
      "22125.592\n",
      "Epoch 195/500: - 0.0531s/step - loss: 0.7127 - accuracy: 0.5000\n",
      "22346.848\n",
      "Epoch 196/500: - 0.0531s/step - loss: 0.7127 - accuracy: 0.5000\n",
      "22570.316\n",
      "Epoch 197/500: - 0.0530s/step - loss: 0.7127 - accuracy: 0.5000\n",
      "22796.02\n",
      "Epoch 198/500: - 0.0530s/step - loss: 0.7127 - accuracy: 0.5000\n",
      "23023.98\n",
      "Epoch 199/500: - 0.0529s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "23254.22\n",
      "Epoch 200/500: - 0.0530s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "23486.762\n",
      "Epoch 201/500: - 0.0530s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "23721.629\n",
      "Epoch 202/500: - 0.0530s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "23958.846\n",
      "Epoch 203/500: - 0.0530s/step - loss: 0.7126 - accuracy: 0.5000\n",
      "24198.434\n",
      "Epoch 204/500: - 0.0529s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "24440.418\n",
      "Epoch 205/500: - 0.0528s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "24684.822\n",
      "Epoch 206/500: - 0.0528s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "24931.67\n",
      "Epoch 207/500: - 0.0528s/step - loss: 0.7125 - accuracy: 0.5000\n",
      "25180.986\n",
      "Epoch 208/500: - 0.0528s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "25432.797\n",
      "Epoch 209/500: - 0.0527s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "25687.125\n",
      "Epoch 210/500: - 0.0527s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "25943.996\n",
      "Epoch 211/500: - 0.0528s/step - loss: 0.7124 - accuracy: 0.5000\n",
      "26203.436\n",
      "Epoch 212/500: - 0.0527s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "26465.469\n",
      "Epoch 213/500: - 0.0527s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "26730.123\n",
      "Epoch 214/500: - 0.0527s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "26997.424\n",
      "Epoch 215/500: - 0.0527s/step - loss: 0.7123 - accuracy: 0.5000\n",
      "27267.398\n",
      "Epoch 216/500: - 0.0527s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "27540.072\n",
      "Epoch 217/500: - 0.0527s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "27815.473\n",
      "Epoch 218/500: - 0.0527s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "28093.627\n",
      "Epoch 219/500: - 0.0527s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "27815.473\n",
      "Epoch 220/500: - 0.0526s/step - loss: 0.7122 - accuracy: 0.5000\n",
      "28093.627\n",
      "Epoch 221/500: - 0.0527s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "28374.562\n",
      "Epoch 222/500: - 0.0526s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "28658.309\n",
      "Epoch 223/500: - 0.0525s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "28944.89\n",
      "Epoch 224/500: - 0.0525s/step - loss: 0.7121 - accuracy: 0.5000\n",
      "29234.34\n",
      "Epoch 225/500: - 0.0524s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "29526.684\n",
      "Epoch 226/500: - 0.0524s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "29821.95\n",
      "Epoch 227/500: - 0.0525s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "30120.168\n",
      "Epoch 228/500: - 0.0525s/step - loss: 0.7120 - accuracy: 0.5000\n",
      "30421.37\n",
      "Epoch 229/500: - 0.0525s/step - loss: 0.7120 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30725.582\n",
      "Epoch 230/500: - 0.0526s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "31032.838\n",
      "Epoch 231/500: - 0.0526s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "31343.166\n",
      "Epoch 232/500: - 0.0525s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "31656.598\n",
      "Epoch 233/500: - 0.0525s/step - loss: 0.7119 - accuracy: 0.5000\n",
      "31973.164\n",
      "Epoch 234/500: - 0.0524s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "32292.895\n",
      "Epoch 235/500: - 0.0524s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "32615.822\n",
      "Epoch 236/500: - 0.0524s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "32941.98\n",
      "Epoch 237/500: - 0.0523s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "33271.4\n",
      "Epoch 238/500: - 0.0523s/step - loss: 0.7118 - accuracy: 0.5000\n",
      "33604.113\n",
      "Epoch 239/500: - 0.0523s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "33940.152\n",
      "Epoch 240/500: - 0.0522s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "34279.555\n",
      "Epoch 241/500: - 0.0522s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "34622.35\n",
      "Epoch 242/500: - 0.0522s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "34968.574\n",
      "Epoch 243/500: - 0.0521s/step - loss: 0.7117 - accuracy: 0.5000\n",
      "35318.258\n",
      "Epoch 244/500: - 0.0521s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "35671.44\n",
      "Epoch 245/500: - 0.0521s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "36028.156\n",
      "Epoch 246/500: - 0.0521s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "36388.438\n",
      "Epoch 247/500: - 0.0521s/step - loss: 0.7116 - accuracy: 0.5000\n",
      "36752.32\n",
      "Epoch 248/500: - 0.0522s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "36388.438\n",
      "Epoch 249/500: - 0.0523s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "36752.32\n",
      "Epoch 250/500: - 0.0524s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "37119.844\n",
      "Epoch 251/500: - 0.0525s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "37491.043\n",
      "Epoch 252/500: - 0.0526s/step - loss: 0.7115 - accuracy: 0.5000\n",
      "37865.953\n",
      "Epoch 253/500: - 0.0525s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "38244.613\n",
      "Epoch 254/500: - 0.0525s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "38627.06\n",
      "Epoch 255/500: - 0.0524s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "39013.33\n",
      "Epoch 256/500: - 0.0524s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "39403.46\n",
      "Epoch 257/500: - 0.0524s/step - loss: 0.7114 - accuracy: 0.5000\n",
      "39797.496\n",
      "Epoch 258/500: - 0.0524s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "40195.47\n",
      "Epoch 259/500: - 0.0524s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "40597.42\n",
      "Epoch 260/500: - 0.0524s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "41003.395\n",
      "Epoch 261/500: - 0.0523s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "41413.43\n",
      "Epoch 262/500: - 0.0524s/step - loss: 0.7113 - accuracy: 0.5000\n",
      "41827.562\n",
      "Epoch 263/500: - 0.0523s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "42245.836\n",
      "Epoch 264/500: - 0.0523s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "42668.293\n",
      "Epoch 265/500: - 0.0523s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "43094.977\n",
      "Epoch 266/500: - 0.0523s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "43525.926\n",
      "Epoch 267/500: - 0.0523s/step - loss: 0.7112 - accuracy: 0.5000\n",
      "43961.184\n",
      "Epoch 268/500: - 0.0523s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "44400.797\n",
      "Epoch 269/500: - 0.0522s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "44844.805\n",
      "Epoch 270/500: - 0.0522s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "45293.254\n",
      "Epoch 271/500: - 0.0523s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "45746.188\n",
      "Epoch 272/500: - 0.0522s/step - loss: 0.7111 - accuracy: 0.5000\n",
      "46203.65\n",
      "Epoch 273/500: - 0.0522s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "46665.684\n",
      "Epoch 274/500: - 0.0521s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "47132.34\n",
      "Epoch 275/500: - 0.0521s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "47603.664\n",
      "Epoch 276/500: - 0.0521s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "48079.7\n",
      "Epoch 277/500: - 0.0521s/step - loss: 0.7110 - accuracy: 0.5000\n",
      "48560.496\n",
      "Epoch 278/500: - 0.0520s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "49046.1\n",
      "Epoch 279/500: - 0.0520s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "49536.562\n",
      "Epoch 280/500: - 0.0520s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "50031.926\n",
      "Epoch 281/500: - 0.0520s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "50532.246\n",
      "Epoch 282/500: - 0.0520s/step - loss: 0.7109 - accuracy: 0.5000\n",
      "51037.566\n",
      "Epoch 283/500: - 0.0521s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "51547.94\n",
      "Epoch 284/500: - 0.0521s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "52063.42\n",
      "Epoch 285/500: - 0.0521s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "52584.055\n",
      "Epoch 286/500: - 0.0522s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "53109.895\n",
      "Epoch 287/500: - 0.0521s/step - loss: 0.7108 - accuracy: 0.5000\n",
      "53640.992\n",
      "Epoch 288/500: - 0.0521s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "54177.402\n",
      "Epoch 289/500: - 0.0521s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "54719.176\n",
      "Epoch 290/500: - 0.0521s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "55266.367\n",
      "Epoch 291/500: - 0.0521s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "55819.03\n",
      "Epoch 292/500: - 0.0520s/step - loss: 0.7107 - accuracy: 0.5000\n",
      "56377.223\n",
      "Epoch 293/500: - 0.0520s/step - loss: 0.7106 - accuracy: 0.5000\n",
      "56940.996\n",
      "Epoch 294/500: - 0.0520s/step - loss: 0.7106 - accuracy: 0.5000\n",
      "57510.406\n",
      "Epoch 295/500: - 0.0520s/step - loss: 0.7106 - accuracy: 0.5000\n",
      "58085.508\n",
      "Epoch 296/500: - 0.0520s/step - loss: 0.7106 - accuracy: 0.5000\n",
      "57510.406\n",
      "Epoch 297/500: - 0.0520s/step - loss: 0.7106 - accuracy: 0.5000\n",
      "56940.996\n",
      "Epoch 298/500: - 0.0520s/step - loss: 0.7106 - accuracy: 0.5000\n",
      "57510.406\n",
      "Epoch 299/500: - 0.0520s/step - loss: 0.7105 - accuracy: 0.5000\n",
      "58085.508\n",
      "Epoch 300/500: - 0.0520s/step - loss: 0.7105 - accuracy: 0.5000\n",
      "57510.406\n",
      "Epoch 301/500: - 0.0519s/step - loss: 0.7105 - accuracy: 0.5000\n",
      "58085.508\n",
      "Epoch 302/500: - 0.0519s/step - loss: 0.7105 - accuracy: 0.5000\n",
      "57510.406\n",
      "Epoch 303/500: - 0.0519s/step - loss: 0.7105 - accuracy: 0.5000\n",
      "58085.508\n",
      "Epoch 304/500: - 0.0519s/step - loss: 0.7104 - accuracy: 0.5000\n",
      "58666.363\n",
      "Epoch 305/500: - 0.0519s/step - loss: 0.7104 - accuracy: 0.5000\n",
      "59253.027\n",
      "Epoch 306/500: - 0.0519s/step - loss: 0.7104 - accuracy: 0.5000\n",
      "59845.56\n",
      "Epoch 307/500: - 0.0519s/step - loss: 0.7104 - accuracy: 0.5000\n",
      "60444.01\n",
      "Epoch 308/500: - 0.0520s/step - loss: 0.7104 - accuracy: 0.5000\n",
      "61048.453\n",
      "Epoch 309/500: - 0.0520s/step - loss: 0.7103 - accuracy: 0.5000\n",
      "61658.938\n",
      "Epoch 310/500: - 0.0520s/step - loss: 0.7103 - accuracy: 0.5000\n",
      "62275.527\n",
      "Epoch 311/500: - 0.0521s/step - loss: 0.7103 - accuracy: 0.5000\n",
      "62898.28\n",
      "Epoch 312/500: - 0.0521s/step - loss: 0.7103 - accuracy: 0.5000\n",
      "63527.26\n",
      "Epoch 313/500: - 0.0521s/step - loss: 0.7103 - accuracy: 0.5000\n",
      "64162.535\n",
      "Epoch 314/500: - 0.0521s/step - loss: 0.7103 - accuracy: 0.5000\n",
      "64804.16\n",
      "Epoch 315/500: - 0.0521s/step - loss: 0.7102 - accuracy: 0.5000\n",
      "65452.2\n",
      "Epoch 316/500: - 0.0521s/step - loss: 0.7102 - accuracy: 0.5000\n",
      "66106.72\n",
      "Epoch 317/500: - 0.0522s/step - loss: 0.7102 - accuracy: 0.5000\n",
      "66767.79\n",
      "Epoch 318/500: - 0.0522s/step - loss: 0.7102 - accuracy: 0.5000\n",
      "67435.47\n",
      "Epoch 319/500: - 0.0522s/step - loss: 0.7102 - accuracy: 0.5000\n",
      "68109.82\n",
      "Epoch 320/500: - 0.0523s/step - loss: 0.7101 - accuracy: 0.5000\n",
      "68790.914\n",
      "Epoch 321/500: - 0.0523s/step - loss: 0.7101 - accuracy: 0.5000\n",
      "69478.82\n",
      "Epoch 322/500: - 0.0523s/step - loss: 0.7101 - accuracy: 0.5000\n",
      "70173.61\n",
      "Epoch 323/500: - 0.0524s/step - loss: 0.7101 - accuracy: 0.5000\n",
      "70875.34\n",
      "Epoch 324/500: - 0.0524s/step - loss: 0.7101 - accuracy: 0.5000\n",
      "71584.09\n",
      "Epoch 325/500: - 0.0525s/step - loss: 0.7101 - accuracy: 0.5000\n",
      "72299.94\n",
      "Epoch 326/500: - 0.0525s/step - loss: 0.7100 - accuracy: 0.5000\n",
      "73022.94\n",
      "Epoch 327/500: - 0.0526s/step - loss: 0.7100 - accuracy: 0.5000\n",
      "72299.94\n",
      "Epoch 328/500: - 0.0526s/step - loss: 0.7100 - accuracy: 0.5000\n",
      "73022.94\n",
      "Epoch 329/500: - 0.0526s/step - loss: 0.7100 - accuracy: 0.5000\n",
      "73753.164\n",
      "Epoch 330/500: - 0.0527s/step - loss: 0.7100 - accuracy: 0.5000\n",
      "74490.695\n",
      "Epoch 331/500: - 0.0528s/step - loss: 0.7100 - accuracy: 0.5000\n",
      "75235.6\n",
      "Epoch 332/500: - 0.0528s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "75987.95\n",
      "Epoch 333/500: - 0.0529s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "76747.83\n",
      "Epoch 334/500: - 0.0529s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "77515.305\n",
      "Epoch 335/500: - 0.0530s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "78290.45\n",
      "Epoch 336/500: - 0.0530s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "79073.36\n",
      "Epoch 337/500: - 0.0531s/step - loss: 0.7099 - accuracy: 0.5000\n",
      "79864.09\n",
      "Epoch 338/500: - 0.0531s/step - loss: 0.7098 - accuracy: 0.5000\n",
      "80662.734\n",
      "Epoch 339/500: - 0.0531s/step - loss: 0.7098 - accuracy: 0.5000\n",
      "81469.36\n",
      "Epoch 340/500: - 0.0531s/step - loss: 0.7098 - accuracy: 0.5000\n",
      "82284.055\n",
      "Epoch 341/500: - 0.0531s/step - loss: 0.7098 - accuracy: 0.5000\n",
      "83106.89\n",
      "Epoch 342/500: - 0.0531s/step - loss: 0.7098 - accuracy: 0.5000\n",
      "83937.96\n",
      "Epoch 343/500: - 0.0530s/step - loss: 0.7097 - accuracy: 0.5000\n",
      "84777.336\n",
      "Epoch 344/500: - 0.0530s/step - loss: 0.7097 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85625.11\n",
      "Epoch 345/500: - 0.0530s/step - loss: 0.7097 - accuracy: 0.5000\n",
      "86481.36\n",
      "Epoch 346/500: - 0.0530s/step - loss: 0.7097 - accuracy: 0.5000\n",
      "87346.17\n",
      "Epoch 347/500: - 0.0530s/step - loss: 0.7097 - accuracy: 0.5000\n",
      "88219.63\n",
      "Epoch 348/500: - 0.0530s/step - loss: 0.7097 - accuracy: 0.5000\n",
      "89101.83\n",
      "Epoch 349/500: - 0.0530s/step - loss: 0.7096 - accuracy: 0.5000\n",
      "89992.84\n",
      "Epoch 350/500: - 0.0531s/step - loss: 0.7096 - accuracy: 0.5000\n",
      "90892.77\n",
      "Epoch 351/500: - 0.0531s/step - loss: 0.7096 - accuracy: 0.5000\n",
      "91801.7\n",
      "Epoch 352/500: - 0.0532s/step - loss: 0.7096 - accuracy: 0.5000\n",
      "92719.72\n",
      "Epoch 353/500: - 0.0532s/step - loss: 0.7096 - accuracy: 0.5000\n",
      "93646.914\n",
      "Epoch 354/500: - 0.0532s/step - loss: 0.7096 - accuracy: 0.5000\n",
      "94583.38\n",
      "Epoch 355/500: - 0.0532s/step - loss: 0.7095 - accuracy: 0.5000\n",
      "95529.22\n",
      "Epoch 356/500: - 0.0533s/step - loss: 0.7095 - accuracy: 0.5000\n",
      "96484.51\n",
      "Epoch 357/500: - 0.0533s/step - loss: 0.7095 - accuracy: 0.5000\n",
      "97449.35\n",
      "Epoch 358/500: - 0.0534s/step - loss: 0.7095 - accuracy: 0.5000\n",
      "98423.84\n",
      "Epoch 359/500: - 0.0535s/step - loss: 0.7095 - accuracy: 0.5000\n",
      "99408.08\n",
      "Epoch 360/500: - 0.0536s/step - loss: 0.7095 - accuracy: 0.5000\n",
      "100402.16\n",
      "Epoch 361/500: - 0.0536s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "101406.18\n",
      "Epoch 362/500: - 0.0537s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "102420.24\n",
      "Epoch 363/500: - 0.0537s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "103444.445\n",
      "Epoch 364/500: - 0.0537s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "104478.89\n",
      "Epoch 365/500: - 0.0537s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "105523.68\n",
      "Epoch 366/500: - 0.0537s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "106578.914\n",
      "Epoch 367/500: - 0.0538s/step - loss: 0.7094 - accuracy: 0.5000\n",
      "107644.7\n",
      "Epoch 368/500: - 0.0538s/step - loss: 0.7093 - accuracy: 0.5000\n",
      "108721.15\n",
      "Epoch 369/500: - 0.0538s/step - loss: 0.7093 - accuracy: 0.5000\n",
      "109808.36\n",
      "Epoch 370/500: - 0.0539s/step - loss: 0.7093 - accuracy: 0.5000\n",
      "110906.445\n",
      "Epoch 371/500: - 0.0539s/step - loss: 0.7093 - accuracy: 0.5000\n",
      "112015.51\n",
      "Epoch 372/500: - 0.0540s/step - loss: 0.7093 - accuracy: 0.5000\n",
      "113135.664\n",
      "Epoch 373/500: - 0.0541s/step - loss: 0.7093 - accuracy: 0.5000\n",
      "114267.02\n",
      "Epoch 374/500: - 0.0541s/step - loss: 0.7092 - accuracy: 0.5000\n",
      "115409.695\n",
      "Epoch 375/500: - 0.0541s/step - loss: 0.7092 - accuracy: 0.5000\n",
      "116563.79\n",
      "Epoch 376/500: - 0.0541s/step - loss: 0.7092 - accuracy: 0.5000\n",
      "117729.43\n",
      "Epoch 377/500: - 0.0541s/step - loss: 0.7092 - accuracy: 0.5000\n",
      "118906.73\n",
      "Epoch 378/500: - 0.0543s/step - loss: 0.7092 - accuracy: 0.5000\n",
      "120095.79\n",
      "Epoch 379/500: - 0.0544s/step - loss: 0.7092 - accuracy: 0.5000\n",
      "121296.74\n",
      "Epoch 380/500: - 0.0544s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "122509.71\n",
      "Epoch 381/500: - 0.0544s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "123734.805\n",
      "Epoch 382/500: - 0.0544s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "124972.15\n",
      "Epoch 383/500: - 0.0543s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "126221.87\n",
      "Epoch 384/500: - 0.0543s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "127484.086\n",
      "Epoch 385/500: - 0.0544s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "128758.92\n",
      "Epoch 386/500: - 0.0544s/step - loss: 0.7091 - accuracy: 0.5000\n",
      "130046.51\n",
      "Epoch 387/500: - 0.0544s/step - loss: 0.7090 - accuracy: 0.5000\n",
      "131346.97\n",
      "Epoch 388/500: - 0.0545s/step - loss: 0.7090 - accuracy: 0.5000\n",
      "132660.44\n",
      "Epoch 389/500: - 0.0545s/step - loss: 0.7090 - accuracy: 0.5000\n",
      "133987.05\n",
      "Epoch 390/500: - 0.0545s/step - loss: 0.7090 - accuracy: 0.5000\n",
      "135326.92\n",
      "Epoch 391/500: - 0.0546s/step - loss: 0.7090 - accuracy: 0.5000\n",
      "136680.19\n",
      "Epoch 392/500: - 0.0548s/step - loss: 0.7090 - accuracy: 0.5000\n",
      "138046.98\n",
      "Epoch 393/500: - 0.0548s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "139427.45\n",
      "Epoch 394/500: - 0.0548s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "140821.72\n",
      "Epoch 395/500: - 0.0548s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "142229.94\n",
      "Epoch 396/500: - 0.0547s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "143652.23\n",
      "Epoch 397/500: - 0.0547s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "145088.75\n",
      "Epoch 398/500: - 0.0548s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "146539.64\n",
      "Epoch 399/500: - 0.0548s/step - loss: 0.7089 - accuracy: 0.5000\n",
      "148005.03\n",
      "Epoch 400/500: - 0.0548s/step - loss: 0.7088 - accuracy: 0.5000\n",
      "146539.64\n",
      "Epoch 401/500: - 0.0547s/step - loss: 0.7088 - accuracy: 0.5000\n",
      "145088.75\n",
      "Epoch 402/500: - 0.0547s/step - loss: 0.7088 - accuracy: 0.5000\n",
      "146539.64\n",
      "Epoch 403/500: - 0.0548s/step - loss: 0.7088 - accuracy: 0.5000\n",
      "148005.03\n",
      "Epoch 404/500: - 0.0548s/step - loss: 0.7088 - accuracy: 0.5000\n",
      "149485.08\n",
      "Epoch 405/500: - 0.0548s/step - loss: 0.7088 - accuracy: 0.5000\n",
      "150979.92\n",
      "Epoch 406/500: - 0.0549s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "152489.72\n",
      "Epoch 407/500: - 0.0549s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "154014.61\n",
      "Epoch 408/500: - 0.0548s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "155554.75\n",
      "Epoch 409/500: - 0.0548s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "157110.3\n",
      "Epoch 410/500: - 0.0548s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "158681.39\n",
      "Epoch 411/500: - 0.0548s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "160268.2\n",
      "Epoch 412/500: - 0.0548s/step - loss: 0.7087 - accuracy: 0.5000\n",
      "161870.89\n",
      "Epoch 413/500: - 0.0548s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "163489.6\n",
      "Epoch 414/500: - 0.0549s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "165124.48\n",
      "Epoch 415/500: - 0.0549s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "166775.73\n",
      "Epoch 416/500: - 0.0548s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "168443.48\n",
      "Epoch 417/500: - 0.0548s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "170127.92\n",
      "Epoch 418/500: - 0.0549s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "171829.2\n",
      "Epoch 419/500: - 0.0549s/step - loss: 0.7086 - accuracy: 0.5000\n",
      "173547.5\n",
      "Epoch 420/500: - 0.0549s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "175282.97\n",
      "Epoch 421/500: - 0.0549s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "177035.8\n",
      "Epoch 422/500: - 0.0549s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "178806.16\n",
      "Epoch 423/500: - 0.0549s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "180594.22\n",
      "Epoch 424/500: - 0.0548s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "182400.16\n",
      "Epoch 425/500: - 0.0548s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "184224.16\n",
      "Epoch 426/500: - 0.0548s/step - loss: 0.7085 - accuracy: 0.5000\n",
      "186066.39\n",
      "Epoch 427/500: - 0.0548s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "187927.05\n",
      "Epoch 428/500: - 0.0548s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "189806.31\n",
      "Epoch 429/500: - 0.0547s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "191704.38\n",
      "Epoch 430/500: - 0.0547s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "193621.42\n",
      "Epoch 431/500: - 0.0547s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "195557.64\n",
      "Epoch 432/500: - 0.0547s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "197513.22\n",
      "Epoch 433/500: - 0.0547s/step - loss: 0.7084 - accuracy: 0.5000\n",
      "199488.34\n",
      "Epoch 434/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "201483.22\n",
      "Epoch 435/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "203498.05\n",
      "Epoch 436/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "205533.03\n",
      "Epoch 437/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "207588.36\n",
      "Epoch 438/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "209664.23\n",
      "Epoch 439/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "211760.88\n",
      "Epoch 440/500: - 0.0547s/step - loss: 0.7083 - accuracy: 0.5000\n",
      "213878.48\n",
      "Epoch 441/500: - 0.0547s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "216017.27\n",
      "Epoch 442/500: - 0.0547s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "218177.44\n",
      "Epoch 443/500: - 0.0548s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "220359.2\n",
      "Epoch 444/500: - 0.0548s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "222562.8\n",
      "Epoch 445/500: - 0.0548s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "224788.42\n",
      "Epoch 446/500: - 0.0548s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "227036.3\n",
      "Epoch 447/500: - 0.0547s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "229306.66\n",
      "Epoch 448/500: - 0.0547s/step - loss: 0.7082 - accuracy: 0.5000\n",
      "227036.3\n",
      "Epoch 449/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "229306.66\n",
      "Epoch 450/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "231599.72\n",
      "Epoch 451/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "233915.72\n",
      "Epoch 452/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "236254.88\n",
      "Epoch 453/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "238617.42\n",
      "Epoch 454/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "241003.6\n",
      "Epoch 455/500: - 0.0547s/step - loss: 0.7081 - accuracy: 0.5000\n",
      "243413.62\n",
      "Epoch 456/500: - 0.0547s/step - loss: 0.7080 - accuracy: 0.5000\n",
      "245847.77\n",
      "Epoch 457/500: - 0.0547s/step - loss: 0.7080 - accuracy: 0.5000\n",
      "248306.23\n",
      "Epoch 458/500: - 0.0548s/step - loss: 0.7080 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250789.3\n",
      "Epoch 459/500: - 0.0548s/step - loss: 0.7080 - accuracy: 0.5000\n",
      "253297.19\n",
      "Epoch 460/500: - 0.0548s/step - loss: 0.7080 - accuracy: 0.5000\n",
      "255830.16\n",
      "Epoch 461/500: - 0.0548s/step - loss: 0.7080 - accuracy: 0.5000\n",
      "258388.45\n",
      "Epoch 462/500: - 0.0548s/step - loss: 0.7080 - accuracy: 0.5000\n",
      "260972.33\n",
      "Epoch 463/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "258388.45\n",
      "Epoch 464/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "260972.33\n",
      "Epoch 465/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "263582.06\n",
      "Epoch 466/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "266217.88\n",
      "Epoch 467/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "268880.06\n",
      "Epoch 468/500: - 0.0548s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "271568.88\n",
      "Epoch 469/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "274284.56\n",
      "Epoch 470/500: - 0.0547s/step - loss: 0.7079 - accuracy: 0.5000\n",
      "277027.4\n",
      "Epoch 471/500: - 0.0547s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "279797.7\n",
      "Epoch 472/500: - 0.0547s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "282595.66\n",
      "Epoch 473/500: - 0.0547s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "285421.62\n",
      "Epoch 474/500: - 0.0547s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "288275.84\n",
      "Epoch 475/500: - 0.0548s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "291158.6\n",
      "Epoch 476/500: - 0.0548s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "288275.84\n",
      "Epoch 477/500: - 0.0547s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "285421.62\n",
      "Epoch 478/500: - 0.0547s/step - loss: 0.7078 - accuracy: 0.5000\n",
      "288275.84\n",
      "Epoch 479/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "291158.6\n",
      "Epoch 480/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "294070.2\n",
      "Epoch 481/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "297010.88\n",
      "Epoch 482/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "299980.97\n",
      "Epoch 483/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "302980.78\n",
      "Epoch 484/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "306010.6\n",
      "Epoch 485/500: - 0.0547s/step - loss: 0.7077 - accuracy: 0.5000\n",
      "309070.7\n",
      "Epoch 486/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "312161.4\n",
      "Epoch 487/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "315283.03\n",
      "Epoch 488/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "318435.84\n",
      "Epoch 489/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "321620.2\n",
      "Epoch 490/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "324836.38\n",
      "Epoch 491/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "328084.75\n",
      "Epoch 492/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "331365.6\n",
      "Epoch 493/500: - 0.0547s/step - loss: 0.7076 - accuracy: 0.5000\n",
      "334679.25\n",
      "Epoch 494/500: - 0.0547s/step - loss: 0.7075 - accuracy: 0.5000\n",
      "338026.03\n",
      "Epoch 495/500: - 0.0547s/step - loss: 0.7075 - accuracy: 0.5000\n",
      "341406.28\n",
      "Epoch 496/500: - 0.0547s/step - loss: 0.7075 - accuracy: 0.5000\n",
      "344820.34\n",
      "Epoch 497/500: - 0.0547s/step - loss: 0.7075 - accuracy: 0.5000\n",
      "348268.53\n",
      "Epoch 498/500: - 0.0547s/step - loss: 0.7075 - accuracy: 0.5000\n",
      "351751.22\n",
      "Epoch 499/500: - 0.0546s/step - loss: 0.7075 - accuracy: 0.5000\n",
      "355268.72\n",
      "Epoch 500/500: - 0.0546s/step - loss: 0.7075 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for bs, (images, labels) in enumerate(train_ds):\n",
    "        \n",
    "        # only one mini-batch\n",
    "        model.update_weights(images, network[bs], labels, 0.1)\n",
    "        #network_new = [model.propose_new_state_hamiltonian(images, net, labels) for (images, labels), net in \n",
    "        #               zip(train_ds, network)]\n",
    "        network_new = []\n",
    "        kernels_new = []\n",
    "        for (images, labels), net, hmc_kernel in zip(train_ds, network, kernels):\n",
    "            net_current = net\n",
    "            net_current = [tf.cast(net_i, dtype=tf.float32) for net_i in net_current]\n",
    "            net_current = net_current[0]\n",
    "        \n",
    "            num_results = 1\n",
    "            num_burnin_steps = 0\n",
    "\n",
    "            samples = tfp.mcmc.sample_chain(\n",
    "                num_results = num_results,\n",
    "                num_burnin_steps = num_burnin_steps,\n",
    "                current_state = net_current, # may need to be reshaped\n",
    "                kernel = hmc_kernel,\n",
    "                trace_fn = None,\n",
    "                return_final_kernel_results = True)\n",
    "\n",
    "            print(samples[2][4].numpy())\n",
    "            new_step_size = samples[2][4].numpy()\n",
    "            net_new = tf.split(samples[0][0], [2], axis = 1)   \n",
    "            network_new.append(net_new)\n",
    "            \n",
    "            ker_new = model.generate_hmc_kernel(images, labels, new_step_size)\n",
    "            kernels_new.append(ker_new)\n",
    "            \n",
    "        network = network_new\n",
    "        kernels = kernels_new\n",
    "        \n",
    "        loss += -1 * tf.reduce_mean(model.target_log_prob(images, network[bs], labels))\n",
    "    \n",
    "    preds = [model.get_predictions(images) for images, labels in train_ds]\n",
    "    train_acc = accuracy_score(np.array(preds[0]), y_train)\n",
    "    print(\"Epoch %d/%d: - %.4fs/step - loss: %.4f - accuracy: %.4f\" \n",
    "          % (epoch + 1, epochs, (time.time() - start_time) / (epoch + 1), loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1778279410038923"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(1000,-0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
