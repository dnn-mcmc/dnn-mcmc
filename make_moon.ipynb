{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "X, Y = make_moons(1000, noise = 0.1)\n",
    "\n",
    "# Split into test and training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=73)\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(64)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(*x_train[y_train.flatten() == 1, :].T)\n",
    "plt.scatter(*x_train[y_train.flatten() == 0, :].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((750, 2), (750, 1))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Standard BP\n",
    "model_bp = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(2,)),\n",
    "        layers.Dense(100, activation = \"sigmoid\"),\n",
    "        #layers.Dense(50, activation = \"sigmoid\"),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "model_bp.summary()\n",
    "#model_bp.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6467\n",
      "Epoch 2/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7373\n",
      "Epoch 3/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6282 - accuracy: 0.7773\n",
      "Epoch 4/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6112 - accuracy: 0.7613\n",
      "Epoch 5/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5907 - accuracy: 0.7920\n",
      "Epoch 6/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.8173\n",
      "Epoch 7/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7933\n",
      "Epoch 8/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8080\n",
      "Epoch 9/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8107\n",
      "Epoch 10/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.8053\n",
      "Epoch 11/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8133\n",
      "Epoch 12/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.8133\n",
      "Epoch 13/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.8187\n",
      "Epoch 14/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.8187\n",
      "Epoch 15/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4202 - accuracy: 0.8173\n",
      "Epoch 16/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8293\n",
      "Epoch 17/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8173\n",
      "Epoch 18/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8200\n",
      "Epoch 19/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8307\n",
      "Epoch 20/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8293\n",
      "Epoch 21/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3657 - accuracy: 0.8320\n",
      "Epoch 22/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8320\n",
      "Epoch 23/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8333\n",
      "Epoch 24/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8320\n",
      "Epoch 25/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3427 - accuracy: 0.8347\n",
      "Epoch 26/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8373\n",
      "Epoch 27/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3327 - accuracy: 0.8413\n",
      "Epoch 28/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8427\n",
      "Epoch 29/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8387\n",
      "Epoch 30/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8400\n",
      "Epoch 31/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8480\n",
      "Epoch 32/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8400\n",
      "Epoch 33/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3123 - accuracy: 0.8427\n",
      "Epoch 34/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3103 - accuracy: 0.8467\n",
      "Epoch 35/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3052 - accuracy: 0.8493\n",
      "Epoch 36/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8453\n",
      "Epoch 37/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8480\n",
      "Epoch 38/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8520\n",
      "Epoch 39/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.8507\n",
      "Epoch 40/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8533\n",
      "Epoch 41/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2918 - accuracy: 0.8533\n",
      "Epoch 42/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.8573\n",
      "Epoch 43/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2876 - accuracy: 0.8560\n",
      "Epoch 44/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2856 - accuracy: 0.8573\n",
      "Epoch 45/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2853 - accuracy: 0.8600\n",
      "Epoch 46/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8573\n",
      "Epoch 47/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2807 - accuracy: 0.8573\n",
      "Epoch 48/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8573\n",
      "Epoch 49/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2778 - accuracy: 0.8587\n",
      "Epoch 50/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2756 - accuracy: 0.8587\n",
      "Epoch 51/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2758 - accuracy: 0.8613\n",
      "Epoch 52/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2738 - accuracy: 0.8627\n",
      "Epoch 53/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8680\n",
      "Epoch 54/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2714 - accuracy: 0.8653\n",
      "Epoch 55/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2708 - accuracy: 0.8627\n",
      "Epoch 56/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2685 - accuracy: 0.8667\n",
      "Epoch 57/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2675 - accuracy: 0.8640\n",
      "Epoch 58/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2663 - accuracy: 0.8693\n",
      "Epoch 59/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8720\n",
      "Epoch 60/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2670 - accuracy: 0.8707\n",
      "Epoch 61/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.8720\n",
      "Epoch 62/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8707\n",
      "Epoch 63/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2616 - accuracy: 0.8707\n",
      "Epoch 64/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.8747\n",
      "Epoch 65/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2617 - accuracy: 0.8733\n",
      "Epoch 66/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.8747\n",
      "Epoch 67/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2601 - accuracy: 0.8733\n",
      "Epoch 68/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.8760\n",
      "Epoch 69/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2594 - accuracy: 0.8747\n",
      "Epoch 70/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2569 - accuracy: 0.8773\n",
      "Epoch 71/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2571 - accuracy: 0.8827\n",
      "Epoch 72/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2565 - accuracy: 0.8773\n",
      "Epoch 73/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2563 - accuracy: 0.8760\n",
      "Epoch 74/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.8800\n",
      "Epoch 75/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2545 - accuracy: 0.8787\n",
      "Epoch 76/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.8747\n",
      "Epoch 77/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.8760\n",
      "Epoch 78/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.8800\n",
      "Epoch 79/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.8747\n",
      "Epoch 80/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.2546 - accuracy: 0.8787\n",
      "Epoch 81/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2526 - accuracy: 0.8787\n",
      "Epoch 82/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.8773\n",
      "Epoch 83/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2528 - accuracy: 0.8800\n",
      "Epoch 84/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.8840\n",
      "Epoch 85/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.8840\n",
      "Epoch 86/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.8787\n",
      "Epoch 87/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.8867\n",
      "Epoch 88/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8773\n",
      "Epoch 89/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2512 - accuracy: 0.8880\n",
      "Epoch 90/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2507 - accuracy: 0.8800\n",
      "Epoch 91/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.8853\n",
      "Epoch 92/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.8800\n",
      "Epoch 93/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2495 - accuracy: 0.8853\n",
      "Epoch 94/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2505 - accuracy: 0.8853\n",
      "Epoch 95/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8827\n",
      "Epoch 96/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8827\n",
      "Epoch 97/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2492 - accuracy: 0.8813\n",
      "Epoch 98/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2496 - accuracy: 0.8827\n",
      "Epoch 99/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8827\n",
      "Epoch 100/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.8853\n",
      "Epoch 101/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.8853\n",
      "Epoch 102/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8827\n",
      "Epoch 103/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8827\n",
      "Epoch 104/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8800\n",
      "Epoch 105/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8827\n",
      "Epoch 106/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8787\n",
      "Epoch 107/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.8800\n",
      "Epoch 108/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8827\n",
      "Epoch 109/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.8827\n",
      "Epoch 110/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.8853\n",
      "Epoch 111/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8787\n",
      "Epoch 112/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8880\n",
      "Epoch 113/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8853\n",
      "Epoch 114/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8867\n",
      "Epoch 115/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8907\n",
      "Epoch 116/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8867\n",
      "Epoch 117/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8853\n",
      "Epoch 118/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8813\n",
      "Epoch 119/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8867\n",
      "Epoch 120/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.8853\n",
      "Epoch 121/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.8760\n",
      "Epoch 122/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8813\n",
      "Epoch 123/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8867\n",
      "Epoch 124/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8880\n",
      "Epoch 125/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 126/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8840\n",
      "Epoch 127/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8840\n",
      "Epoch 128/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8867\n",
      "Epoch 129/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.8827\n",
      "Epoch 130/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 131/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 132/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8800\n",
      "Epoch 133/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8840\n",
      "Epoch 134/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8867\n",
      "Epoch 135/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8840\n",
      "Epoch 136/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8853\n",
      "Epoch 137/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8853\n",
      "Epoch 138/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8880\n",
      "Epoch 139/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8840\n",
      "Epoch 140/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8827\n",
      "Epoch 141/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8827\n",
      "Epoch 142/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8853\n",
      "Epoch 143/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8880\n",
      "Epoch 144/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8840\n",
      "Epoch 145/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8813\n",
      "Epoch 146/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8760\n",
      "Epoch 147/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.8827\n",
      "Epoch 148/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 149/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 150/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.8827\n",
      "Epoch 151/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8853\n",
      "Epoch 152/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8840\n",
      "Epoch 153/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 154/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8827\n",
      "Epoch 155/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 156/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8853\n",
      "Epoch 157/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8853\n",
      "Epoch 158/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 159/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8800\n",
      "Epoch 160/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8840\n",
      "Epoch 161/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8867\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.8827\n",
      "Epoch 163/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8840\n",
      "Epoch 164/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8813\n",
      "Epoch 165/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8867\n",
      "Epoch 166/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8800\n",
      "Epoch 167/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8880\n",
      "Epoch 168/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8773\n",
      "Epoch 169/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8893\n",
      "Epoch 170/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 171/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 172/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 173/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 174/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8867\n",
      "Epoch 175/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 176/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8827\n",
      "Epoch 177/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 178/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8867\n",
      "Epoch 179/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 180/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8827\n",
      "Epoch 181/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 182/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8813\n",
      "Epoch 183/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8853\n",
      "Epoch 184/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 185/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8867\n",
      "Epoch 186/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 187/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8760\n",
      "Epoch 188/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 189/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8867\n",
      "Epoch 190/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8880\n",
      "Epoch 191/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.8867\n",
      "Epoch 192/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 193/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8853\n",
      "Epoch 194/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8813\n",
      "Epoch 195/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8867\n",
      "Epoch 196/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8813\n",
      "Epoch 197/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8800\n",
      "Epoch 198/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8893\n",
      "Epoch 199/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8827\n",
      "Epoch 200/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8907\n",
      "Epoch 201/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8827\n",
      "Epoch 202/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 203/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8840\n",
      "Epoch 204/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 205/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 206/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8853\n",
      "Epoch 207/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 208/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8800\n",
      "Epoch 209/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8800\n",
      "Epoch 210/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 211/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8827\n",
      "Epoch 212/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8853\n",
      "Epoch 213/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 214/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8827\n",
      "Epoch 215/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8853\n",
      "Epoch 216/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8853\n",
      "Epoch 217/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8787\n",
      "Epoch 218/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8840\n",
      "Epoch 219/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 220/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8867\n",
      "Epoch 221/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8827\n",
      "Epoch 222/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8800\n",
      "Epoch 223/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8880\n",
      "Epoch 224/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8813\n",
      "Epoch 225/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 226/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 227/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8813\n",
      "Epoch 228/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8840\n",
      "Epoch 229/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8827\n",
      "Epoch 230/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 231/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2464 - accuracy: 0.8827\n",
      "Epoch 232/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 233/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 234/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 235/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8867\n",
      "Epoch 236/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 237/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8813\n",
      "Epoch 238/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 239/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8853\n",
      "Epoch 240/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8880\n",
      "Epoch 241/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8747\n",
      "Epoch 242/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.8827\n",
      "Epoch 243/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8827\n",
      "Epoch 244/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 245/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8813\n",
      "Epoch 246/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8813\n",
      "Epoch 247/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8880\n",
      "Epoch 248/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.8907\n",
      "Epoch 249/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8840\n",
      "Epoch 250/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8787\n",
      "Epoch 251/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8773\n",
      "Epoch 252/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.8827\n",
      "Epoch 253/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 254/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 255/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8813\n",
      "Epoch 256/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 257/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8853\n",
      "Epoch 258/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8867\n",
      "Epoch 259/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8880\n",
      "Epoch 260/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8827\n",
      "Epoch 261/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.8867\n",
      "Epoch 262/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 263/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 264/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 265/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8827\n",
      "Epoch 266/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8840\n",
      "Epoch 267/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.8853\n",
      "Epoch 268/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8893\n",
      "Epoch 269/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8800\n",
      "Epoch 270/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8840\n",
      "Epoch 271/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8827\n",
      "Epoch 272/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8880\n",
      "Epoch 273/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 274/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8827\n",
      "Epoch 275/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8760\n",
      "Epoch 276/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8893\n",
      "Epoch 277/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.8840\n",
      "Epoch 278/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 279/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 280/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8813\n",
      "Epoch 281/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.8867\n",
      "Epoch 282/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8893\n",
      "Epoch 283/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8800\n",
      "Epoch 284/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8840\n",
      "Epoch 285/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 286/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8773\n",
      "Epoch 287/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8800\n",
      "Epoch 288/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 289/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8813\n",
      "Epoch 290/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.8827\n",
      "Epoch 291/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8880\n",
      "Epoch 292/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8853\n",
      "Epoch 293/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8813\n",
      "Epoch 294/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 295/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8827\n",
      "Epoch 296/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8827\n",
      "Epoch 297/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 298/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8827\n",
      "Epoch 299/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 300/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 301/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 302/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.8813\n",
      "Epoch 303/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8800\n",
      "Epoch 304/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8880\n",
      "Epoch 305/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8800\n",
      "Epoch 306/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8813\n",
      "Epoch 307/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8867\n",
      "Epoch 308/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8840\n",
      "Epoch 309/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 310/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8813\n",
      "Epoch 311/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8867\n",
      "Epoch 312/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8893\n",
      "Epoch 313/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8800\n",
      "Epoch 314/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 315/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8800\n",
      "Epoch 316/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8853\n",
      "Epoch 317/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 318/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8880\n",
      "Epoch 319/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 320/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 321/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.8867\n",
      "Epoch 323/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8773\n",
      "Epoch 324/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8840\n",
      "Epoch 325/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.8827\n",
      "Epoch 326/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.8787\n",
      "Epoch 327/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 328/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8880\n",
      "Epoch 329/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 330/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8827\n",
      "Epoch 331/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8907\n",
      "Epoch 332/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8787\n",
      "Epoch 333/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8893\n",
      "Epoch 334/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 335/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 336/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8867\n",
      "Epoch 337/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8813\n",
      "Epoch 338/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 339/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8867\n",
      "Epoch 340/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 341/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8813\n",
      "Epoch 342/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 343/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8800\n",
      "Epoch 344/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8880\n",
      "Epoch 345/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8880\n",
      "Epoch 346/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8813\n",
      "Epoch 347/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8827\n",
      "Epoch 348/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8867\n",
      "Epoch 349/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8800\n",
      "Epoch 350/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8813\n",
      "Epoch 351/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 352/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8773\n",
      "Epoch 353/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8867\n",
      "Epoch 354/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8867\n",
      "Epoch 355/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8893\n",
      "Epoch 356/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 357/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8853\n",
      "Epoch 358/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.8800\n",
      "Epoch 359/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8853\n",
      "Epoch 360/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8853\n",
      "Epoch 361/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8800\n",
      "Epoch 362/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 363/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8827\n",
      "Epoch 364/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8853\n",
      "Epoch 365/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.8880\n",
      "Epoch 366/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 367/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.8893\n",
      "Epoch 368/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8827\n",
      "Epoch 369/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8813\n",
      "Epoch 370/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8880\n",
      "Epoch 371/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8800\n",
      "Epoch 372/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8813\n",
      "Epoch 373/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 374/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 375/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 376/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 377/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8853\n",
      "Epoch 378/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8840\n",
      "Epoch 379/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8840\n",
      "Epoch 380/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8813\n",
      "Epoch 381/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8840\n",
      "Epoch 382/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8867\n",
      "Epoch 383/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 384/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8800\n",
      "Epoch 385/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 386/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8827\n",
      "Epoch 387/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 388/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8853\n",
      "Epoch 389/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 390/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8920\n",
      "Epoch 391/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 392/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 393/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8867\n",
      "Epoch 394/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8800\n",
      "Epoch 395/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8853\n",
      "Epoch 396/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 397/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2450 - accuracy: 0.8800\n",
      "Epoch 398/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8880\n",
      "Epoch 399/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.8773\n",
      "Epoch 400/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2471 - accuracy: 0.8840\n",
      "Epoch 401/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8813\n",
      "Epoch 402/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 403/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2455 - accuracy: 0.8800\n",
      "Epoch 404/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8800\n",
      "Epoch 405/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 406/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8787\n",
      "Epoch 407/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 408/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 409/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8787\n",
      "Epoch 410/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 411/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8893\n",
      "Epoch 412/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 413/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8880\n",
      "Epoch 414/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8840\n",
      "Epoch 415/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8800\n",
      "Epoch 416/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8813\n",
      "Epoch 417/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 418/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 419/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8840\n",
      "Epoch 420/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 421/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8773\n",
      "Epoch 422/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.8880\n",
      "Epoch 423/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 424/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8933\n",
      "Epoch 425/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8827\n",
      "Epoch 426/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8827\n",
      "Epoch 427/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2455 - accuracy: 0.8840\n",
      "Epoch 428/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8840\n",
      "Epoch 429/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.8893\n",
      "Epoch 430/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 431/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8853\n",
      "Epoch 432/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 433/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8787\n",
      "Epoch 434/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8867\n",
      "Epoch 435/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8800\n",
      "Epoch 436/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8840\n",
      "Epoch 437/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8813\n",
      "Epoch 438/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8853\n",
      "Epoch 439/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8867\n",
      "Epoch 440/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 441/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8840\n",
      "Epoch 442/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8800\n",
      "Epoch 443/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 444/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 445/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8827\n",
      "Epoch 446/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 447/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.8840\n",
      "Epoch 448/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8813\n",
      "Epoch 449/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 450/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8813\n",
      "Epoch 451/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 452/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8813\n",
      "Epoch 453/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 454/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.8907\n",
      "Epoch 455/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8813\n",
      "Epoch 456/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8880\n",
      "Epoch 457/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 458/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 459/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8800\n",
      "Epoch 460/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 461/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8813\n",
      "Epoch 462/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 463/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8827\n",
      "Epoch 464/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8827\n",
      "Epoch 465/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8893\n",
      "Epoch 466/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8827\n",
      "Epoch 467/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8800\n",
      "Epoch 468/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8867\n",
      "Epoch 469/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 470/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8893\n",
      "Epoch 471/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8800\n",
      "Epoch 472/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8840\n",
      "Epoch 473/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 474/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8787\n",
      "Epoch 475/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8787\n",
      "Epoch 476/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 477/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8867\n",
      "Epoch 478/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 479/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8840\n",
      "Epoch 480/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8800\n",
      "Epoch 481/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 483/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8800\n",
      "Epoch 484/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8880\n",
      "Epoch 485/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8787\n",
      "Epoch 486/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8840\n",
      "Epoch 487/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 488/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8853\n",
      "Epoch 489/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8840\n",
      "Epoch 490/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8880\n",
      "Epoch 491/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 492/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 493/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8893\n",
      "Epoch 494/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 495/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8800\n",
      "Epoch 496/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8827\n",
      "Epoch 497/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8867\n",
      "Epoch 498/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8880\n",
      "Epoch 499/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 500/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2483 - accuracy: 0.8800\n",
      "Epoch 501/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8787\n",
      "Epoch 502/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8893\n",
      "Epoch 503/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8773\n",
      "Epoch 504/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.8827\n",
      "Epoch 505/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8787\n",
      "Epoch 506/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 507/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 508/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8853\n",
      "Epoch 509/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 510/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8853\n",
      "Epoch 511/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8853\n",
      "Epoch 512/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8907\n",
      "Epoch 513/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 514/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8827\n",
      "Epoch 515/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8907\n",
      "Epoch 516/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8800\n",
      "Epoch 517/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 518/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8853\n",
      "Epoch 519/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 520/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.8813\n",
      "Epoch 521/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 522/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 523/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8747\n",
      "Epoch 524/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8880\n",
      "Epoch 525/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.8853\n",
      "Epoch 526/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 527/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8787\n",
      "Epoch 528/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8840\n",
      "Epoch 529/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2462 - accuracy: 0.8853\n",
      "Epoch 530/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 531/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8773\n",
      "Epoch 532/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8813\n",
      "Epoch 533/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8800\n",
      "Epoch 534/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8827\n",
      "Epoch 535/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8800\n",
      "Epoch 536/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 537/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8853\n",
      "Epoch 538/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8867\n",
      "Epoch 539/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 540/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 541/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8880\n",
      "Epoch 542/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 543/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 544/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 545/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8893\n",
      "Epoch 546/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 547/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.8867\n",
      "Epoch 548/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 549/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 550/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 551/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8773\n",
      "Epoch 552/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 553/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 554/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.8827\n",
      "Epoch 555/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8867\n",
      "Epoch 556/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.8787\n",
      "Epoch 557/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 558/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 559/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8840\n",
      "Epoch 560/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 561/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8827\n",
      "Epoch 562/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 563/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8773\n",
      "Epoch 564/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8867\n",
      "Epoch 565/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 566/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 567/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 568/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8893\n",
      "Epoch 569/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8840\n",
      "Epoch 570/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8827\n",
      "Epoch 571/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 572/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8773\n",
      "Epoch 573/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8813\n",
      "Epoch 574/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 575/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 576/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 577/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 578/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8840\n",
      "Epoch 579/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 580/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8760\n",
      "Epoch 581/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8907\n",
      "Epoch 582/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8787\n",
      "Epoch 583/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 584/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8827\n",
      "Epoch 585/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.8827\n",
      "Epoch 586/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8840\n",
      "Epoch 587/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 588/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.8760\n",
      "Epoch 589/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 590/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 591/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8760\n",
      "Epoch 592/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8827\n",
      "Epoch 593/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8867\n",
      "Epoch 594/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8787\n",
      "Epoch 595/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.8880\n",
      "Epoch 596/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8853\n",
      "Epoch 597/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8867\n",
      "Epoch 598/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8840\n",
      "Epoch 599/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 600/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 601/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8827\n",
      "Epoch 602/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8800\n",
      "Epoch 603/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 604/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8867\n",
      "Epoch 605/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8827\n",
      "Epoch 606/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8867\n",
      "Epoch 607/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8827\n",
      "Epoch 608/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8813\n",
      "Epoch 609/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 610/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8733\n",
      "Epoch 611/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8867\n",
      "Epoch 612/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 613/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8867\n",
      "Epoch 614/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8893\n",
      "Epoch 615/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8867\n",
      "Epoch 616/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8813\n",
      "Epoch 617/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 618/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8827\n",
      "Epoch 619/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8800\n",
      "Epoch 620/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8880\n",
      "Epoch 621/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8813\n",
      "Epoch 622/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8800\n",
      "Epoch 623/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8867\n",
      "Epoch 624/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8773\n",
      "Epoch 625/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 626/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8827\n",
      "Epoch 627/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8840\n",
      "Epoch 628/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8813\n",
      "Epoch 629/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8827\n",
      "Epoch 630/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 631/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8853\n",
      "Epoch 632/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8867\n",
      "Epoch 633/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8853\n",
      "Epoch 634/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8813\n",
      "Epoch 635/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 636/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 637/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 638/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8813\n",
      "Epoch 639/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8840\n",
      "Epoch 640/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8907\n",
      "Epoch 641/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8840\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8880\n",
      "Epoch 643/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8787\n",
      "Epoch 644/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8853\n",
      "Epoch 645/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8893\n",
      "Epoch 646/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8813\n",
      "Epoch 647/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 648/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8880\n",
      "Epoch 649/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8907\n",
      "Epoch 650/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8800\n",
      "Epoch 651/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8813\n",
      "Epoch 652/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 653/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8867\n",
      "Epoch 654/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8907\n",
      "Epoch 655/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8867\n",
      "Epoch 656/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 657/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8853\n",
      "Epoch 658/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8787\n",
      "Epoch 659/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 660/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8800\n",
      "Epoch 661/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.8800\n",
      "Epoch 662/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8827\n",
      "Epoch 663/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8787\n",
      "Epoch 664/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8747\n",
      "Epoch 665/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 666/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8813\n",
      "Epoch 667/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8893\n",
      "Epoch 668/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8867\n",
      "Epoch 669/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 670/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2470 - accuracy: 0.8853\n",
      "Epoch 671/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 672/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 673/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8853\n",
      "Epoch 674/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8827\n",
      "Epoch 675/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8800\n",
      "Epoch 676/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8840\n",
      "Epoch 677/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8840\n",
      "Epoch 678/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8813\n",
      "Epoch 679/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2466 - accuracy: 0.8800\n",
      "Epoch 680/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8800\n",
      "Epoch 681/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 682/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8813\n",
      "Epoch 683/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8800\n",
      "Epoch 684/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8893\n",
      "Epoch 685/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8853\n",
      "Epoch 686/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8827\n",
      "Epoch 687/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8787\n",
      "Epoch 688/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8787\n",
      "Epoch 689/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 690/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.8827\n",
      "Epoch 691/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 692/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8827\n",
      "Epoch 693/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8813\n",
      "Epoch 694/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2454 - accuracy: 0.8813\n",
      "Epoch 695/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8840\n",
      "Epoch 696/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8787\n",
      "Epoch 697/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8867\n",
      "Epoch 698/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8840\n",
      "Epoch 699/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 700/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8867\n",
      "Epoch 701/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8853\n",
      "Epoch 702/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8880\n",
      "Epoch 703/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8827\n",
      "Epoch 704/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8827\n",
      "Epoch 705/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8880\n",
      "Epoch 706/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8840\n",
      "Epoch 707/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8893\n",
      "Epoch 708/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8827\n",
      "Epoch 709/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 710/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8880\n",
      "Epoch 711/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 712/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8880\n",
      "Epoch 713/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8880\n",
      "Epoch 714/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2443 - accuracy: 0.8907\n",
      "Epoch 715/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8773\n",
      "Epoch 716/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8853\n",
      "Epoch 717/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 718/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8813\n",
      "Epoch 719/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8840\n",
      "Epoch 720/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8893\n",
      "Epoch 721/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8867\n",
      "Epoch 722/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 723/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8853\n",
      "Epoch 724/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8800\n",
      "Epoch 725/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 726/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 727/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8840\n",
      "Epoch 728/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8867\n",
      "Epoch 729/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8840\n",
      "Epoch 730/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8893\n",
      "Epoch 731/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 732/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8813\n",
      "Epoch 733/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8880\n",
      "Epoch 734/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 735/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 736/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8800\n",
      "Epoch 737/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 738/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8827\n",
      "Epoch 739/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8840\n",
      "Epoch 740/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 741/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8880\n",
      "Epoch 742/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8813\n",
      "Epoch 743/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8867\n",
      "Epoch 744/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8893\n",
      "Epoch 745/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 746/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8893\n",
      "Epoch 747/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 748/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 749/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8880\n",
      "Epoch 750/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8773\n",
      "Epoch 751/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8867\n",
      "Epoch 752/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2457 - accuracy: 0.8800\n",
      "Epoch 753/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8853\n",
      "Epoch 754/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8813\n",
      "Epoch 755/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8893\n",
      "Epoch 756/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 757/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8827\n",
      "Epoch 758/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8893\n",
      "Epoch 759/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 760/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8853\n",
      "Epoch 761/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8800\n",
      "Epoch 762/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2462 - accuracy: 0.8827\n",
      "Epoch 763/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8840\n",
      "Epoch 764/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8813\n",
      "Epoch 765/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8853\n",
      "Epoch 766/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8813\n",
      "Epoch 767/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8827\n",
      "Epoch 768/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8813\n",
      "Epoch 769/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8853\n",
      "Epoch 770/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8867\n",
      "Epoch 771/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8827\n",
      "Epoch 772/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8840\n",
      "Epoch 773/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 774/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8813\n",
      "Epoch 775/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.8893\n",
      "Epoch 776/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8853\n",
      "Epoch 777/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.8853\n",
      "Epoch 778/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8840\n",
      "Epoch 779/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8853\n",
      "Epoch 780/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8880\n",
      "Epoch 781/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 782/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8840\n",
      "Epoch 783/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8840\n",
      "Epoch 784/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8853\n",
      "Epoch 785/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8787\n",
      "Epoch 786/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8867\n",
      "Epoch 787/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8867\n",
      "Epoch 788/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8747\n",
      "Epoch 789/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8867\n",
      "Epoch 790/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8787\n",
      "Epoch 791/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8813\n",
      "Epoch 792/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8867\n",
      "Epoch 793/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.8907\n",
      "Epoch 794/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 795/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 796/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.8827\n",
      "Epoch 797/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8813\n",
      "Epoch 798/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8840\n",
      "Epoch 799/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 800/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 801/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8853\n",
      "Epoch 803/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8827\n",
      "Epoch 804/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8853\n",
      "Epoch 805/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8853\n",
      "Epoch 806/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8800\n",
      "Epoch 807/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.8840\n",
      "Epoch 808/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 809/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 810/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 811/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8840\n",
      "Epoch 812/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 813/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8853\n",
      "Epoch 814/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8853\n",
      "Epoch 815/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8813\n",
      "Epoch 816/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8840\n",
      "Epoch 817/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.8840\n",
      "Epoch 818/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.8867\n",
      "Epoch 819/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.8800\n",
      "Epoch 820/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2447 - accuracy: 0.8800\n",
      "Epoch 821/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8813\n",
      "Epoch 822/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8827\n",
      "Epoch 823/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8867\n",
      "Epoch 824/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 825/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 826/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 827/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8880\n",
      "Epoch 828/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 829/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8880\n",
      "Epoch 830/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 831/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8773\n",
      "Epoch 832/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8853\n",
      "Epoch 833/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8813\n",
      "Epoch 834/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 835/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8813\n",
      "Epoch 836/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8800\n",
      "Epoch 837/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8813\n",
      "Epoch 838/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.8853\n",
      "Epoch 839/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8827\n",
      "Epoch 840/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8827\n",
      "Epoch 841/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8880\n",
      "Epoch 842/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8827\n",
      "Epoch 843/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8840\n",
      "Epoch 844/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8867\n",
      "Epoch 845/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8907\n",
      "Epoch 846/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8827\n",
      "Epoch 847/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 848/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8827\n",
      "Epoch 849/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8840\n",
      "Epoch 850/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8853\n",
      "Epoch 851/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 852/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8787\n",
      "Epoch 853/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8853\n",
      "Epoch 854/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8880\n",
      "Epoch 855/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8813\n",
      "Epoch 856/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.8893\n",
      "Epoch 857/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8813\n",
      "Epoch 858/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8867\n",
      "Epoch 859/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 860/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8840\n",
      "Epoch 861/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8893\n",
      "Epoch 862/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8773\n",
      "Epoch 863/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 864/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 865/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8853\n",
      "Epoch 866/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.8827\n",
      "Epoch 867/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8827\n",
      "Epoch 868/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8853\n",
      "Epoch 869/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8893\n",
      "Epoch 870/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8813\n",
      "Epoch 871/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8880\n",
      "Epoch 872/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 873/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8893\n",
      "Epoch 874/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8787\n",
      "Epoch 875/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8827\n",
      "Epoch 876/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8827\n",
      "Epoch 877/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8800\n",
      "Epoch 878/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2437 - accuracy: 0.8827\n",
      "Epoch 879/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2464 - accuracy: 0.8840\n",
      "Epoch 880/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8920\n",
      "Epoch 881/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8747\n",
      "Epoch 882/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8893\n",
      "Epoch 883/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8867\n",
      "Epoch 884/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8813\n",
      "Epoch 885/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8867\n",
      "Epoch 886/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2463 - accuracy: 0.8773\n",
      "Epoch 887/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.8880\n",
      "Epoch 888/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8813\n",
      "Epoch 889/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8813\n",
      "Epoch 890/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 891/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 892/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8813\n",
      "Epoch 893/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8867\n",
      "Epoch 894/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8787\n",
      "Epoch 895/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8760\n",
      "Epoch 896/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8813\n",
      "Epoch 897/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8880\n",
      "Epoch 898/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8800\n",
      "Epoch 899/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8813\n",
      "Epoch 900/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8880\n",
      "Epoch 901/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8787\n",
      "Epoch 902/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8773\n",
      "Epoch 903/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8853\n",
      "Epoch 904/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 905/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.8880\n",
      "Epoch 906/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8787\n",
      "Epoch 907/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8893\n",
      "Epoch 908/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2459 - accuracy: 0.8840\n",
      "Epoch 909/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8827\n",
      "Epoch 910/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8813\n",
      "Epoch 911/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8760\n",
      "Epoch 912/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8800\n",
      "Epoch 913/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8827\n",
      "Epoch 914/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8880\n",
      "Epoch 915/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 916/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8813\n",
      "Epoch 917/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8880\n",
      "Epoch 918/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2453 - accuracy: 0.8840\n",
      "Epoch 919/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8867\n",
      "Epoch 920/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8827\n",
      "Epoch 921/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8800\n",
      "Epoch 922/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 923/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8840\n",
      "Epoch 924/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8853\n",
      "Epoch 925/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8853\n",
      "Epoch 926/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 927/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8787\n",
      "Epoch 928/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8880\n",
      "Epoch 929/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8827\n",
      "Epoch 930/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8827\n",
      "Epoch 931/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8867\n",
      "Epoch 932/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8813\n",
      "Epoch 933/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2458 - accuracy: 0.8840\n",
      "Epoch 934/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8853\n",
      "Epoch 935/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2467 - accuracy: 0.8813\n",
      "Epoch 936/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8853\n",
      "Epoch 937/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8853\n",
      "Epoch 938/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8840\n",
      "Epoch 939/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8867\n",
      "Epoch 940/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 941/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.8867\n",
      "Epoch 942/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8867\n",
      "Epoch 943/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8853\n",
      "Epoch 944/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8827\n",
      "Epoch 945/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8827\n",
      "Epoch 946/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8787\n",
      "Epoch 947/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 948/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8800\n",
      "Epoch 949/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2436 - accuracy: 0.8773\n",
      "Epoch 950/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2457 - accuracy: 0.8880\n",
      "Epoch 951/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8827\n",
      "Epoch 952/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8867\n",
      "Epoch 953/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2455 - accuracy: 0.8800\n",
      "Epoch 954/1000\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.8880\n",
      "Epoch 955/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 956/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2446 - accuracy: 0.8907\n",
      "Epoch 957/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8893\n",
      "Epoch 958/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8880\n",
      "Epoch 959/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8893\n",
      "Epoch 960/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8827\n",
      "Epoch 961/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2456 - accuracy: 0.8787\n",
      "Epoch 963/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8840\n",
      "Epoch 964/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2433 - accuracy: 0.8773\n",
      "Epoch 965/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8893\n",
      "Epoch 966/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8800\n",
      "Epoch 967/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8813\n",
      "Epoch 968/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8853\n",
      "Epoch 969/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8853\n",
      "Epoch 970/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8840\n",
      "Epoch 971/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8867\n",
      "Epoch 972/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8853\n",
      "Epoch 973/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8880\n",
      "Epoch 974/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8840\n",
      "Epoch 975/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8800\n",
      "Epoch 976/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8867\n",
      "Epoch 977/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2469 - accuracy: 0.8800\n",
      "Epoch 978/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8840\n",
      "Epoch 979/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8867\n",
      "Epoch 980/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8827\n",
      "Epoch 981/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.8813\n",
      "Epoch 982/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8880\n",
      "Epoch 983/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 984/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.8827\n",
      "Epoch 985/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2440 - accuracy: 0.8813\n",
      "Epoch 986/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2453 - accuracy: 0.8853\n",
      "Epoch 987/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8840\n",
      "Epoch 988/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2449 - accuracy: 0.8853\n",
      "Epoch 989/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.8827\n",
      "Epoch 990/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.8840\n",
      "Epoch 991/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2439 - accuracy: 0.8880\n",
      "Epoch 992/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2441 - accuracy: 0.8800\n",
      "Epoch 993/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.8827\n",
      "Epoch 994/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.8813\n",
      "Epoch 995/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.8813\n",
      "Epoch 996/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.8867\n",
      "Epoch 997/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.8853\n",
      "Epoch 998/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2454 - accuracy: 0.8853\n",
      "Epoch 999/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.8840\n",
      "Epoch 1000/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2443 - accuracy: 0.8840\n",
      "31.09956407546997\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "st = time.time()\n",
    "model_bp.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model_bp.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hmc\n",
    "\n",
    "def convert2_zero_one(x):\n",
    "    \n",
    "    t = [tf.math.sigmoid(i) for i in x]\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerange(x, r = 6.0):\n",
    "    \n",
    "    out_of_range = tf.cast(tf.math.greater(tf.math.abs(x), r), tf.float32)\n",
    "    sign = tf.math.sign(x)\n",
    "    \n",
    "    return x * (1 - out_of_range) + sign * r * out_of_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        #x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        h_current = convert2_zero_one([tf.cast(h_i, dtype=tf.float32) for h_i in h])\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "    \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "\n",
    "        h_current = convert2_zero_one(tf.split(h, self.hidden_layer_sizes, axis = 1))\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def generate_hmc_kernel(self, x, y, step_size = pow(1000, -1/4)):\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = step_size),\n",
    "            num_adaptation_steps=int(100 * 0.8))\n",
    "        \n",
    "        return adaptive_hmc\n",
    "    \n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y, hmc_kernel):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concatenate(h_current)\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_results = 1\n",
    "        num_burnin_steps = 0\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            trace_fn = None)\n",
    "\n",
    "        new_step_size = samples[2][4].numpy()\n",
    "        \n",
    "        h_state = rerange(samples[0][0])\n",
    "        h_new = tf.split(h_state, [100], axis = 1)   \n",
    "\n",
    "        return(h_new, new_step_size)\n",
    "    \n",
    "    def update_weights(self, x, h, y, lr = 0.1):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "\n",
    "        logits = 0.0\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tf.math.sigmoid(logits)\n",
    "        \n",
    "        logits = self.output_layer(x)\n",
    "        probs = tf.math.sigmoid(logits)\n",
    "        #print(probs)\n",
    "        labels = tf.cast(tf.math.greater(probs, 0.5), tf.int32)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [100], n_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_28 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [model.generate_hmc_kernel(images, labels) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n"
     ]
    }
   ],
   "source": [
    "burnin = 500\n",
    "step_sizes = []\n",
    "for i in range(burnin):\n",
    "    \n",
    "    if(i % 100 == 0):\n",
    "        print(\"Step %d\" % i)\n",
    "    network_new = []\n",
    "    kernels_new = []\n",
    "    \n",
    "    for (images, labels), net, hmc_kernel in zip(train_ds, network, kernels):\n",
    "        net_current = net\n",
    "        net_current = [tf.cast(net_i, dtype=tf.float32) for net_i in net_current]\n",
    "        net_current = tf.concat(net_current, axis = 1)\n",
    "        \n",
    "        num_results = 1\n",
    "        num_burnin_steps = 0\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = net_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            #trace_fn = lambda _, pkr: pkr.inner_results.accepted_results.new_step_size,\n",
    "            trace_fn = None,\n",
    "            return_final_kernel_results = True)\n",
    "        \n",
    "        #print(samples[2].new_step_size.numpy())\n",
    "        new_step_size = samples[2][4].numpy()\n",
    "        step_sizes.append(new_step_size)\n",
    "        \n",
    "        new_state = rerange(samples[0][0])\n",
    "        net_new = tf.split(new_state, [100], axis = 1)   \n",
    "        network_new.append(net_new)\n",
    "        \n",
    "        # build new kernel\n",
    "        ker_new = model.generate_hmc_kernel(images, labels, new_step_size)\n",
    "        kernels_new.append(ker_new)\n",
    "            \n",
    "    network = network_new\n",
    "    kernels = kernels_new\n",
    "    \n",
    "    #print(network[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(step_sizes)), step_sizes)\n",
    "plt.show()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: - 3.5292s/step - loss: 834.4193 - accuracy: 0.4987\n",
      "Epoch 2/1000: - 3.4532s/step - loss: 832.7709 - accuracy: 0.4987\n",
      "Epoch 3/1000: - 3.4241s/step - loss: 830.1022 - accuracy: 0.6947\n",
      "Epoch 4/1000: - 3.4361s/step - loss: 826.6130 - accuracy: 0.7947\n",
      "Epoch 5/1000: - 3.5280s/step - loss: 824.9352 - accuracy: 0.7853\n",
      "Epoch 6/1000: - 3.6803s/step - loss: 821.5208 - accuracy: 0.7867\n",
      "Epoch 7/1000: - 3.7281s/step - loss: 818.6333 - accuracy: 0.7880\n",
      "Epoch 8/1000: - 3.9903s/step - loss: 814.4333 - accuracy: 0.7893\n",
      "Epoch 9/1000: - 3.9396s/step - loss: 811.3907 - accuracy: 0.7907\n",
      "Epoch 10/1000: - 3.9920s/step - loss: 805.8640 - accuracy: 0.7867\n",
      "Epoch 11/1000: - 3.9562s/step - loss: 801.4409 - accuracy: 0.7907\n",
      "Epoch 12/1000: - 3.9110s/step - loss: 796.9257 - accuracy: 0.7947\n",
      "Epoch 13/1000: - 3.9304s/step - loss: 792.7896 - accuracy: 0.7947\n",
      "Epoch 14/1000: - 3.8919s/step - loss: 788.4025 - accuracy: 0.7987\n",
      "Epoch 15/1000: - 3.8667s/step - loss: 783.7791 - accuracy: 0.7987\n",
      "Epoch 16/1000: - 3.8506s/step - loss: 779.3858 - accuracy: 0.8000\n",
      "Epoch 17/1000: - 3.8282s/step - loss: 775.3726 - accuracy: 0.8013\n",
      "Epoch 18/1000: - 3.8135s/step - loss: 770.9703 - accuracy: 0.8067\n",
      "Epoch 19/1000: - 3.7977s/step - loss: 767.4297 - accuracy: 0.8093\n",
      "Epoch 20/1000: - 3.7831s/step - loss: 761.4920 - accuracy: 0.8133\n",
      "Epoch 21/1000: - 3.7886s/step - loss: 757.6040 - accuracy: 0.8160\n",
      "Epoch 22/1000: - 3.7745s/step - loss: 754.6280 - accuracy: 0.8187\n",
      "Epoch 23/1000: - 3.7566s/step - loss: 749.5322 - accuracy: 0.8200\n",
      "Epoch 24/1000: - 3.7389s/step - loss: 746.5826 - accuracy: 0.8240\n",
      "Epoch 25/1000: - 3.7235s/step - loss: 742.8398 - accuracy: 0.8240\n",
      "Epoch 26/1000: - 3.7093s/step - loss: 739.6029 - accuracy: 0.8267\n",
      "Epoch 27/1000: - 3.6970s/step - loss: 735.9274 - accuracy: 0.8293\n",
      "Epoch 28/1000: - 3.6908s/step - loss: 733.2009 - accuracy: 0.8293\n",
      "Epoch 29/1000: - 3.7053s/step - loss: 729.1454 - accuracy: 0.8293\n",
      "Epoch 30/1000: - 3.7483s/step - loss: 726.1790 - accuracy: 0.8307\n",
      "Epoch 31/1000: - 3.7687s/step - loss: 722.9635 - accuracy: 0.8347\n",
      "Epoch 32/1000: - 3.7610s/step - loss: 720.6932 - accuracy: 0.8307\n",
      "Epoch 33/1000: - 3.7581s/step - loss: 718.6627 - accuracy: 0.8333\n",
      "Epoch 34/1000: - 3.7737s/step - loss: 715.5436 - accuracy: 0.8333\n",
      "Epoch 35/1000: - 3.7673s/step - loss: 712.6984 - accuracy: 0.8360\n",
      "Epoch 36/1000: - 3.7657s/step - loss: 711.6514 - accuracy: 0.8373\n",
      "Epoch 37/1000: - 3.8263s/step - loss: 709.9639 - accuracy: 0.8333\n",
      "Epoch 38/1000: - 3.8175s/step - loss: 707.9235 - accuracy: 0.8347\n",
      "Epoch 39/1000: - 3.8052s/step - loss: 706.5553 - accuracy: 0.8347\n",
      "Epoch 40/1000: - 3.7941s/step - loss: 704.5125 - accuracy: 0.8387\n",
      "Epoch 41/1000: - 3.7829s/step - loss: 703.0620 - accuracy: 0.8373\n",
      "Epoch 42/1000: - 3.7728s/step - loss: 701.6802 - accuracy: 0.8387\n",
      "Epoch 43/1000: - 3.7635s/step - loss: 700.3186 - accuracy: 0.8387\n",
      "Epoch 44/1000: - 3.7732s/step - loss: 698.8087 - accuracy: 0.8400\n",
      "Epoch 45/1000: - 3.7632s/step - loss: 697.0521 - accuracy: 0.8400\n",
      "Epoch 46/1000: - 3.7562s/step - loss: 696.1329 - accuracy: 0.8413\n",
      "Epoch 47/1000: - 3.7532s/step - loss: 695.3351 - accuracy: 0.8413\n",
      "Epoch 48/1000: - 3.7506s/step - loss: 694.1917 - accuracy: 0.8427\n",
      "Epoch 49/1000: - 3.7470s/step - loss: 693.0722 - accuracy: 0.8427\n",
      "Epoch 50/1000: - 3.7491s/step - loss: 691.9474 - accuracy: 0.8427\n",
      "Epoch 51/1000: - 3.7410s/step - loss: 690.9466 - accuracy: 0.8413\n",
      "Epoch 52/1000: - 3.7336s/step - loss: 689.8390 - accuracy: 0.8440\n",
      "Epoch 53/1000: - 3.7307s/step - loss: 689.0653 - accuracy: 0.8453\n",
      "Epoch 54/1000: - 3.7283s/step - loss: 688.4083 - accuracy: 0.8427\n",
      "Epoch 55/1000: - 3.7214s/step - loss: 687.3546 - accuracy: 0.8440\n",
      "Epoch 56/1000: - 3.7188s/step - loss: 686.8292 - accuracy: 0.8427\n",
      "Epoch 57/1000: - 3.7127s/step - loss: 686.3007 - accuracy: 0.8427\n",
      "Epoch 58/1000: - 3.7069s/step - loss: 685.4297 - accuracy: 0.8440\n",
      "Epoch 59/1000: - 3.7027s/step - loss: 685.3588 - accuracy: 0.8440\n",
      "Epoch 60/1000: - 3.6990s/step - loss: 684.8624 - accuracy: 0.8453\n",
      "Epoch 61/1000: - 3.7249s/step - loss: 684.0997 - accuracy: 0.8440\n",
      "Epoch 62/1000: - 3.7287s/step - loss: 683.7693 - accuracy: 0.8427\n",
      "Epoch 63/1000: - 3.7220s/step - loss: 682.7758 - accuracy: 0.8440\n",
      "Epoch 64/1000: - 3.7165s/step - loss: 681.8245 - accuracy: 0.8427\n",
      "Epoch 65/1000: - 3.7120s/step - loss: 681.0988 - accuracy: 0.8427\n",
      "Epoch 66/1000: - 3.7061s/step - loss: 680.3755 - accuracy: 0.8467\n",
      "Epoch 67/1000: - 3.7000s/step - loss: 680.0164 - accuracy: 0.8427\n",
      "Epoch 68/1000: - 3.6948s/step - loss: 679.2881 - accuracy: 0.8427\n",
      "Epoch 69/1000: - 3.6898s/step - loss: 678.5349 - accuracy: 0.8467\n",
      "Epoch 70/1000: - 3.6846s/step - loss: 678.0302 - accuracy: 0.8480\n",
      "Epoch 71/1000: - 3.6797s/step - loss: 677.6606 - accuracy: 0.8480\n",
      "Epoch 72/1000: - 3.6740s/step - loss: 677.0085 - accuracy: 0.8480\n",
      "Epoch 73/1000: - 3.6687s/step - loss: 676.4980 - accuracy: 0.8467\n",
      "Epoch 74/1000: - 3.6641s/step - loss: 676.2263 - accuracy: 0.8493\n",
      "Epoch 75/1000: - 3.6595s/step - loss: 675.6133 - accuracy: 0.8480\n",
      "Epoch 76/1000: - 3.6550s/step - loss: 675.1541 - accuracy: 0.8493\n",
      "Epoch 77/1000: - 3.6596s/step - loss: 674.8939 - accuracy: 0.8480\n",
      "Epoch 78/1000: - 3.6581s/step - loss: 674.6545 - accuracy: 0.8480\n",
      "Epoch 79/1000: - 3.6597s/step - loss: 674.0395 - accuracy: 0.8493\n",
      "Epoch 80/1000: - 3.6555s/step - loss: 673.5985 - accuracy: 0.8507\n",
      "Epoch 81/1000: - 3.6518s/step - loss: 672.9987 - accuracy: 0.8507\n",
      "Epoch 82/1000: - 3.6478s/step - loss: 672.8444 - accuracy: 0.8493\n",
      "Epoch 83/1000: - 3.6437s/step - loss: 672.3539 - accuracy: 0.8507\n",
      "Epoch 84/1000: - 3.6396s/step - loss: 671.9589 - accuracy: 0.8507\n",
      "Epoch 85/1000: - 3.6360s/step - loss: 671.6696 - accuracy: 0.8507\n",
      "Epoch 86/1000: - 3.6326s/step - loss: 671.5492 - accuracy: 0.8520\n",
      "Epoch 87/1000: - 3.6289s/step - loss: 671.3291 - accuracy: 0.8520\n",
      "Epoch 88/1000: - 3.6282s/step - loss: 671.1613 - accuracy: 0.8507\n",
      "Epoch 89/1000: - 3.6383s/step - loss: 670.6694 - accuracy: 0.8520\n",
      "Epoch 90/1000: - 3.6349s/step - loss: 669.9670 - accuracy: 0.8520\n",
      "Epoch 91/1000: - 3.6314s/step - loss: 669.6799 - accuracy: 0.8520\n",
      "Epoch 92/1000: - 3.6281s/step - loss: 668.7990 - accuracy: 0.8520\n",
      "Epoch 93/1000: - 3.6249s/step - loss: 668.5181 - accuracy: 0.8533\n",
      "Epoch 94/1000: - 3.6219s/step - loss: 668.2246 - accuracy: 0.8520\n",
      "Epoch 95/1000: - 3.6191s/step - loss: 667.6952 - accuracy: 0.8520\n",
      "Epoch 96/1000: - 3.6184s/step - loss: 667.1672 - accuracy: 0.8520\n",
      "Epoch 97/1000: - 3.6167s/step - loss: 666.9670 - accuracy: 0.8520\n",
      "Epoch 98/1000: - 3.6141s/step - loss: 666.2783 - accuracy: 0.8547\n",
      "Epoch 99/1000: - 3.6116s/step - loss: 665.8197 - accuracy: 0.8520\n",
      "Epoch 100/1000: - 3.6089s/step - loss: 665.4169 - accuracy: 0.8520\n",
      "Epoch 101/1000: - 3.6063s/step - loss: 664.7940 - accuracy: 0.8520\n",
      "Epoch 102/1000: - 3.6044s/step - loss: 664.4391 - accuracy: 0.8520\n",
      "Epoch 103/1000: - 3.6020s/step - loss: 664.1143 - accuracy: 0.8533\n",
      "Epoch 104/1000: - 3.5991s/step - loss: 663.9958 - accuracy: 0.8533\n",
      "Epoch 105/1000: - 3.5967s/step - loss: 663.7538 - accuracy: 0.8533\n",
      "Epoch 106/1000: - 3.5944s/step - loss: 663.8290 - accuracy: 0.8533\n",
      "Epoch 107/1000: - 3.5927s/step - loss: 663.4295 - accuracy: 0.8533\n",
      "Epoch 108/1000: - 3.5902s/step - loss: 662.9373 - accuracy: 0.8533\n",
      "Epoch 109/1000: - 3.5880s/step - loss: 662.6964 - accuracy: 0.8533\n",
      "Epoch 110/1000: - 3.5854s/step - loss: 662.4283 - accuracy: 0.8533\n",
      "Epoch 111/1000: - 3.5836s/step - loss: 662.1792 - accuracy: 0.8560\n",
      "Epoch 112/1000: - 3.5813s/step - loss: 661.9294 - accuracy: 0.8573\n",
      "Epoch 113/1000: - 3.5792s/step - loss: 661.5616 - accuracy: 0.8533\n",
      "Epoch 114/1000: - 3.5767s/step - loss: 661.5280 - accuracy: 0.8547\n",
      "Epoch 115/1000: - 3.5747s/step - loss: 661.2080 - accuracy: 0.8533\n",
      "Epoch 116/1000: - 3.5725s/step - loss: 661.1595 - accuracy: 0.8533\n",
      "Epoch 117/1000: - 3.5730s/step - loss: 661.0604 - accuracy: 0.8533\n",
      "Epoch 118/1000: - 3.5717s/step - loss: 660.3849 - accuracy: 0.8547\n",
      "Epoch 119/1000: - 3.5693s/step - loss: 660.3919 - accuracy: 0.8533\n",
      "Epoch 120/1000: - 3.5675s/step - loss: 660.3828 - accuracy: 0.8547\n",
      "Epoch 121/1000: - 3.5655s/step - loss: 659.8469 - accuracy: 0.8600\n",
      "Epoch 122/1000: - 3.5637s/step - loss: 659.2948 - accuracy: 0.8600\n",
      "Epoch 123/1000: - 3.5682s/step - loss: 658.7632 - accuracy: 0.8600\n",
      "Epoch 124/1000: - 3.5675s/step - loss: 658.6577 - accuracy: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000: - 3.5667s/step - loss: 658.5577 - accuracy: 0.8547\n",
      "Epoch 126/1000: - 3.5646s/step - loss: 658.5063 - accuracy: 0.8560\n",
      "Epoch 127/1000: - 3.5624s/step - loss: 658.1181 - accuracy: 0.8560\n",
      "Epoch 128/1000: - 3.5604s/step - loss: 657.9594 - accuracy: 0.8533\n",
      "Epoch 129/1000: - 3.5592s/step - loss: 657.4438 - accuracy: 0.8533\n",
      "Epoch 130/1000: - 3.5573s/step - loss: 657.1545 - accuracy: 0.8533\n",
      "Epoch 131/1000: - 3.5556s/step - loss: 656.7266 - accuracy: 0.8533\n",
      "Epoch 132/1000: - 3.5541s/step - loss: 656.5719 - accuracy: 0.8533\n",
      "Epoch 133/1000: - 3.5526s/step - loss: 656.5386 - accuracy: 0.8533\n",
      "Epoch 134/1000: - 3.5507s/step - loss: 656.3618 - accuracy: 0.8533\n",
      "Epoch 135/1000: - 3.5490s/step - loss: 656.3187 - accuracy: 0.8533\n",
      "Epoch 136/1000: - 3.5474s/step - loss: 656.0220 - accuracy: 0.8533\n",
      "Epoch 137/1000: - 3.5455s/step - loss: 655.6465 - accuracy: 0.8533\n",
      "Epoch 138/1000: - 3.5440s/step - loss: 655.5096 - accuracy: 0.8533\n",
      "Epoch 139/1000: - 3.5422s/step - loss: 655.1794 - accuracy: 0.8533\n",
      "Epoch 140/1000: - 3.5405s/step - loss: 655.0528 - accuracy: 0.8533\n",
      "Epoch 141/1000: - 3.5391s/step - loss: 654.6034 - accuracy: 0.8533\n",
      "Epoch 142/1000: - 3.5374s/step - loss: 654.2513 - accuracy: 0.8547\n",
      "Epoch 143/1000: - 3.5359s/step - loss: 654.0629 - accuracy: 0.8547\n",
      "Epoch 144/1000: - 3.5347s/step - loss: 653.9561 - accuracy: 0.8560\n",
      "Epoch 145/1000: - 3.5386s/step - loss: 653.4442 - accuracy: 0.8573\n",
      "Epoch 146/1000: - 3.5448s/step - loss: 653.2982 - accuracy: 0.8573\n",
      "Epoch 147/1000: - 3.5431s/step - loss: 653.1786 - accuracy: 0.8627\n",
      "Epoch 148/1000: - 3.5467s/step - loss: 653.1547 - accuracy: 0.8627\n",
      "Epoch 149/1000: - 3.5491s/step - loss: 653.0309 - accuracy: 0.8627\n",
      "Epoch 150/1000: - 3.5495s/step - loss: 652.6106 - accuracy: 0.8627\n",
      "Epoch 151/1000: - 3.5493s/step - loss: 652.5499 - accuracy: 0.8627\n",
      "Epoch 152/1000: - 3.5480s/step - loss: 652.3746 - accuracy: 0.8627\n",
      "Epoch 153/1000: - 3.5467s/step - loss: 652.2656 - accuracy: 0.8627\n",
      "Epoch 154/1000: - 3.5453s/step - loss: 651.9703 - accuracy: 0.8627\n",
      "Epoch 155/1000: - 3.5441s/step - loss: 651.8916 - accuracy: 0.8627\n",
      "Epoch 156/1000: - 3.5436s/step - loss: 651.6646 - accuracy: 0.8627\n",
      "Epoch 157/1000: - 3.5440s/step - loss: 651.7194 - accuracy: 0.8627\n",
      "Epoch 158/1000: - 3.5463s/step - loss: 651.5511 - accuracy: 0.8627\n",
      "Epoch 159/1000: - 3.5485s/step - loss: 651.3141 - accuracy: 0.8627\n",
      "Epoch 160/1000: - 3.5512s/step - loss: 650.9805 - accuracy: 0.8627\n",
      "Epoch 161/1000: - 3.5519s/step - loss: 650.7479 - accuracy: 0.8640\n",
      "Epoch 162/1000: - 3.5514s/step - loss: 650.5679 - accuracy: 0.8640\n",
      "Epoch 163/1000: - 3.5502s/step - loss: 650.4452 - accuracy: 0.8640\n",
      "Epoch 164/1000: - 3.5488s/step - loss: 650.3665 - accuracy: 0.8640\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-939120217daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 return_final_kernel_results = True)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrerange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mnet_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mnetwork_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-555779f60ccc>\u001b[0m in \u001b[0;36mrerange\u001b[0;34m(x, r)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrerange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mout_of_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0msign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mabs\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0mreturned\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrespectively\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[0;32m--> 264\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Abs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name, default_name, values, skip_on_eager)\u001b[0m\n\u001b[1;32m   6212\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6213\u001b[0m   \"\"\"\n\u001b[0;32m-> 6214\u001b[0;31m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6215\u001b[0m   \u001b[0min_eager_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6216\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_eager_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for bs, (x, y) in enumerate(train_ds):\n",
    "        \n",
    "        # only one mini-batch\n",
    "        model.update_weights(x, network[bs], y, 0.1)\n",
    "        \n",
    "        network_new = []\n",
    "\n",
    "        for (xx, yy), net, hmc_kernel in zip(train_ds, network, kernels):\n",
    "            net_current = net\n",
    "            net_current = [tf.cast(net_i, dtype=tf.float32) for net_i in net_current]\n",
    "            net_current = tf.concat(net_current, axis = 1)\n",
    "        \n",
    "            num_results = 1\n",
    "            num_burnin_steps = 0\n",
    "\n",
    "            samples = tfp.mcmc.sample_chain(\n",
    "                num_results = num_results,\n",
    "                num_burnin_steps = num_burnin_steps,\n",
    "                current_state = net_current, # may need to be reshaped\n",
    "                kernel = hmc_kernel,\n",
    "                trace_fn = None,\n",
    "                return_final_kernel_results = True)\n",
    "            \n",
    "            new_state = rerange(samples[0][0])\n",
    "            net_new = tf.split(new_state, [100], axis = 1)   \n",
    "            network_new.append(net_new)\n",
    "   \n",
    "        network = network_new\n",
    "        \n",
    "        loss += -1 * tf.reduce_mean(model.target_log_prob(x, network[bs], y))\n",
    "    \n",
    "    preds = [model.get_predictions(images) for images, labels in train_ds]\n",
    "    train_acc = accuracy_score(np.concatenate(preds), y_train)\n",
    "    print(\"Epoch %d/%d: - %.4fs/step - loss: %.4f - accuracy: %.4f\" \n",
    "          % (epoch + 1, epochs, (time.time() - start_time) / (epoch + 1), loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
