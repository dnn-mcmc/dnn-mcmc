{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.math import log_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12665 training images.\n",
      "There are 2115 test images.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select binary data\n",
    "label_sub = [0,1]\n",
    "x_train_sub = [x for x, y in zip(x_train, y_train) if y in label_sub]\n",
    "y_train_sub = [y for y in y_train if y in label_sub]\n",
    "x_test_sub = [x for x, y in zip(x_test, y_test) if y in label_sub]\n",
    "y_test_sub = [y for y in y_test if y in label_sub]\n",
    "\n",
    "\n",
    "print('There are', len(x_train_sub), 'training images.')\n",
    "print('There are', len(x_test_sub), 'test images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_sub, y_train_sub)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test_sub, y_test_sub)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_zero_one(x):\n",
    "\n",
    "    t = [tf.math.sigmoid(i) for i in x]\n",
    "    \n",
    "    return t\n",
    "\n",
    "def rerange(x, r = 6.0):\n",
    "    \n",
    "    out_of_range = tf.cast(tf.math.greater(tf.math.abs(x), r), tf.float32)\n",
    "    sign = tf.math.sign(x)\n",
    "    \n",
    "    return x * (1 - out_of_range) + sign * r * out_of_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes = [100, 50], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "        \n",
    "    def call(self, x):\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        y = [[i] for i in y]\n",
    "        h_current = convert2_zero_one([tf.cast(h_i, dtype=tf.float32) for h_i in h])\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "    \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        y = [[i] for i in y]\n",
    "        h_current = convert2_zero_one(tf.split(h, self.hidden_layer_sizes, axis = 1))\n",
    "        #h_current = [h_current[0]]\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def generate_hmc_kernel(self, x, y, step_size = pow(1000, -1/4)):\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = step_size),\n",
    "            num_adaptation_steps=int(100 * 0.8))\n",
    "        \n",
    "        return adaptive_hmc\n",
    "    \n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y, hmc_ker):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concat([h[0], h[1]], axis=1)\n",
    "\n",
    "        # initialize the HMC transition kernel\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = pow(1000, -1/4)),\n",
    "            num_adaptation_steps=int(100*0.8))\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_results = 1\n",
    "        num_burnin_steps = 100\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = adaptive_hmc,\n",
    "            trace_fn = None)\n",
    "\n",
    "        h_new = tf.split(samples[0], self.hidden_layer_sizes, axis = 1)\n",
    "\n",
    "        return(h_new)\n",
    "    \n",
    "    def update_weights(self, x, h, y, lr = 0.1):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        logits = 0.0\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tf.math.sigmoid(logits)\n",
    "        \n",
    "        logits = self.output_layer(x)\n",
    "        probs = tf.math.sigmoid(logits)\n",
    "        #print(probs)\n",
    "        labels = tf.cast(tf.math.greater(probs, 0.5), tf.int32)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [100, 50], n_outputs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(32, 100), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 0, 1, ..., 0, 0, 1],\n",
       "        [1, 0, 1, ..., 0, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 1],\n",
       "        [0, 1, 1, ..., 1, 0, 1],\n",
       "        [0, 0, 1, ..., 1, 0, 1]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
       " array([[0, 0, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 1, 0],\n",
       "        [0, 1, 0, ..., 0, 1, 1],\n",
       "        [0, 0, 1, ..., 1, 1, 0]], dtype=int32)>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlp = [model.target_log_prob(images, network[bs], labels) for bs, (images, labels) in enumerate(train_ds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmy/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow_probability/python/__init__.py:74: UserWarning: TensorFloat-32 matmul/conv are enabled for NVIDIA Ampere+ GPUs. The resulting loss of precision may hinder MCMC convergence. To turn off, run `tf.config.experimental.enable_tensor_float_32_execution(False)`. For more detail, see https://github.com/tensorflow/community/pull/287.\n",
      "  'TensorFloat-32 matmul/conv are enabled for NVIDIA Ampere+ GPUs. The '\n"
     ]
    }
   ],
   "source": [
    "kernels = [model.generate_hmc_kernel(images, labels) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin = 20\n",
    "step_sizes = []\n",
    "for i in range(burnin):\n",
    "    \n",
    "    print(i)\n",
    "    network_new = []\n",
    "    kernels_new = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for (images, labels), net, hmc_kernel in zip(train_ds, network, kernels):\n",
    "        net_current = net\n",
    "        net_current = [tf.cast(net_i, dtype=tf.float32) for net_i in net_current]\n",
    "        #net_current = tf.concat([net_current[0], net_current[1]], axis=1)\n",
    "        net_current = tf.concat(net_current, axis = 1)\n",
    "        #print(net_current)\n",
    "        num_results = 1\n",
    "        num_burnin_steps = 0\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = net_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            #trace_fn = lambda _, pkr: pkr.inner_results.accepted_results.new_step_size,\n",
    "            trace_fn = None,\n",
    "            return_final_kernel_results = True)\n",
    "        \n",
    "        #print(samples[2].new_step_size.numpy())\n",
    "        new_step_size = samples[2].new_step_size.numpy()\n",
    "        step_sizes.append(new_step_size)\n",
    "\n",
    "        new_state = rerange(samples[0][0])\n",
    "        net_new = tf.split(new_state, [100, 50], axis = 1)   \n",
    "        network_new.append(net_new)\n",
    "        \n",
    "        # build new kernel\n",
    "        ker_new = model.generate_hmc_kernel(images, labels, new_step_size)\n",
    "        kernels_new.append(ker_new)\n",
    "            \n",
    "    network = network_new\n",
    "    kernels = kernels_new\n",
    "    \n",
    "    print(\"Step %d - time %.4f\" % (i, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(step_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(len(step_sizes)), step_sizes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "propose_new_state_hamiltonian() missing 1 required positional argument: 'hmc_ker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6654f34b8ed9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         network_new = [model.propose_new_state_hamiltonian(images, net, labels) for (images, labels), net in \n\u001b[0;32m---> 13\u001b[0;31m                        zip(train_ds, network)]\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mnetwork_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-6654f34b8ed9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# only one mini-batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         network_new = [model.propose_new_state_hamiltonian(images, net, labels) for (images, labels), net in \n\u001b[0m\u001b[1;32m     13\u001b[0m                        zip(train_ds, network)]\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: propose_new_state_hamiltonian() missing 1 required positional argument: 'hmc_ker'"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for bs, (images, labels) in enumerate(train_ds):\n",
    "        \n",
    "        # only one mini-batch\n",
    "        model.update_weights(images, network[bs], labels, 0.1)\n",
    "        network_new = [model.propose_new_state_hamiltonian(images, net, labels) for (images, labels), net in \n",
    "                       zip(train_ds, network)]\n",
    "        \n",
    "        network_new = []\n",
    "        #kernels_new = []\n",
    "        for net, hmc_kernel in zip(network, kernels):\n",
    "            net_current = net\n",
    "            net_current = [tf.cast(net_i, dtype=tf.float32) for net_i in net_current]\n",
    "            net_current = tf.concat(net_current, axis = 1)\n",
    "            \n",
    "            num_results = 1\n",
    "            num_burnin_steps = 0\n",
    "\n",
    "            samples = tfp.mcmc.sample_chain(\n",
    "                num_results = num_results,\n",
    "                num_burnin_steps = num_burnin_steps,\n",
    "                current_state = net_current, # may need to be reshaped\n",
    "                kernel = hmc_kernel,\n",
    "                trace_fn = None,\n",
    "                return_final_kernel_results = True)\n",
    "\n",
    "            #new_step_size = samples[2].new_step_size.numpy()\n",
    "            \n",
    "            new_state = rerange(samples[0][0])\n",
    "            net_new = tf.split(new_state, [100, 50], axis = 1)   \n",
    "            network_new.append(net_new)\n",
    "            \n",
    "            #ker_new = model.generate_hmc_kernel(images2, labels2, new_step_size)\n",
    "            #kernels_new.append(ker_new)\n",
    "            \n",
    "        network = network_new\n",
    "        #kernels = kernels_new\n",
    "\n",
    "        loss += -1 * tf.reduce_mean(model.target_log_prob(images, network[bs], labels))\n",
    "       \n",
    "    preds = [model.get_predictions(images) for images, labels in train_ds]\n",
    "    #print(preds)\n",
    "    train_acc = accuracy_score(np.array(preds[0]), y_train)\n",
    "    print(\"Epoch %d/%d: - %.4fs/step - loss: %.4f - accuracy: %.4f\" \n",
    "          % (epoch + 1, epochs, (time.time() - start_time) / (epoch + 1), loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
