{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12665 training images.\n",
      "There are 2115 test images.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select binary data\n",
    "label_sub = [0,1]\n",
    "x_train_sub = [x for x, y in zip(x_train, y_train) if y in label_sub]\n",
    "y_train_sub = [y for y in y_train if y in label_sub]\n",
    "x_test_sub = [x for x, y in zip(x_test, y_test) if y in label_sub]\n",
    "y_test_sub = [y for y in y_test if y in label_sub]\n",
    "\n",
    "\n",
    "print('There are', len(x_train_sub), 'training images.')\n",
    "print('There are', len(x_test_sub), 'test images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_sub, y_train_sub)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test_sub, y_test_sub)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "            #network['h%i_logits' % i] = logits\n",
    "            #network['h%i_values' % i] = x\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    \n",
    "    def propose_new_state(self, x, h, y):\n",
    "        '''returns new proposed h values\n",
    "        x: inputs\n",
    "        h: list of layer values\n",
    "        y: labels\n",
    "        returns h_proposed'''\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "\n",
    "        #h_current = [h['h%i_values' % i] for i in range(len(self.fc_layers))]\n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        \n",
    "        in_layers = self.fc_layers\n",
    "        out_layers = self.fc_layers[1:] + [self.output_layer]\n",
    "        \n",
    "        prev_vals = [x] + h_current[:-1]\n",
    "        curr_vals = h_current\n",
    "        next_vals = h_current[1:] + [y]\n",
    "        \n",
    "        h_new = []\n",
    "        \n",
    "        for i, (in_layer, out_layer, pv, cv, nv) in enumerate(\n",
    "            zip(in_layers, out_layers, prev_vals, curr_vals, next_vals)):\n",
    "            \n",
    "            prob_parents = tf.math.sigmoid(in_layer(pv))\n",
    "            \n",
    "            out_layer_weights = out_layer.get_weights()[0]\n",
    "            \n",
    "            next_logits = out_layer(cv)\n",
    "            \n",
    "            # if h1 node is a 1, subtract its weight\n",
    "            next_logits_if_node_is_0 = next_logits[:, tf.newaxis, :] - cv[:, :, np.newaxis] * out_layer_weights[tf.newaxis, :, :]\n",
    "        \n",
    "            # if h1 node is a 0, add its weight\n",
    "            next_logits_if_node_is_1 = next_logits[:, tf.newaxis, :] + (1 - cv[:, :, np.newaxis]) * out_layer_weights[tf.newaxis, :, :]\n",
    "            \n",
    "            if i < (len(curr_vals) - 1):\n",
    "                \n",
    "                nv_tiled = tf.cast(np.tile(nv[:, np.newaxis, :], (1, cv.shape[-1], 1)), dtype=tf.float32)\n",
    "                \n",
    "                logprob_children_if_node_is_0 = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=nv_tiled, logits=next_logits_if_node_is_0), axis=-1)\n",
    "\n",
    "                logprob_children_if_node_is_1  = tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                    labels=nv_tiled, logits=next_logits_if_node_is_1), axis=-1)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                nv_tiled = tf.cast(np.tile(nv[:, np.newaxis], (1, cv.shape[-1])), dtype=tf.int32)\n",
    "                \n",
    "                logprob_children_if_node_is_0 = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=nv_tiled, logits=next_logits_if_node_is_0)\n",
    "\n",
    "                logprob_children_if_node_is_1  = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                    labels=nv_tiled, logits=next_logits_if_node_is_1)\n",
    "            \n",
    "            prob_0 = (1 - prob_parents) * tf.math.exp(logprob_children_if_node_is_0)\n",
    "            prob_1 = prob_parents * tf.math.exp(logprob_children_if_node_is_1)\n",
    "        \n",
    "            prob = prob_1 / (prob_1 + prob_0)\n",
    "            \n",
    "            new_layer_state = tfp.distributions.Bernoulli(probs=prob).sample()\n",
    "            h_new.append(new_layer_state)\n",
    "       \n",
    "        # not sample output labels\n",
    "        # h_new['labels'] = tf.argmax(\n",
    "        #     tfp.distributions.Multinomial(10, logits=self.output_layer(h_current[-1])).sample(),\n",
    "        #     axis=1)\n",
    "            \n",
    "        return h_new\n",
    "\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        \n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "            \n",
    "        nlog_prob += tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.int32), logits=self.output_layer(h_current[-1]))\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def accept_reject(self, x, h, h_p, y):\n",
    "\n",
    "        log_prob_curr = self.target_log_prob(x, h, y)\n",
    "        log_prob_prop = self.target_log_prob(x, h_p, y)\n",
    "        \n",
    "        #ratio = [np.exp(-np.maximum(0, prop - curr)) for curr, prop in zip(log_prob_curr, log_prob_prop)]\n",
    "        ratio = np.exp(-np.maximum(0, log_prob_prop - log_prob_curr))\n",
    "        acceptance = tfp.distributions.Bernoulli(probs = ratio).sample()\n",
    "        \n",
    "        h_new = []\n",
    "        \n",
    "        for i in range(len(self.fc_layers)):\n",
    "            #h_new['h%i_values' % i] = h_p['h%i_values' % i] * acceptance[:, np.newaxis] \\\n",
    "            #    + h['h%i_values' % i] * (1 - acceptance)[:, np.newaxis]\n",
    "            acc_layer_state = h_p[i] * acceptance[:, np.newaxis] + h[i] * (1 - acceptance)[:, np.newaxis]\n",
    "            h_new.append(acc_layer_state)\n",
    "        \n",
    "        return h_new\n",
    "    \n",
    "    # update weights using tensorflow functions\n",
    "    def update_weights(self, x, h, y, lr = 0.001):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "\n",
    "        x = Flatten()(x)\n",
    "        h_current = tf.split(h, self.hidden_layer_sizes, axis = 1)\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=layer(pv))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "            \n",
    "        nlog_prob += tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.int32), logits=self.output_layer(h_current[-1]))\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concat([h_current[0], h_current[1]], axis=1)\n",
    "\n",
    "        # initialize the HMC transition kernel\n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = pow(1000, -1/4)),\n",
    "            num_adaptation_steps=int(100 * 0.8))\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_results = 1\n",
    "        num_burnin_steps = 100\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = adaptive_hmc,\n",
    "            trace_fn = None)\n",
    "\n",
    "        new_state = tf.math.sign(tf.math.sign(samples[0]) - 1) + 1\n",
    "        h_new = tf.split(new_state, self.hidden_layer_sizes, axis = 1)\n",
    "\n",
    "        return(h_new)\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "        x = Flatten()(x)\n",
    "\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits = logits).sample()\n",
    "        \n",
    "        final_logits = self.output_layer(x)\n",
    "        #final_predictions = tf.nn.softmax(final_logits)\n",
    "        final_labels = tf.argmax(tfp.distributions.Bernoulli(logits = final_logits).sample(), axis = 1)\n",
    "\n",
    "        return final_labels\n",
    "\n",
    "    def save_model(self, file):\n",
    "        with open(file, 'wb') as f:\n",
    "            for layer in self.fc_layers:\n",
    "                np.save(f, np.array(layer.get_weights()))\n",
    "            np.save(f, self.output_layer.get_weights())\n",
    "    \n",
    "    def load_model(self, file):\n",
    "        with open(file, 'rb', file) as f:\n",
    "            for layer in self.fc_layers:\n",
    "                layer.set_weights(np.load(f, allow_pickle = True))\n",
    "            self.output_layer.set_weights(np.load(f, allow_pickle = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [100, 50], n_outputs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_proposed = [model.propose_new_state(images, net, labels) for (images, labels), net in zip(train_ds, network)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.0% of nodes in layer 0 flipped\n",
      "46.7% of nodes in layer 1 flipped\n"
     ]
    }
   ],
   "source": [
    "# What proportion of the nodes flipped in batch 0?\n",
    "\n",
    "flipped = np.abs(network[0][0].numpy() - h_proposed[0][0].numpy())\n",
    "print('%.1f%% of nodes in layer 0 flipped' % (100. * flipped.sum() / np.ones_like(flipped).sum()))\n",
    "\n",
    "flipped = np.abs(network[0][1].numpy() - h_proposed[0][1].numpy())\n",
    "print('%.1f%% of nodes in layer 1 flipped' % (100. * flipped.sum() / np.ones_like(flipped).sum()))\n",
    "\n",
    "#print('Proposed label counts:', np.unique(h_proposed[0]['labels'], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_new = [model.accept_reject(images, net, net_proposed, labels) \n",
    "                      for (images, labels), net, net_proposed in zip(train_ds, network, h_proposed)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(32, 100), dtype=int32, numpy=\n",
       " array([[0, 0, 1, ..., 0, 1, 0],\n",
       "        [1, 0, 1, ..., 1, 1, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 1, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 1, 0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
       " array([[1, 0, 0, ..., 1, 1, 1],\n",
       "        [1, 0, 1, ..., 0, 0, 1],\n",
       "        [0, 1, 0, ..., 1, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 1, 1],\n",
       "        [0, 1, 0, ..., 0, 0, 1],\n",
       "        [1, 0, 0, ..., 1, 1, 1]], dtype=int32)>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-937b7f6a3297>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork_new_hmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose_new_state_hamiltonian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-937b7f6a3297>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork_new_hmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose_new_state_hamiltonian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-061754ba687d>\u001b[0m in \u001b[0;36mpropose_new_state_hamiltonian\u001b[0;34m(self, x, h, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mcurrent_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# may need to be reshaped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_hmc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             trace_fn = None)\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                             trace_fn(*state_and_results)),\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_final_kernel_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[0;34m(loop_fn, initial_state, elems, trace_fn, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mstacked_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_body\u001b[0;34m(i, state, trace_arrays)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       trace_arrays = tf.nest.pack_sequence_as(trace_arrays, [\n\u001b[1;32m    385\u001b[0m           a.write(i, v) for a, v in zip(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36m_trace_scan_fn\u001b[0;34m(state_and_results, num_steps)\u001b[0m\n\u001b[1;32m    341\u001b[0m           \u001b[0mbody_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m           \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_and_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m           parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    344\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36msmart_for_loop\u001b[0;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    314\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m       )[1:]\n\u001b[1;32m    318\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    312\u001b[0m       return tf.while_loop(\n\u001b[1;32m    313\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;31m# Step the inner kernel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       new_state, new_inner_results = self.inner_kernel.one_step(\n\u001b[0;32m--> 343\u001b[0;31m           current_state, inner_results)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m       \u001b[0;31m# Get the new step size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_step_size_assign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m       next_state, kernel_results = self._impl.one_step(\n\u001b[0;32m--> 547\u001b[0;31m           current_state, previous_kernel_results)\n\u001b[0m\u001b[1;32m    548\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         step_size_assign = self.step_size_update_fn(  # pylint: disable=not-callable\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m           \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m           previous_kernel_results.accepted_results)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       if (not has_target_log_prob(proposed_results) or\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    734\u001b[0m                      \u001b[0mcurrent_state_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                      \u001b[0mcurrent_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                      current_target_log_prob_grad_parts)\n\u001b[0m\u001b[1;32m    737\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_gradients_are_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mnext_state_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_state_parts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, momentum_parts, state_parts, target, target_grad_parts, name)\u001b[0m\n\u001b[1;32m    289\u001b[0m               \u001b[0mstate_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m               \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m               \u001b[0mtarget_grad_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m           ])\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n\u001b[0;32m--> 285\u001b[0;31m               self.target_fn, self.step_sizes, *args)),\n\u001b[0m\u001b[1;32m    286\u001b[0m           loop_vars=[\n\u001b[1;32m    287\u001b[0m               \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m_one_step\u001b[0;34m(target_fn, step_sizes, half_next_momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     [next_target, next_target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n\u001b[0;32m--> 326\u001b[0;31m         target_fn, next_state_parts)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_target_grad_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[1;32m    263\u001b[0m                    else [fn_arg_list])\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     if not all(dtype_util.is_floating(r.dtype)\n\u001b[1;32m    266\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    247\u001b[0m       ]\n\u001b[1;32m    248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp_math_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/math/gradient.py\u001b[0m in \u001b[0;36mvalue_and_gradient\u001b[0;34m(f, xs, output_gradients, use_gradient_tape, name)\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m       \u001b[0mdydx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m   \u001b[0;31m# This does not work with v1 TensorArrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m   if ops.executing_eagerly_outside_functions(\n\u001b[0m\u001b[1;32m    151\u001b[0m   ) or control_flow_util.EnableControlFlowV2(ops.get_default_graph()):\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mexecuting_eagerly_outside_functions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5578\u001b[0m     \u001b[0mboolean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moutermost\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meager\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5579\u001b[0m   \"\"\"\n\u001b[0;32m-> 5580\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5581\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5582\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecuting_eagerly\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1788\u001b[0m   \"\"\"\n\u001b[1;32m   1789\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault_execution_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "network_new_hmc = [model.propose_new_state_hamiltonian(images, net, labels) for (images, labels), net in zip(train_ds, network)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_new_hmc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_9/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[-0.07082057, -0.0320609 , -0.05619943, ...,  0.02850856,\n",
       "         -0.05967197, -0.01113894],\n",
       "        [ 0.05576119, -0.0653046 , -0.07524821, ...,  0.016     ,\n",
       "          0.01178055, -0.06248111],\n",
       "        [ 0.00890749,  0.05940312, -0.01237544, ..., -0.0494523 ,\n",
       "         -0.05554733,  0.06047027],\n",
       "        ...,\n",
       "        [ 0.05368322, -0.02687827, -0.07280143, ...,  0.05591173,\n",
       "         -0.015717  ,  0.04161309],\n",
       "        [ 0.02622981,  0.01471373,  0.00295261, ..., -0.02321336,\n",
       "         -0.0020818 , -0.0493086 ],\n",
       "        [-0.06421332,  0.02006906, -0.08206352, ...,  0.00243353,\n",
       "         -0.00642765,  0.03985669]], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_10/kernel:0' shape=(100, 50) dtype=float32, numpy=\n",
       " array([[-0.07048592,  0.18813653,  0.18288226, ..., -0.10015116,\n",
       "         -0.04023871,  0.00491723],\n",
       "        [ 0.15379359, -0.06974187,  0.03998065, ..., -0.05115633,\n",
       "         -0.03911129, -0.1792668 ],\n",
       "        [ 0.1749024 , -0.19124226, -0.02438517, ...,  0.03942661,\n",
       "          0.12589683, -0.08727312],\n",
       "        ...,\n",
       "        [ 0.08002569,  0.01156898, -0.14210811, ...,  0.08627416,\n",
       "         -0.06457224, -0.12008786],\n",
       "        [-0.01442079, -0.01256891, -0.1335866 , ...,  0.15032567,\n",
       "          0.03691883, -0.01873598],\n",
       "        [-0.03915338, -0.04443531, -0.17477345, ..., -0.19476895,\n",
       "         -0.01401405,  0.02520685]], dtype=float32)>,\n",
       " <tf.Variable 'dense_10/bias:0' shape=(50,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_11/kernel:0' shape=(50, 2) dtype=float32, numpy=\n",
       " array([[ 0.27912885,  0.20311904],\n",
       "        [ 0.10693315,  0.04138035],\n",
       "        [-0.12603088, -0.13363172],\n",
       "        [-0.07645077, -0.08188352],\n",
       "        [-0.08735639, -0.0197283 ],\n",
       "        [-0.13995266,  0.24360114],\n",
       "        [ 0.10362622,  0.15764827],\n",
       "        [ 0.16875666,  0.31549704],\n",
       "        [ 0.17931062, -0.08619818],\n",
       "        [ 0.27682346,  0.06792855],\n",
       "        [ 0.01114354, -0.096544  ],\n",
       "        [ 0.22558224, -0.15499564],\n",
       "        [-0.24800545, -0.08365181],\n",
       "        [ 0.23863542,  0.31213522],\n",
       "        [ 0.00563505,  0.11264586],\n",
       "        [-0.1884422 ,  0.255404  ],\n",
       "        [ 0.07436967,  0.19129682],\n",
       "        [-0.0362359 ,  0.18396664],\n",
       "        [ 0.22500688, -0.27835727],\n",
       "        [-0.03464153, -0.25145817],\n",
       "        [-0.32671124, -0.13094328],\n",
       "        [ 0.1359933 ,  0.10150743],\n",
       "        [ 0.11233845,  0.27754325],\n",
       "        [-0.084562  , -0.00730452],\n",
       "        [-0.1730628 , -0.25786358],\n",
       "        [-0.25244117,  0.0906063 ],\n",
       "        [-0.12034608,  0.12001696],\n",
       "        [-0.27217928,  0.20581448],\n",
       "        [ 0.33664256, -0.11217631],\n",
       "        [ 0.1597111 ,  0.16908103],\n",
       "        [ 0.315405  ,  0.24409008],\n",
       "        [-0.26806206,  0.08980972],\n",
       "        [-0.10911736, -0.12289442],\n",
       "        [-0.08904666,  0.15693098],\n",
       "        [-0.09984632,  0.29299974],\n",
       "        [ 0.19265449, -0.05303112],\n",
       "        [-0.27070466,  0.29858065],\n",
       "        [ 0.02018207, -0.19699739],\n",
       "        [ 0.30269486, -0.19673046],\n",
       "        [ 0.02704343,  0.06430325],\n",
       "        [-0.24964026, -0.20167121],\n",
       "        [ 0.06588048, -0.14832516],\n",
       "        [ 0.15210384,  0.23377103],\n",
       "        [ 0.31916124, -0.05911896],\n",
       "        [ 0.23102069,  0.09095672],\n",
       "        [-0.25119132,  0.24813348],\n",
       "        [-0.24315912,  0.2570495 ],\n",
       "        [ 0.06609225, -0.32683545],\n",
       "        [ 0.13158706,  0.24659061],\n",
       "        [-0.12634811,  0.12224206]], dtype=float32)>,\n",
       " <tf.Variable 'dense_11/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_9/kernel:0' shape=(784, 100) dtype=float32, numpy=\n",
       " array([[-0.07082057, -0.0320609 , -0.05619943, ...,  0.02850856,\n",
       "         -0.05967197, -0.01113894],\n",
       "        [ 0.05576119, -0.0653046 , -0.07524821, ...,  0.016     ,\n",
       "          0.01178055, -0.06248111],\n",
       "        [ 0.00890749,  0.05940312, -0.01237544, ..., -0.0494523 ,\n",
       "         -0.05554733,  0.06047027],\n",
       "        ...,\n",
       "        [ 0.05368322, -0.02687827, -0.07280143, ...,  0.05591173,\n",
       "         -0.015717  ,  0.04161309],\n",
       "        [ 0.02622981,  0.01471373,  0.00295261, ..., -0.02321336,\n",
       "         -0.0020818 , -0.0493086 ],\n",
       "        [-0.06421332,  0.02006906, -0.08206352, ...,  0.00243353,\n",
       "         -0.00642765,  0.03985669]], dtype=float32)>,\n",
       " <tf.Variable 'dense_9/bias:0' shape=(100,) dtype=float32, numpy=\n",
       " array([-1.09920176e-02, -7.02443952e-03,  4.99742758e-03, -7.00119045e-03,\n",
       "        -1.70314740e-02, -1.11086080e-02, -2.77765915e-02, -1.29712876e-02,\n",
       "        -1.30442884e-02,  5.88683528e-04,  1.49598327e-02,  2.69950461e-02,\n",
       "        -1.02777369e-02,  1.10220853e-02, -4.84432979e-03, -1.09322527e-02,\n",
       "        -1.58373564e-02,  2.97541358e-03, -1.10078985e-02,  8.73841904e-03,\n",
       "         6.99261110e-03,  1.33675849e-02,  1.50002586e-02, -1.11327628e-02,\n",
       "        -1.10052770e-03,  2.85501103e-03,  2.09964626e-02, -6.99228374e-03,\n",
       "        -3.00412579e-03, -1.70081723e-02, -8.95781908e-03,  2.91753057e-02,\n",
       "         1.89227927e-02, -2.42803413e-02,  2.47775335e-02,  2.65120436e-03,\n",
       "        -4.93071415e-03,  9.01438762e-03,  4.74166591e-03, -1.00516633e-03,\n",
       "         4.98732273e-03, -3.23079936e-02, -3.02741770e-03, -8.99909250e-03,\n",
       "        -2.99471547e-03, -1.09797614e-02, -1.07082883e-02,  5.76260267e-03,\n",
       "         1.22494204e-02, -3.09926365e-02,  2.11832505e-02, -1.47485062e-02,\n",
       "        -2.90653426e-02,  1.30118402e-02,  2.91539263e-02, -9.98903648e-04,\n",
       "        -1.70078333e-02, -3.69626358e-02,  1.46657582e-02, -1.90879516e-02,\n",
       "         1.54688060e-02,  2.50009205e-02, -1.63640436e-02, -4.59410716e-03,\n",
       "         2.13642493e-02,  2.04543509e-02,  2.97645642e-03, -1.04420527e-03,\n",
       "         1.01286126e-03,  1.09721655e-02, -1.89994406e-02, -9.77516524e-04,\n",
       "         2.30077486e-02,  2.69321967e-02, -6.08850177e-03,  5.00044413e-03,\n",
       "        -6.80642808e-03, -9.98278963e-04,  4.97166673e-03,  1.18053965e-02,\n",
       "         2.30003707e-02, -1.70108899e-02,  1.45533802e-02,  4.69248630e-02,\n",
       "         1.69789810e-02,  5.05353604e-03, -3.90653219e-03, -2.10087597e-02,\n",
       "        -2.48199701e-03, -3.87899973e-03,  1.91606814e-05, -5.08906972e-03,\n",
       "        -1.30157694e-02, -2.99046258e-03, -1.70367956e-02, -1.65706053e-02,\n",
       "        -2.78904885e-02, -1.51671469e-02,  1.29739223e-02,  1.69745348e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_10/kernel:0' shape=(100, 50) dtype=float32, numpy=\n",
       " array([[-6.15762919e-02,  1.87163457e-01,  1.63884848e-01, ...,\n",
       "         -1.25123203e-01, -5.31468429e-02,  1.93505548e-06],\n",
       "        [ 1.70747548e-01, -5.09303473e-02,  3.93049307e-02, ...,\n",
       "         -5.63874356e-02, -5.01175113e-02, -1.84272215e-01],\n",
       "        [ 1.93898126e-01, -1.96155950e-01, -9.39192064e-03, ...,\n",
       "          2.24302784e-02,  1.20926134e-01, -9.22750831e-02],\n",
       "        ...,\n",
       "        [ 1.01047836e-01,  1.06722107e-02, -1.45142764e-01, ...,\n",
       "          7.92815611e-02, -6.55792281e-02, -1.17308639e-01],\n",
       "        [-2.13816576e-02, -1.15621984e-02, -9.86242741e-02, ...,\n",
       "          1.33321032e-01,  3.98286544e-02, -9.65003297e-03],\n",
       "        [ 1.98060852e-02, -7.34437481e-02, -1.99758887e-01, ...,\n",
       "         -1.97785705e-01, -3.29191126e-02,  4.21982743e-02]], dtype=float32)>,\n",
       " <tf.Variable 'dense_10/bias:0' shape=(50,) dtype=float32, numpy=\n",
       " array([-0.01697478, -0.00297951,  0.0070524 ,  0.0070093 , -0.00499708,\n",
       "         0.00879664, -0.01102493, -0.008972  , -0.0009462 ,  0.00504102,\n",
       "         0.0049489 , -0.00499632,  0.00455178,  0.00097825, -0.00105508,\n",
       "        -0.00300483, -0.00104808,  0.00301256, -0.00500358,  0.00084135,\n",
       "        -0.01890898, -0.00898503,  0.00910064,  0.00540398, -0.00298116,\n",
       "        -0.00903174, -0.00501219,  0.00699481, -0.01491246,  0.01099164,\n",
       "         0.0110804 ,  0.00700308, -0.0190448 , -0.00901093, -0.01498612,\n",
       "         0.00477951, -0.00298632,  0.00900221, -0.00492985, -0.00899597,\n",
       "        -0.0090952 , -0.00500707, -0.00301399,  0.01299478, -0.00298401,\n",
       "         0.00301792,  0.0049917 ,  0.01098849, -0.00298645, -0.00103462],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_11/kernel:0' shape=(50, 2) dtype=float32, numpy=\n",
       " array([[ 0.2701499 ,  0.21209815],\n",
       "        [ 0.06591415,  0.0823993 ],\n",
       "        [-0.11904105, -0.14062153],\n",
       "        [-0.08341599, -0.07491831],\n",
       "        [-0.08236547, -0.02471917],\n",
       "        [-0.0489905 ,  0.1526391 ],\n",
       "        [ 0.08460157,  0.17667294],\n",
       "        [ 0.20175354,  0.28250027],\n",
       "        [ 0.11233854, -0.01922607],\n",
       "        [ 0.20838237,  0.13636976],\n",
       "        [-0.00386505, -0.08153541],\n",
       "        [ 0.14864518, -0.07805864],\n",
       "        [-0.22098018, -0.11067681],\n",
       "        [ 0.27364245,  0.27712825],\n",
       "        [ 0.00265651,  0.11562445],\n",
       "        [-0.11142208,  0.17838375],\n",
       "        [ 0.08134647,  0.18431993],\n",
       "        [ 0.01279355,  0.13493733],\n",
       "        [ 0.12615184, -0.17950235],\n",
       "        [-0.07171988, -0.21437995],\n",
       "        [-0.28971776, -0.16793686],\n",
       "        [ 0.1489978 ,  0.08850309],\n",
       "        [ 0.13141902,  0.25846255],\n",
       "        [-0.03557315, -0.05629339],\n",
       "        [-0.19003566, -0.24089016],\n",
       "        [-0.1854514 ,  0.02361647],\n",
       "        [-0.077401  ,  0.07707189],\n",
       "        [-0.16517776,  0.09881308],\n",
       "        [ 0.28562543, -0.06115953],\n",
       "        [ 0.19071187,  0.13808022],\n",
       "        [ 0.3185555 ,  0.24093944],\n",
       "        [-0.18906507,  0.01081243],\n",
       "        [-0.08611169, -0.14590013],\n",
       "        [-0.01205457,  0.07993888],\n",
       "        [-0.02681652,  0.21996988],\n",
       "        [ 0.14147387, -0.00185051],\n",
       "        [-0.15379465,  0.1816707 ],\n",
       "        [-0.00861316, -0.16820209],\n",
       "        [ 0.24167013, -0.13570584],\n",
       "        [ 0.06998926,  0.02135745],\n",
       "        [-0.22860694, -0.2227045 ],\n",
       "        [ 0.01688906, -0.09933383],\n",
       "        [ 0.17709437,  0.20878048],\n",
       "        [ 0.26214644, -0.00210449],\n",
       "        [ 0.2020024 ,  0.11997496],\n",
       "        [-0.19021648,  0.18715867],\n",
       "        [-0.13617061,  0.15006095],\n",
       "        [-0.01895748, -0.24178599],\n",
       "        [ 0.16455217,  0.21362552],\n",
       "        [-0.0553448 ,  0.05123873]], dtype=float32)>,\n",
       " <tf.Variable 'dense_11/bias:0' shape=(2,) dtype=float32, numpy=array([ 0.01876623, -0.01876616], dtype=float32)>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update weights from batches\n",
    "\n",
    "for bs, (images, labels) in enumerate(train_ds):\n",
    "    # time test\n",
    "    print(bs)\n",
    "    model.update_weights(images, network[bs], labels, 0.001)\n",
    "    if bs >= 10:\n",
    "        break\n",
    "\n",
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
