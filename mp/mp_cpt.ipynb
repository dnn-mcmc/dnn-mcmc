{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8cf4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.math as tm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427736f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_zero_one(x):\n",
    "    \n",
    "    t = [tf.math.sigmoid(i) for i in x]    \n",
    "    return t\n",
    "\n",
    "def cont_bern_log_norm(lam, l_lim=0.49, u_lim=0.51):\n",
    "    '''\n",
    "    computes the log normalizing constant of a continuous Bernoulli distribution in a numerically stable way.\n",
    "    returns the log normalizing constant for lam in (0, l_lim) U (u_lim, 1) and a Taylor approximation in\n",
    "    [l_lim, u_lim].\n",
    "    cut_y below might appear useless, but it is important to not evaluate log_norm near 0.5 as tf.where evaluates\n",
    "    both options, regardless of the value of the condition.\n",
    "    '''\n",
    "    \n",
    "    cut_lam = tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), lam, l_lim * tf.ones_like(lam))\n",
    "    log_norm = tm.log(tm.abs(2.0 * tm.atanh(1 - 2.0 * cut_lam))) - tm.log(tm.abs(1 - 2.0 * cut_lam))\n",
    "    taylor = tm.log(2.0) + 4.0 / 3.0 * tm.pow(lam - 0.5, 2) + 104.0 / 45.0 * tm.pow(lam - 0.5, 4)\n",
    "    return tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), log_norm, taylor)\n",
    "\n",
    "def bin_bits(x, n_bits):\n",
    "    \n",
    "    binx = []\n",
    "    for i in range(n_bits):\n",
    "        binx = [x % 2] + binx\n",
    "        x //= 2\n",
    "    return binx\n",
    "\n",
    "def get_ls(x, n_bits):\n",
    "    \n",
    "    n = 2**n_bits\n",
    "    l = n//(2**(x+1))\n",
    "    false_ls = []\n",
    "    true_ls = []\n",
    "    \n",
    "    for i in range(0, n//l, 2):\n",
    "        false_ls.extend(list(range(i*l, (i+1)*l)))\n",
    "        true_ls.extend(list(range((i+1)*l, (i+2)*l)))\n",
    "    \n",
    "    return false_ls, true_ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "26be92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBN(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes = [4, 4], n_outputs = 1, learning_rate = 0.01):\n",
    "        '''\n",
    "        initialize the loopy belief network and the optimizer.\n",
    "        '''\n",
    "        \n",
    "        super(LBN, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.hidden_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.n_outputs = n_outputs\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "        self.optimizer = tf.keras.optimizers.SGD(learning_rate = learning_rate)\n",
    "        \n",
    "        # initial CPTs for all the nodes (hidden nodes and output node)\n",
    "        # Each node in first hidden layer needs 2 cells (They have evidence from input nodes.)\n",
    "        # Nodes in other layers need 2^(#nodes of last layer) cells\n",
    "        # With N hidden layers, cpts have N+1 layers (include output layer) \n",
    "        # p_trues have N (only for hidden layers) \n",
    "        \n",
    "        all_layer_sizes = [0] + hidden_layer_sizes + [n_outputs]\n",
    "        self.cpts = [np.zeros([layer_size, 2**(last_layer_size + 1)], dtype = \"float\") for layer_size, \n",
    "                         last_layer_size in zip(all_layer_sizes[1:], all_layer_sizes[:-1])]\n",
    "        \n",
    "        self.p_trues = [np.zeros([layer_size, 2], dtype = \"float\") for layer_size \n",
    "                            in hidden_layer_sizes]\n",
    "        \n",
    "    def call(self, x):\n",
    "        '''\n",
    "        initialize the weights of the NN and calculate CPTs\n",
    "        '''\n",
    "        \n",
    "        all_layers = self.hidden_layers + [self.output_layer]\n",
    "        input_nodes = x\n",
    "        \n",
    "        # initialize weights\n",
    "        for layer in all_layers:\n",
    "            logits = layer(x)\n",
    "            x = tm.sigmoid(logits)\n",
    "        \n",
    "        # initialize cpts\n",
    "        # 0 = false, 1 = true\n",
    "        probs = tm.sigmoid(all_layers[0](input_nodes))[0].numpy()\n",
    "        self.cpts[0][:, 0] = 1 - probs\n",
    "        self.cpts[0][:, 1] = probs\n",
    "        \n",
    "        for i, (last_layer_size, layer) in enumerate(zip(self.hidden_layer_sizes, all_layers[1:])):\n",
    "            \n",
    "            n_cells = 2**last_layer_size\n",
    "            for j in range(n_cells):\n",
    "                nodes = np.array([bin_bits(j, last_layer_size)])\n",
    "                probs = tm.sigmoid(layer(nodes))[0].numpy()\n",
    "                self.cpts[i + 1][:, j] = 1 - probs\n",
    "                self.cpts[i + 1][:, j + n_cells] = probs\n",
    "\n",
    "    def mp(self, y):\n",
    "        '''\n",
    "        message passing, including forward passing and backward passing\n",
    "        '''\n",
    "                \n",
    "        # forward passing\n",
    "        last_layer_sizes = [0] + self.hidden_layer_sizes\n",
    "        n_layer = len(self.hidden_layers)\n",
    "        \n",
    "        for i, last_layer_size in enumerate(last_layer_sizes):\n",
    "            \n",
    "            # first hidden layer \n",
    "            if i == 0: \n",
    "                self.p_trues[i] = self.cpts[i]\n",
    "            else:\n",
    "                n_cells = 2**last_layer_size\n",
    "                for j in range(n_cells):\n",
    "                    nodes = bin_bits(j, last_layer_size)\n",
    "                    messages = [self.p_trues[i - 1][k, flag] for k, flag in enumerate(nodes)]\n",
    "                    tot_message = np.prod(messages)\n",
    "                    self.cpts[i][:, j] *= tot_message\n",
    "                    self.cpts[i][:, j + n_cells] *= tot_message\n",
    "            \n",
    "                # output layer\n",
    "                if i == n_layer:\n",
    "                    # get message from the observation\n",
    "                    if y == 0: self.cpts[i] = self.cpts[i][:, :n_cells]\n",
    "                    if y == 1: self.cpts[i] = self.cpts[i][:, n_cells:]        \n",
    "                else:\n",
    "                    p_true = np.sum(self.cpts[i][:, :n_cells], axis = 1)\n",
    "                    p_false = np.sum(self.cpts[i][:, n_cells:], axis = 1)\n",
    "                    self.p_trues[i][:, 0] = p_false / (p_true + p_false)\n",
    "                    self.p_trues[i][:, 1] = p_true / (p_true + p_false)\n",
    "                \n",
    "        \n",
    "        # backward passing\n",
    "        \n",
    "        curr_sizes = self.hidden_layer_sizes[::-1]\n",
    "        #next_sizes = [self.n_outputs] + self.hidden_layer_sizes[:0:-1]\n",
    "        #print(curr_sizes)\n",
    "        \n",
    "        \n",
    "        for i, curr_size in enumerate(curr_sizes):\n",
    "            \n",
    "            # current layer number\n",
    "            curr_id = n_layer - i - 1 \n",
    "            \n",
    "            for j in range(curr_size):\n",
    "                \n",
    "                # get messages from next layer\n",
    "                f_cells, t_cells = get_ls(j, curr_size)\n",
    "                \n",
    "                if i != 0: # not the last hidden layer\n",
    "                    ff_cells = [x + 2**curr_size for x in f_cells]\n",
    "                    f_cells.extend(ff_cells)\n",
    "                    \n",
    "                    tt_cells = [x + 2**curr_size for x in t_cells]\n",
    "                    t_cells.extend(tt_cells)\n",
    "                \n",
    "                p_true = np.sum(self.cpts[curr_id + 1][:, t_cells], axis = 1) / self.p_trues[curr_id][j, 1]\n",
    "                p_false = np.sum(self.cpts[curr_id + 1][:, f_cells], axis = 1) / self.p_trues[curr_id][j, 0]\n",
    "                message_true = np.prod(p_true)\n",
    "                message_false = np.prod(p_false)\n",
    "                \n",
    "                n_cells = self.cpts[i].shape[1] // 2\n",
    "                self.cpts[i][j, :n_cells] *= message_false\n",
    "                self.cpts[i][j, n_cells:] *= message_true\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3e2f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "nn = LBN(hidden_layer_sizes = [2, 2], n_outputs = 1, learning_rate = 0.01)\n",
    "print(nn.cpts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "298d4b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,0]])\n",
    "y = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd654957",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9105e3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([array([[0.32601833, 0.67398167],\n",
       "       [0.46811044, 0.53188956]]), array([[0.5       , 0.35928935, 0.25800598, 0.16317272, 0.5       ,\n",
       "        0.64071065, 0.74199402, 0.83682728],\n",
       "       [0.5       , 0.63740325, 0.7709558 , 0.8554284 , 0.5       ,\n",
       "        0.36259675, 0.22904417, 0.1445716 ]]), array([[0.5       , 0.52978426, 0.277807  , 0.30235946, 0.5       ,\n",
       "        0.47021574, 0.722193  , 0.69764054]])])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "910f5ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([array([[0., 0.],\n",
       "       [0., 0.]]), array([[0., 0.],\n",
       "       [0., 0.]])])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.p_trues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e33bbfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "nn.mp(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f498361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListWrapper([array([[0.26640116, 0.26368794],\n",
       "       [0.29639798, 0.1478194 ]]), array([[0.40944883, 0.16058854, 0.75907189, 0.26993928, 0.77564417,\n",
       "        0.169211  , 0.675426  , 0.1336017 ],\n",
       "       [3.70483624, 1.2103338 , 5.67742828, 1.83858099, 1.2725838 ,\n",
       "        0.36099619, 1.51722998, 0.42664102]]), array([[0.08358126, 0.14718558, 0.09277467, 0.19680356]])])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.cpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "b=[1,3]\n",
    "c=[0,2]\n",
    "np.sum(a[:, b], axis = 1) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c0f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c3d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
