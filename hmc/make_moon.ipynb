{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.math as tm\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "X, Y = make_moons(200, noise = 0.1)\n",
    "\n",
    "# Split into test and training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=73)\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(*x_train[y_train.flatten() == 1, :].T)\n",
    "plt.scatter(*x_train[y_train.flatten() == 0, :].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (150, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard BP\n",
    "model_bp = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(2,)),\n",
    "        layers.Dense(100, activation = \"sigmoid\"),\n",
    "        #layers.Dense(50, activation = \"sigmoid\"),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "model_bp.summary()\n",
    "#model_bp.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "st = time.time()\n",
    "model_bp.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model_bp.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_zero_one(x):\n",
    "    \n",
    "    t = [tm.sigmoid(i) for i in x]\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerange(x, r = 6.0):\n",
    "    \n",
    "    out_of_range = tf.cast(tm.greater(tm.abs(x), r), tf.float32)\n",
    "    sign = tm.sign(x)\n",
    "    \n",
    "    return x * (1 - out_of_range) + sign * r * out_of_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_bern_log_norm(lam, l_lim=0.49, u_lim=0.51):\n",
    "    '''\n",
    "    computes the log normalizing constant of a continuous Bernoulli distribution in a numerically stable way.\n",
    "    returns the log normalizing constant for lam in (0, l_lim) U (u_lim, 1) and a Taylor approximation in\n",
    "    [l_lim, u_lim].\n",
    "    cut_y below might appear useless, but it is important to not evaluate log_norm near 0.5 as tf.where evaluates\n",
    "    both options, regardless of the value of the condition.\n",
    "    '''\n",
    "    \n",
    "    cut_lam = tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), lam, l_lim * tf.ones_like(lam))\n",
    "    log_norm = tm.log(tm.abs(2.0 * tm.atanh(1 - 2.0 * cut_lam))) - tm.log(tm.abs(1 - 2.0 * cut_lam))\n",
    "    taylor = tm.log(2.0) + 4.0 / 3.0 * tm.pow(lam - 0.5, 2) + 104.0 / 45.0 * tm.pow(lam - 0.5, 4)\n",
    "    return tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), log_norm, taylor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        #x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        h_current = convert2_zero_one([tf.cast(h_i, dtype=tf.float32) for h_i in h])\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "    \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            logits = layer(pv)\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=logits)\n",
    "            \n",
    "            ce += cont_bern_log_norm(tf.nn.sigmoid(logits))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "\n",
    "        h_current = convert2_zero_one(tf.split(h, self.hidden_layer_sizes, axis = 1))\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            logits = layer(pv)\n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=logits)\n",
    "            \n",
    "            ce += cont_bern_log_norm(tf.nn.sigmoid(logits))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def generate_hmc_kernel(self, x, y, step_size = pow(1000, -1/4)):\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = step_size),\n",
    "            num_adaptation_steps=int(100 * 0.8))\n",
    "        \n",
    "        return adaptive_hmc\n",
    "    \n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y, hmc_kernel, is_update_kernel = True):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concat(h_current, axis = 1)\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_burnin_steps = 0\n",
    "        num_results = 1\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            trace_fn = None,\n",
    "            return_final_kernel_results = True)\n",
    "    \n",
    "        # Generate new states of chains\n",
    "        #h_state = rerange(samples[0][0])\n",
    "        h_state = samples[0][0]\n",
    "        h_new = tf.split(h_state, self.hidden_layer_sizes, axis = 1) \n",
    "        \n",
    "        # Update the kernel if necesssary\n",
    "        if is_update_kernel:\n",
    "            new_step_size = samples[2].new_step_size.numpy()\n",
    "            ker_new = self.generate_hmc_kernel(x, y, new_step_size)\n",
    "            return(h_new, ker_new)\n",
    "        else:\n",
    "            return h_new\n",
    "    \n",
    "    def update_weights(self, x, h, y, lr = 0.1):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "\n",
    "        logits = 0.0\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tm.sigmoid(logits)\n",
    "        \n",
    "        logits = self.output_layer(x)\n",
    "        probs = tm.sigmoid(logits)\n",
    "        #print(probs)\n",
    "        labels = tf.cast(tm.greater(probs, 0.5), tf.int32)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [100], n_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = [model.call(x) for x, y in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [model.generate_hmc_kernel(x, y) for x, y in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "CPU times: user 1min 10s, sys: 859 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "burnin = 500\n",
    "for i in range(burnin):\n",
    "    \n",
    "    if(i % 100 == 0): print(\"Step %d\" % i)\n",
    "        \n",
    "    network_new = []\n",
    "    kernels_new = []\n",
    "    \n",
    "    res = [model.propose_new_state_hamiltonian(x, net, y, ker) \n",
    "               for (x, y), net, ker in zip(train_ds, network, kernels)]\n",
    "    \n",
    "    network_new, kernels_new = zip(*res)\n",
    "         \n",
    "    network = network_new\n",
    "    kernels = kernels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(32, 100), dtype=float32, numpy=\n",
      "array([[-353.09763 , -480.7659  , -248.21957 , ..., -227.4209  ,\n",
      "         -20.72667 ,  278.59558 ],\n",
      "       [ -25.334011,  423.945   , -214.96654 , ...,   78.27854 ,\n",
      "        -239.08904 ,  365.50577 ],\n",
      "       [-254.05093 ,   17.78176 , -736.2611  , ..., -195.07812 ,\n",
      "        -201.33344 , -380.09515 ],\n",
      "       ...,\n",
      "       [ 399.5531  , -184.6452  , -145.47342 , ..., -368.80072 ,\n",
      "          32.707024,   14.626984],\n",
      "       [ 102.313354, -438.1059  ,  424.2397  , ..., -334.101   ,\n",
      "        -295.98138 ,  -77.21953 ],\n",
      "       [ 644.9836  ,  408.20123 ,  185.26974 , ...,  158.24371 ,\n",
      "         163.33359 ,  727.41113 ]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(network[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: - 0.9430s/step - loss: 694.5419 - accuracy: 0.5133\n",
      "Epoch 2/1000: - 0.8905s/step - loss: 693.9839 - accuracy: 0.5133\n",
      "Epoch 3/1000: - 0.8632s/step - loss: 693.6526 - accuracy: 0.5133\n",
      "Epoch 4/1000: - 0.8364s/step - loss: 693.4288 - accuracy: 0.6000\n",
      "Epoch 5/1000: - 0.8209s/step - loss: 693.0852 - accuracy: 0.5133\n",
      "Epoch 6/1000: - 0.8087s/step - loss: 692.9448 - accuracy: 0.5000\n",
      "Epoch 7/1000: - 0.7995s/step - loss: 692.7964 - accuracy: 0.6000\n",
      "Epoch 8/1000: - 0.8088s/step - loss: 692.6230 - accuracy: 0.5667\n",
      "Epoch 9/1000: - 0.8036s/step - loss: 692.4446 - accuracy: 0.6400\n",
      "Epoch 10/1000: - 0.7986s/step - loss: 692.2433 - accuracy: 0.7067\n",
      "Epoch 11/1000: - 0.7934s/step - loss: 692.1597 - accuracy: 0.7733\n",
      "Epoch 12/1000: - 0.7891s/step - loss: 692.0814 - accuracy: 0.8000\n",
      "Epoch 13/1000: - 0.7927s/step - loss: 691.9809 - accuracy: 0.8000\n",
      "Epoch 14/1000: - 0.7907s/step - loss: 691.9734 - accuracy: 0.8000\n",
      "Epoch 15/1000: - 0.7906s/step - loss: 692.1539 - accuracy: 0.8000\n",
      "Epoch 16/1000: - 0.7950s/step - loss: 692.1616 - accuracy: 0.8267\n",
      "Epoch 17/1000: - 0.7981s/step - loss: 692.0241 - accuracy: 0.7867\n",
      "Epoch 18/1000: - 0.8030s/step - loss: 691.5986 - accuracy: 0.8000\n",
      "Epoch 19/1000: - 0.8062s/step - loss: 691.6382 - accuracy: 0.8267\n",
      "Epoch 20/1000: - 0.8070s/step - loss: 691.6943 - accuracy: 0.8467\n",
      "Epoch 21/1000: - 0.8062s/step - loss: 691.4835 - accuracy: 0.8133\n",
      "Epoch 22/1000: - 0.8061s/step - loss: 691.4908 - accuracy: 0.8467\n",
      "Epoch 23/1000: - 0.8084s/step - loss: 691.1970 - accuracy: 0.8467\n",
      "Epoch 24/1000: - 0.8096s/step - loss: 691.2168 - accuracy: 0.8067\n",
      "Epoch 25/1000: - 0.8129s/step - loss: 691.2676 - accuracy: 0.8133\n",
      "Epoch 26/1000: - 0.8119s/step - loss: 691.2156 - accuracy: 0.8200\n",
      "Epoch 27/1000: - 0.8134s/step - loss: 690.9476 - accuracy: 0.8267\n",
      "Epoch 28/1000: - 0.8160s/step - loss: 690.6829 - accuracy: 0.8067\n",
      "Epoch 29/1000: - 0.8178s/step - loss: 691.1835 - accuracy: 0.8200\n",
      "Epoch 30/1000: - 0.8223s/step - loss: 690.8611 - accuracy: 0.8133\n",
      "Epoch 31/1000: - 0.8224s/step - loss: 690.3835 - accuracy: 0.8067\n",
      "Epoch 32/1000: - 0.8223s/step - loss: 690.4431 - accuracy: 0.8133\n",
      "Epoch 33/1000: - 0.8231s/step - loss: 690.1361 - accuracy: 0.8067\n",
      "Epoch 34/1000: - 0.8224s/step - loss: 690.1860 - accuracy: 0.8067\n",
      "Epoch 35/1000: - 0.8225s/step - loss: 690.2667 - accuracy: 0.8200\n",
      "Epoch 36/1000: - 0.8220s/step - loss: 690.2834 - accuracy: 0.8333\n",
      "Epoch 37/1000: - 0.8225s/step - loss: 690.1083 - accuracy: 0.8200\n",
      "Epoch 38/1000: - 0.8242s/step - loss: 690.1080 - accuracy: 0.8400\n",
      "Epoch 39/1000: - 0.8240s/step - loss: 689.9183 - accuracy: 0.8333\n",
      "Epoch 40/1000: - 0.8249s/step - loss: 689.9327 - accuracy: 0.8333\n",
      "Epoch 41/1000: - 0.8253s/step - loss: 690.1327 - accuracy: 0.8467\n",
      "Epoch 42/1000: - 0.8262s/step - loss: 690.0377 - accuracy: 0.8333\n",
      "Epoch 43/1000: - 0.8262s/step - loss: 690.0622 - accuracy: 0.8333\n",
      "Epoch 44/1000: - 0.8259s/step - loss: 689.9397 - accuracy: 0.8400\n",
      "Epoch 45/1000: - 0.8260s/step - loss: 689.8235 - accuracy: 0.8333\n",
      "Epoch 46/1000: - 0.8249s/step - loss: 689.7227 - accuracy: 0.8333\n",
      "Epoch 47/1000: - 0.8238s/step - loss: 689.8165 - accuracy: 0.8467\n",
      "Epoch 48/1000: - 0.8225s/step - loss: 689.5137 - accuracy: 0.8333\n",
      "Epoch 49/1000: - 0.8219s/step - loss: 689.4923 - accuracy: 0.8533\n",
      "Epoch 50/1000: - 0.8206s/step - loss: 689.4954 - accuracy: 0.8467\n",
      "Epoch 51/1000: - 0.8191s/step - loss: 689.3191 - accuracy: 0.8533\n",
      "Epoch 52/1000: - 0.8187s/step - loss: 689.0474 - accuracy: 0.8467\n",
      "Epoch 53/1000: - 0.8179s/step - loss: 689.2438 - accuracy: 0.8333\n",
      "Epoch 54/1000: - 0.8170s/step - loss: 689.1619 - accuracy: 0.8533\n",
      "Epoch 55/1000: - 0.8156s/step - loss: 688.9977 - accuracy: 0.8467\n",
      "Epoch 56/1000: - 0.8152s/step - loss: 689.1751 - accuracy: 0.8467\n",
      "Epoch 57/1000: - 0.8143s/step - loss: 688.7817 - accuracy: 0.8400\n",
      "Epoch 58/1000: - 0.8134s/step - loss: 688.9789 - accuracy: 0.8400\n",
      "Epoch 59/1000: - 0.8127s/step - loss: 688.9824 - accuracy: 0.8400\n",
      "Epoch 60/1000: - 0.8120s/step - loss: 688.9825 - accuracy: 0.8467\n",
      "Epoch 61/1000: - 0.8113s/step - loss: 688.7589 - accuracy: 0.8467\n",
      "Epoch 62/1000: - 0.8106s/step - loss: 689.0692 - accuracy: 0.8467\n",
      "Epoch 63/1000: - 0.8103s/step - loss: 689.2543 - accuracy: 0.8533\n",
      "Epoch 64/1000: - 0.8096s/step - loss: 688.9421 - accuracy: 0.8400\n",
      "Epoch 65/1000: - 0.8090s/step - loss: 689.0111 - accuracy: 0.8533\n",
      "Epoch 66/1000: - 0.8081s/step - loss: 688.8403 - accuracy: 0.8533\n",
      "Epoch 67/1000: - 0.8077s/step - loss: 688.7441 - accuracy: 0.8533\n",
      "Epoch 68/1000: - 0.8070s/step - loss: 688.7146 - accuracy: 0.8467\n",
      "Epoch 69/1000: - 0.8063s/step - loss: 688.4646 - accuracy: 0.8533\n",
      "Epoch 70/1000: - 0.8058s/step - loss: 688.0953 - accuracy: 0.8533\n",
      "Epoch 71/1000: - 0.8056s/step - loss: 688.1273 - accuracy: 0.8467\n",
      "Epoch 72/1000: - 0.8054s/step - loss: 688.3380 - accuracy: 0.8467\n",
      "Epoch 73/1000: - 0.8046s/step - loss: 688.4640 - accuracy: 0.8400\n",
      "Epoch 74/1000: - 0.8039s/step - loss: 688.3157 - accuracy: 0.8467\n",
      "Epoch 75/1000: - 0.8035s/step - loss: 688.4054 - accuracy: 0.8533\n",
      "Epoch 76/1000: - 0.8030s/step - loss: 688.1866 - accuracy: 0.8333\n",
      "Epoch 77/1000: - 0.8026s/step - loss: 688.2070 - accuracy: 0.8533\n",
      "Epoch 78/1000: - 0.8024s/step - loss: 688.2208 - accuracy: 0.8533\n",
      "Epoch 79/1000: - 0.8022s/step - loss: 688.1802 - accuracy: 0.8533\n",
      "Epoch 80/1000: - 0.8017s/step - loss: 688.0597 - accuracy: 0.8533\n",
      "Epoch 81/1000: - 0.8014s/step - loss: 687.9955 - accuracy: 0.8600\n",
      "Epoch 82/1000: - 0.8017s/step - loss: 688.0171 - accuracy: 0.8600\n",
      "Epoch 83/1000: - 0.8012s/step - loss: 687.9691 - accuracy: 0.8667\n",
      "Epoch 84/1000: - 0.8014s/step - loss: 688.0154 - accuracy: 0.8600\n",
      "Epoch 85/1000: - 0.8014s/step - loss: 687.9049 - accuracy: 0.8600\n",
      "Epoch 86/1000: - 0.8009s/step - loss: 687.7145 - accuracy: 0.8600\n",
      "Epoch 87/1000: - 0.8004s/step - loss: 688.0225 - accuracy: 0.8600\n",
      "Epoch 88/1000: - 0.8001s/step - loss: 687.9515 - accuracy: 0.8667\n",
      "Epoch 89/1000: - 0.7997s/step - loss: 687.8715 - accuracy: 0.8667\n",
      "Epoch 90/1000: - 0.7991s/step - loss: 687.4214 - accuracy: 0.8600\n",
      "Epoch 91/1000: - 0.7989s/step - loss: 687.5980 - accuracy: 0.8600\n",
      "Epoch 92/1000: - 0.7989s/step - loss: 687.6323 - accuracy: 0.8600\n",
      "Epoch 93/1000: - 0.7986s/step - loss: 687.8441 - accuracy: 0.8600\n",
      "Epoch 94/1000: - 0.7981s/step - loss: 688.0568 - accuracy: 0.8600\n",
      "Epoch 95/1000: - 0.7977s/step - loss: 688.0263 - accuracy: 0.8600\n",
      "Epoch 96/1000: - 0.7974s/step - loss: 687.7626 - accuracy: 0.8667\n",
      "Epoch 97/1000: - 0.7970s/step - loss: 688.0471 - accuracy: 0.8667\n",
      "Epoch 98/1000: - 0.7966s/step - loss: 688.2386 - accuracy: 0.8667\n",
      "Epoch 99/1000: - 0.7964s/step - loss: 688.2162 - accuracy: 0.8600\n",
      "Epoch 100/1000: - 0.7962s/step - loss: 687.9764 - accuracy: 0.8667\n",
      "Epoch 101/1000: - 0.7960s/step - loss: 687.9288 - accuracy: 0.8667\n",
      "Epoch 102/1000: - 0.7956s/step - loss: 688.0013 - accuracy: 0.8600\n",
      "Epoch 103/1000: - 0.7953s/step - loss: 688.2386 - accuracy: 0.8667\n",
      "Epoch 104/1000: - 0.7949s/step - loss: 688.3372 - accuracy: 0.8667\n",
      "Epoch 105/1000: - 0.7945s/step - loss: 688.0916 - accuracy: 0.8667\n",
      "Epoch 106/1000: - 0.7942s/step - loss: 688.0126 - accuracy: 0.8667\n",
      "Epoch 107/1000: - 0.7940s/step - loss: 687.8323 - accuracy: 0.8667\n",
      "Epoch 108/1000: - 0.7937s/step - loss: 687.4960 - accuracy: 0.8733\n",
      "Epoch 109/1000: - 0.7954s/step - loss: 687.9445 - accuracy: 0.8733\n",
      "Epoch 110/1000: - 0.7980s/step - loss: 687.8657 - accuracy: 0.8667\n",
      "Epoch 111/1000: - 0.7988s/step - loss: 687.6957 - accuracy: 0.8667\n",
      "Epoch 112/1000: - 0.7998s/step - loss: 687.6971 - accuracy: 0.8667\n",
      "Epoch 113/1000: - 0.8008s/step - loss: 687.5173 - accuracy: 0.8733\n",
      "Epoch 114/1000: - 0.8006s/step - loss: 687.5718 - accuracy: 0.8733\n",
      "Epoch 115/1000: - 0.8004s/step - loss: 687.6451 - accuracy: 0.8667\n",
      "Epoch 116/1000: - 0.8009s/step - loss: 687.8481 - accuracy: 0.8667\n",
      "Epoch 117/1000: - 0.8016s/step - loss: 687.4789 - accuracy: 0.8667\n",
      "Epoch 118/1000: - 0.8019s/step - loss: 687.4276 - accuracy: 0.8667\n",
      "Epoch 119/1000: - 0.8022s/step - loss: 687.3494 - accuracy: 0.8733\n",
      "Epoch 120/1000: - 0.8026s/step - loss: 687.4707 - accuracy: 0.8667\n",
      "Epoch 121/1000: - 0.8023s/step - loss: 687.1816 - accuracy: 0.8667\n",
      "Epoch 122/1000: - 0.8028s/step - loss: 687.1517 - accuracy: 0.8733\n",
      "Epoch 123/1000: - 0.8043s/step - loss: 687.2066 - accuracy: 0.8733\n",
      "Epoch 124/1000: - 0.8053s/step - loss: 686.9370 - accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000: - 0.8050s/step - loss: 686.9438 - accuracy: 0.8667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0763f7aba359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n\u001b[0;32m---> 13\u001b[0;31m                    for (x, y), net, ker in zip(train_ds, network, kernels)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0763f7aba359>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n\u001b[0;32m---> 13\u001b[0;31m                    for (x, y), net, ker in zip(train_ds, network, kernels)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-08cc8226ace7>\u001b[0m in \u001b[0;36mpropose_new_state_hamiltonian\u001b[0;34m(self, x, h, y, hmc_kernel, is_update_kernel)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtrace_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             return_final_kernel_results = True)\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Generate new states of chains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                             trace_fn(*state_and_results)),\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_final_kernel_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[0;34m(loop_fn, initial_state, elems, trace_fn, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mstacked_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_body\u001b[0;34m(i, state, trace_arrays)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       trace_arrays = tf.nest.pack_sequence_as(trace_arrays, [\n\u001b[1;32m    385\u001b[0m           a.write(i, v) for a, v in zip(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36m_trace_scan_fn\u001b[0;34m(state_and_results, num_steps)\u001b[0m\n\u001b[1;32m    341\u001b[0m           \u001b[0mbody_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m           \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_and_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m           parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    344\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36msmart_for_loop\u001b[0;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    314\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m       )[1:]\n\u001b[1;32m    318\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    312\u001b[0m       return tf.while_loop(\n\u001b[1;32m    313\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;31m# Step the inner kernel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       new_state, new_inner_results = self.inner_kernel.one_step(\n\u001b[0;32m--> 343\u001b[0;31m           current_state, inner_results)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m       \u001b[0;31m# Get the new step size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_step_size_assign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m       next_state, kernel_results = self._impl.one_step(\n\u001b[0;32m--> 547\u001b[0;31m           current_state, previous_kernel_results)\n\u001b[0m\u001b[1;32m    548\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         step_size_assign = self.step_size_update_fn(  # pylint: disable=not-callable\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m           \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m           previous_kernel_results.accepted_results)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       if (not has_target_log_prob(proposed_results) or\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    734\u001b[0m                      \u001b[0mcurrent_state_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                      \u001b[0mcurrent_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                      current_target_log_prob_grad_parts)\n\u001b[0m\u001b[1;32m    737\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_gradients_are_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mnext_state_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_state_parts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, momentum_parts, state_parts, target, target_grad_parts, name)\u001b[0m\n\u001b[1;32m    289\u001b[0m               \u001b[0mstate_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m               \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m               \u001b[0mtarget_grad_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m           ])\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n\u001b[0;32m--> 285\u001b[0;31m               self.target_fn, self.step_sizes, *args)),\n\u001b[0m\u001b[1;32m    286\u001b[0m           loop_vars=[\n\u001b[1;32m    287\u001b[0m               \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m_one_step\u001b[0;34m(target_fn, step_sizes, half_next_momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     [next_target, next_target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n\u001b[0;32m--> 326\u001b[0;31m         target_fn, next_state_parts)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_target_grad_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[1;32m    263\u001b[0m                    else [fn_arg_list])\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     if not all(dtype_util.is_floating(r.dtype)\n\u001b[1;32m    266\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    247\u001b[0m       ]\n\u001b[1;32m    248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp_math_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/math/gradient.py\u001b[0m in \u001b[0;36mvalue_and_gradient\u001b[0;34m(f, xs, output_gradients, use_gradient_tape, name)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0mdydx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-08cc8226ace7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mtarget_log_prob_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mnum_leapfrog_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             step_size = step_size),\n",
      "\u001b[0;32m<ipython-input-8-08cc8226ace7>\u001b[0m in \u001b[0;36mtarget_log_prob2\u001b[0;34m(self, x, h, y)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         fce = tf.nn.sigmoid_cross_entropy_with_logits(\n\u001b[0;32m---> 70\u001b[0;31m             labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mnlog_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m    239\u001b[0m   \"\"\"\n\u001b[1;32m    240\u001b[0m   return sigmoid_cross_entropy_with_logits(\n\u001b[0;32m--> 241\u001b[0;31m       logits=logits, labels=labels, name=name)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mneg_abs_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     return math_ops.add(\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mrelu_logits\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_abs_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for bs, (x, y) in enumerate(train_ds):\n",
    "        \n",
    "        # only one mini-batch\n",
    "        model.update_weights(x, network[bs], y, 0.1)\n",
    "        res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n",
    "                   for (x, y), net, ker in zip(train_ds, network, kernels)]\n",
    "        network = res\n",
    "        loss += -1 * tf.reduce_mean(model.target_log_prob(x, network[bs], y))\n",
    "    \n",
    "    preds = [model.get_predictions(images) for images, labels in train_ds]\n",
    "    train_acc = accuracy_score(np.concatenate(preds), y_train)\n",
    "    print(\"Epoch %d/%d: - %.4fs/step - loss: %.4f - accuracy: %.4f\" \n",
    "          % (epoch + 1, epochs, (time.time() - start_time) / (epoch + 1), loss, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
