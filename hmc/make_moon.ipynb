{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.math as tm\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "X, Y = make_moons(200, noise = 0.1)\n",
    "\n",
    "# Split into test and training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=73)\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(*x_train[y_train.flatten() == 1, :].T)\n",
    "plt.scatter(*x_train[y_train.flatten() == 0, :].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (150, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard BP\n",
    "model_bp = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(2,)),\n",
    "        layers.Dense(100, activation = \"sigmoid\"),\n",
    "        #layers.Dense(50, activation = \"sigmoid\"),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "model_bp.summary()\n",
    "#model_bp.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "batch_size = 32\n",
    "epochs = 1000\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "st = time.time()\n",
    "model_bp.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "model_bp.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_zero_one(x):\n",
    "    \n",
    "    t = [tm.sigmoid(i) for i in x]\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerange(x, r = 6.0):\n",
    "    \n",
    "    out_of_range = tf.cast(tm.greater(tm.abs(x), r), tf.float32)\n",
    "    sign = tm.sign(x)\n",
    "    \n",
    "    return x * (1 - out_of_range) + sign * r * out_of_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_bern_log_norm(lam, l_lim=0.49, u_lim=0.51):\n",
    "    '''\n",
    "    computes the log normalizing constant of a continuous Bernoulli distribution in a numerically stable way.\n",
    "    returns the log normalizing constant for lam in (0, l_lim) U (u_lim, 1) and a Taylor approximation in\n",
    "    [l_lim, u_lim].\n",
    "    cut_y below might appear useless, but it is important to not evaluate log_norm near 0.5 as tf.where evaluates\n",
    "    both options, regardless of the value of the condition.\n",
    "    '''\n",
    "    \n",
    "    cut_lam = tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), lam, l_lim * tf.ones_like(lam))\n",
    "    log_norm = tm.log(tm.abs(2.0 * tm.atanh(1 - 2.0 * cut_lam))) - tm.log(tm.abs(1 - 2.0 * cut_lam))\n",
    "    taylor = tm.log(2.0) + 4.0 / 3.0 * tm.pow(lam - 0.5, 2) + 104.0 / 45.0 * tm.pow(lam - 0.5, 4)\n",
    "    return tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), log_norm, taylor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        #x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        h_current = convert2_zero_one([tf.cast(h_i, dtype=tf.float32) for h_i in h])\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "    \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            logits = layer(pv)\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=logits)\n",
    "            \n",
    "            ce += cont_bern_log_norm(tf.nn.sigmoid(logits))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "\n",
    "        h_current = convert2_zero_one(tf.split(h, self.hidden_layer_sizes, axis = 1))\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            logits = layer(pv)\n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=logits)\n",
    "            \n",
    "            ce += cont_bern_log_norm(tf.nn.sigmoid(logits))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def generate_hmc_kernel(self, x, y, step_size = pow(1000, -1/4)):\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = step_size),\n",
    "            num_adaptation_steps=int(100 * 0.8))\n",
    "        \n",
    "        return adaptive_hmc\n",
    "    \n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y, hmc_kernel, is_update_kernel = True):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concat(h_current, axis = 1)\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_burnin_steps = 0\n",
    "        num_results = 1\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            trace_fn = None,\n",
    "            return_final_kernel_results = True)\n",
    "    \n",
    "        # Generate new states of chains\n",
    "        #h_state = rerange(samples[0][0])\n",
    "        h_state = samples[0][0]\n",
    "        h_new = tf.split(h_state, self.hidden_layer_sizes, axis = 1) \n",
    "        \n",
    "        # Update the kernel if necesssary\n",
    "        if is_update_kernel:\n",
    "            new_step_size = samples[2].new_step_size.numpy()\n",
    "            ker_new = self.generate_hmc_kernel(x, y, new_step_size)\n",
    "            return(h_new, ker_new)\n",
    "        else:\n",
    "            return h_new\n",
    "    \n",
    "    def update_weights(self, x, h, y, lr = 0.1):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "\n",
    "        logits = 0.0\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tm.sigmoid(logits)\n",
    "        \n",
    "        logits = self.output_layer(x)\n",
    "        probs = tm.sigmoid(logits)\n",
    "        #print(probs)\n",
    "        labels = tf.cast(tm.greater(probs, 0.5), tf.int32)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [100], n_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [model.call(x) for x, y in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [model.generate_hmc_kernel(x, y) for x, y in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 100\n",
      "Step 200\n",
      "Step 300\n",
      "Step 400\n",
      "CPU times: user 1min 10s, sys: 859 ms, total: 1min 11s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "burnin = 500\n",
    "for i in range(burnin):\n",
    "    \n",
    "    if(i % 100 == 0): print(\"Step %d\" % i)\n",
    "        \n",
    "    network_new = []\n",
    "    kernels_new = []\n",
    "    \n",
    "    res = [model.propose_new_state_hamiltonian(x, net, y, ker) \n",
    "               for (x, y), net, ker in zip(train_ds, network, kernels)]\n",
    "    \n",
    "    network_new, kernels_new = zip(*res)\n",
    "         \n",
    "    network = network_new\n",
    "    kernels = kernels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(32, 100), dtype=float32, numpy=\n",
      "array([[-353.09763 , -480.7659  , -248.21957 , ..., -227.4209  ,\n",
      "         -20.72667 ,  278.59558 ],\n",
      "       [ -25.334011,  423.945   , -214.96654 , ...,   78.27854 ,\n",
      "        -239.08904 ,  365.50577 ],\n",
      "       [-254.05093 ,   17.78176 , -736.2611  , ..., -195.07812 ,\n",
      "        -201.33344 , -380.09515 ],\n",
      "       ...,\n",
      "       [ 399.5531  , -184.6452  , -145.47342 , ..., -368.80072 ,\n",
      "          32.707024,   14.626984],\n",
      "       [ 102.313354, -438.1059  ,  424.2397  , ..., -334.101   ,\n",
      "        -295.98138 ,  -77.21953 ],\n",
      "       [ 644.9836  ,  408.20123 ,  185.26974 , ...,  158.24371 ,\n",
      "         163.33359 ,  727.41113 ]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(network[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: - 0.9430s/step - loss: 694.5419 - accuracy: 0.5133\n",
      "Epoch 2/1000: - 0.8905s/step - loss: 693.9839 - accuracy: 0.5133\n",
      "Epoch 3/1000: - 0.8632s/step - loss: 693.6526 - accuracy: 0.5133\n",
      "Epoch 4/1000: - 0.8364s/step - loss: 693.4288 - accuracy: 0.6000\n",
      "Epoch 5/1000: - 0.8209s/step - loss: 693.0852 - accuracy: 0.5133\n",
      "Epoch 6/1000: - 0.8087s/step - loss: 692.9448 - accuracy: 0.5000\n",
      "Epoch 7/1000: - 0.7995s/step - loss: 692.7964 - accuracy: 0.6000\n",
      "Epoch 8/1000: - 0.8088s/step - loss: 692.6230 - accuracy: 0.5667\n",
      "Epoch 9/1000: - 0.8036s/step - loss: 692.4446 - accuracy: 0.6400\n",
      "Epoch 10/1000: - 0.7986s/step - loss: 692.2433 - accuracy: 0.7067\n",
      "Epoch 11/1000: - 0.7934s/step - loss: 692.1597 - accuracy: 0.7733\n",
      "Epoch 12/1000: - 0.7891s/step - loss: 692.0814 - accuracy: 0.8000\n",
      "Epoch 13/1000: - 0.7927s/step - loss: 691.9809 - accuracy: 0.8000\n",
      "Epoch 14/1000: - 0.7907s/step - loss: 691.9734 - accuracy: 0.8000\n",
      "Epoch 15/1000: - 0.7906s/step - loss: 692.1539 - accuracy: 0.8000\n",
      "Epoch 16/1000: - 0.7950s/step - loss: 692.1616 - accuracy: 0.8267\n",
      "Epoch 17/1000: - 0.7981s/step - loss: 692.0241 - accuracy: 0.7867\n",
      "Epoch 18/1000: - 0.8030s/step - loss: 691.5986 - accuracy: 0.8000\n",
      "Epoch 19/1000: - 0.8062s/step - loss: 691.6382 - accuracy: 0.8267\n",
      "Epoch 20/1000: - 0.8070s/step - loss: 691.6943 - accuracy: 0.8467\n",
      "Epoch 21/1000: - 0.8062s/step - loss: 691.4835 - accuracy: 0.8133\n",
      "Epoch 22/1000: - 0.8061s/step - loss: 691.4908 - accuracy: 0.8467\n",
      "Epoch 23/1000: - 0.8084s/step - loss: 691.1970 - accuracy: 0.8467\n",
      "Epoch 24/1000: - 0.8096s/step - loss: 691.2168 - accuracy: 0.8067\n",
      "Epoch 25/1000: - 0.8129s/step - loss: 691.2676 - accuracy: 0.8133\n",
      "Epoch 26/1000: - 0.8119s/step - loss: 691.2156 - accuracy: 0.8200\n",
      "Epoch 27/1000: - 0.8134s/step - loss: 690.9476 - accuracy: 0.8267\n",
      "Epoch 28/1000: - 0.8160s/step - loss: 690.6829 - accuracy: 0.8067\n",
      "Epoch 29/1000: - 0.8178s/step - loss: 691.1835 - accuracy: 0.8200\n",
      "Epoch 30/1000: - 0.8223s/step - loss: 690.8611 - accuracy: 0.8133\n",
      "Epoch 31/1000: - 0.8224s/step - loss: 690.3835 - accuracy: 0.8067\n",
      "Epoch 32/1000: - 0.8223s/step - loss: 690.4431 - accuracy: 0.8133\n",
      "Epoch 33/1000: - 0.8231s/step - loss: 690.1361 - accuracy: 0.8067\n",
      "Epoch 34/1000: - 0.8224s/step - loss: 690.1860 - accuracy: 0.8067\n",
      "Epoch 35/1000: - 0.8225s/step - loss: 690.2667 - accuracy: 0.8200\n",
      "Epoch 36/1000: - 0.8220s/step - loss: 690.2834 - accuracy: 0.8333\n",
      "Epoch 37/1000: - 0.8225s/step - loss: 690.1083 - accuracy: 0.8200\n",
      "Epoch 38/1000: - 0.8242s/step - loss: 690.1080 - accuracy: 0.8400\n",
      "Epoch 39/1000: - 0.8240s/step - loss: 689.9183 - accuracy: 0.8333\n",
      "Epoch 40/1000: - 0.8249s/step - loss: 689.9327 - accuracy: 0.8333\n",
      "Epoch 41/1000: - 0.8253s/step - loss: 690.1327 - accuracy: 0.8467\n",
      "Epoch 42/1000: - 0.8262s/step - loss: 690.0377 - accuracy: 0.8333\n",
      "Epoch 43/1000: - 0.8262s/step - loss: 690.0622 - accuracy: 0.8333\n",
      "Epoch 44/1000: - 0.8259s/step - loss: 689.9397 - accuracy: 0.8400\n",
      "Epoch 45/1000: - 0.8260s/step - loss: 689.8235 - accuracy: 0.8333\n",
      "Epoch 46/1000: - 0.8249s/step - loss: 689.7227 - accuracy: 0.8333\n",
      "Epoch 47/1000: - 0.8238s/step - loss: 689.8165 - accuracy: 0.8467\n",
      "Epoch 48/1000: - 0.8225s/step - loss: 689.5137 - accuracy: 0.8333\n",
      "Epoch 49/1000: - 0.8219s/step - loss: 689.4923 - accuracy: 0.8533\n",
      "Epoch 50/1000: - 0.8206s/step - loss: 689.4954 - accuracy: 0.8467\n",
      "Epoch 51/1000: - 0.8191s/step - loss: 689.3191 - accuracy: 0.8533\n",
      "Epoch 52/1000: - 0.8187s/step - loss: 689.0474 - accuracy: 0.8467\n",
      "Epoch 53/1000: - 0.8179s/step - loss: 689.2438 - accuracy: 0.8333\n",
      "Epoch 54/1000: - 0.8170s/step - loss: 689.1619 - accuracy: 0.8533\n",
      "Epoch 55/1000: - 0.8156s/step - loss: 688.9977 - accuracy: 0.8467\n",
      "Epoch 56/1000: - 0.8152s/step - loss: 689.1751 - accuracy: 0.8467\n",
      "Epoch 57/1000: - 0.8143s/step - loss: 688.7817 - accuracy: 0.8400\n",
      "Epoch 58/1000: - 0.8134s/step - loss: 688.9789 - accuracy: 0.8400\n",
      "Epoch 59/1000: - 0.8127s/step - loss: 688.9824 - accuracy: 0.8400\n",
      "Epoch 60/1000: - 0.8120s/step - loss: 688.9825 - accuracy: 0.8467\n",
      "Epoch 61/1000: - 0.8113s/step - loss: 688.7589 - accuracy: 0.8467\n",
      "Epoch 62/1000: - 0.8106s/step - loss: 689.0692 - accuracy: 0.8467\n",
      "Epoch 63/1000: - 0.8103s/step - loss: 689.2543 - accuracy: 0.8533\n",
      "Epoch 64/1000: - 0.8096s/step - loss: 688.9421 - accuracy: 0.8400\n",
      "Epoch 65/1000: - 0.8090s/step - loss: 689.0111 - accuracy: 0.8533\n",
      "Epoch 66/1000: - 0.8081s/step - loss: 688.8403 - accuracy: 0.8533\n",
      "Epoch 67/1000: - 0.8077s/step - loss: 688.7441 - accuracy: 0.8533\n",
      "Epoch 68/1000: - 0.8070s/step - loss: 688.7146 - accuracy: 0.8467\n",
      "Epoch 69/1000: - 0.8063s/step - loss: 688.4646 - accuracy: 0.8533\n",
      "Epoch 70/1000: - 0.8058s/step - loss: 688.0953 - accuracy: 0.8533\n",
      "Epoch 71/1000: - 0.8056s/step - loss: 688.1273 - accuracy: 0.8467\n",
      "Epoch 72/1000: - 0.8054s/step - loss: 688.3380 - accuracy: 0.8467\n",
      "Epoch 73/1000: - 0.8046s/step - loss: 688.4640 - accuracy: 0.8400\n",
      "Epoch 74/1000: - 0.8039s/step - loss: 688.3157 - accuracy: 0.8467\n",
      "Epoch 75/1000: - 0.8035s/step - loss: 688.4054 - accuracy: 0.8533\n",
      "Epoch 76/1000: - 0.8030s/step - loss: 688.1866 - accuracy: 0.8333\n",
      "Epoch 77/1000: - 0.8026s/step - loss: 688.2070 - accuracy: 0.8533\n",
      "Epoch 78/1000: - 0.8024s/step - loss: 688.2208 - accuracy: 0.8533\n",
      "Epoch 79/1000: - 0.8022s/step - loss: 688.1802 - accuracy: 0.8533\n",
      "Epoch 80/1000: - 0.8017s/step - loss: 688.0597 - accuracy: 0.8533\n",
      "Epoch 81/1000: - 0.8014s/step - loss: 687.9955 - accuracy: 0.8600\n",
      "Epoch 82/1000: - 0.8017s/step - loss: 688.0171 - accuracy: 0.8600\n",
      "Epoch 83/1000: - 0.8012s/step - loss: 687.9691 - accuracy: 0.8667\n",
      "Epoch 84/1000: - 0.8014s/step - loss: 688.0154 - accuracy: 0.8600\n",
      "Epoch 85/1000: - 0.8014s/step - loss: 687.9049 - accuracy: 0.8600\n",
      "Epoch 86/1000: - 0.8009s/step - loss: 687.7145 - accuracy: 0.8600\n",
      "Epoch 87/1000: - 0.8004s/step - loss: 688.0225 - accuracy: 0.8600\n",
      "Epoch 88/1000: - 0.8001s/step - loss: 687.9515 - accuracy: 0.8667\n",
      "Epoch 89/1000: - 0.7997s/step - loss: 687.8715 - accuracy: 0.8667\n",
      "Epoch 90/1000: - 0.7991s/step - loss: 687.4214 - accuracy: 0.8600\n",
      "Epoch 91/1000: - 0.7989s/step - loss: 687.5980 - accuracy: 0.8600\n",
      "Epoch 92/1000: - 0.7989s/step - loss: 687.6323 - accuracy: 0.8600\n",
      "Epoch 93/1000: - 0.7986s/step - loss: 687.8441 - accuracy: 0.8600\n",
      "Epoch 94/1000: - 0.7981s/step - loss: 688.0568 - accuracy: 0.8600\n",
      "Epoch 95/1000: - 0.7977s/step - loss: 688.0263 - accuracy: 0.8600\n",
      "Epoch 96/1000: - 0.7974s/step - loss: 687.7626 - accuracy: 0.8667\n",
      "Epoch 97/1000: - 0.7970s/step - loss: 688.0471 - accuracy: 0.8667\n",
      "Epoch 98/1000: - 0.7966s/step - loss: 688.2386 - accuracy: 0.8667\n",
      "Epoch 99/1000: - 0.7964s/step - loss: 688.2162 - accuracy: 0.8600\n",
      "Epoch 100/1000: - 0.7962s/step - loss: 687.9764 - accuracy: 0.8667\n",
      "Epoch 101/1000: - 0.7960s/step - loss: 687.9288 - accuracy: 0.8667\n",
      "Epoch 102/1000: - 0.7956s/step - loss: 688.0013 - accuracy: 0.8600\n",
      "Epoch 103/1000: - 0.7953s/step - loss: 688.2386 - accuracy: 0.8667\n",
      "Epoch 104/1000: - 0.7949s/step - loss: 688.3372 - accuracy: 0.8667\n",
      "Epoch 105/1000: - 0.7945s/step - loss: 688.0916 - accuracy: 0.8667\n",
      "Epoch 106/1000: - 0.7942s/step - loss: 688.0126 - accuracy: 0.8667\n",
      "Epoch 107/1000: - 0.7940s/step - loss: 687.8323 - accuracy: 0.8667\n",
      "Epoch 108/1000: - 0.7937s/step - loss: 687.4960 - accuracy: 0.8733\n",
      "Epoch 109/1000: - 0.7954s/step - loss: 687.9445 - accuracy: 0.8733\n",
      "Epoch 110/1000: - 0.7980s/step - loss: 687.8657 - accuracy: 0.8667\n",
      "Epoch 111/1000: - 0.7988s/step - loss: 687.6957 - accuracy: 0.8667\n",
      "Epoch 112/1000: - 0.7998s/step - loss: 687.6971 - accuracy: 0.8667\n",
      "Epoch 113/1000: - 0.8008s/step - loss: 687.5173 - accuracy: 0.8733\n",
      "Epoch 114/1000: - 0.8006s/step - loss: 687.5718 - accuracy: 0.8733\n",
      "Epoch 115/1000: - 0.8004s/step - loss: 687.6451 - accuracy: 0.8667\n",
      "Epoch 116/1000: - 0.8009s/step - loss: 687.8481 - accuracy: 0.8667\n",
      "Epoch 117/1000: - 0.8016s/step - loss: 687.4789 - accuracy: 0.8667\n",
      "Epoch 118/1000: - 0.8019s/step - loss: 687.4276 - accuracy: 0.8667\n",
      "Epoch 119/1000: - 0.8022s/step - loss: 687.3494 - accuracy: 0.8733\n",
      "Epoch 120/1000: - 0.8026s/step - loss: 687.4707 - accuracy: 0.8667\n",
      "Epoch 121/1000: - 0.8023s/step - loss: 687.1816 - accuracy: 0.8667\n",
      "Epoch 122/1000: - 0.8028s/step - loss: 687.1517 - accuracy: 0.8733\n",
      "Epoch 123/1000: - 0.8043s/step - loss: 687.2066 - accuracy: 0.8733\n",
      "Epoch 124/1000: - 0.8053s/step - loss: 686.9370 - accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/1000: - 0.8050s/step - loss: 686.9438 - accuracy: 0.8667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0763f7aba359>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n\u001b[0;32m---> 13\u001b[0;31m                    for (x, y), net, ker in zip(train_ds, network, kernels)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0763f7aba359>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n\u001b[0;32m---> 13\u001b[0;31m                    for (x, y), net, ker in zip(train_ds, network, kernels)]\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-08cc8226ace7>\u001b[0m in \u001b[0;36mpropose_new_state_hamiltonian\u001b[0;34m(self, x, h, y, hmc_kernel, is_update_kernel)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmc_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mtrace_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             return_final_kernel_results = True)\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m# Generate new states of chains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                             trace_fn(*state_and_results)),\n\u001b[1;32m    358\u001b[0m         \u001b[0;31m# pylint: enable=g-long-lambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_final_kernel_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[0;34m(loop_fn, initial_state, elems, trace_fn, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mstacked_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_body\u001b[0;34m(i, state, trace_arrays)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melems_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       trace_arrays = tf.nest.pack_sequence_as(trace_arrays, [\n\u001b[1;32m    385\u001b[0m           a.write(i, v) for a, v in zip(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36m_trace_scan_fn\u001b[0;34m(state_and_results, num_steps)\u001b[0m\n\u001b[1;32m    341\u001b[0m           \u001b[0mbody_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m           \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_and_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m           parallel_iterations=parallel_iterations)\n\u001b[0m\u001b[1;32m    344\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36msmart_for_loop\u001b[0;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    314\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m       )[1:]\n\u001b[1;32m    318\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    312\u001b[0m       return tf.while_loop(\n\u001b[1;32m    313\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;31m# Step the inner kernel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       new_state, new_inner_results = self.inner_kernel.one_step(\n\u001b[0;32m--> 343\u001b[0;31m           current_state, inner_results)\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m       \u001b[0;31m# Get the new step size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_step_size_assign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m       next_state, kernel_results = self._impl.one_step(\n\u001b[0;32m--> 547\u001b[0;31m           current_state, previous_kernel_results)\n\u001b[0m\u001b[1;32m    548\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         step_size_assign = self.step_size_update_fn(  # pylint: disable=not-callable\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m           \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m           previous_kernel_results.accepted_results)\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m       if (not has_target_log_prob(proposed_results) or\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results)\u001b[0m\n\u001b[1;32m    734\u001b[0m                      \u001b[0mcurrent_state_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m                      \u001b[0mcurrent_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m                      current_target_log_prob_grad_parts)\n\u001b[0m\u001b[1;32m    737\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_gradients_are_stopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mnext_state_parts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_state_parts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, momentum_parts, state_parts, target, target_grad_parts, name)\u001b[0m\n\u001b[1;32m    289\u001b[0m               \u001b[0mstate_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m               \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m               \u001b[0mtarget_grad_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m           ])\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 574\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2489\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m       return_same_structure=True)\n\u001b[0m\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2726\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    283\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n\u001b[0;32m--> 285\u001b[0;31m               self.target_fn, self.step_sizes, *args)),\n\u001b[0m\u001b[1;32m    286\u001b[0m           loop_vars=[\n\u001b[1;32m    287\u001b[0m               \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m_one_step\u001b[0;34m(target_fn, step_sizes, half_next_momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     [next_target, next_target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n\u001b[0;32m--> 326\u001b[0;31m         target_fn, next_state_parts)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_target_grad_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[1;32m    263\u001b[0m                    else [fn_arg_list])\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     if not all(dtype_util.is_floating(r.dtype)\n\u001b[1;32m    266\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    247\u001b[0m       ]\n\u001b[1;32m    248\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfp_math_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_probability/python/math/gradient.py\u001b[0m in \u001b[0;36mvalue_and_gradient\u001b[0;34m(f, xs, output_gradients, use_gradient_tape, name)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0mdydx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-08cc8226ace7>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mtarget_log_prob_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mnum_leapfrog_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             step_size = step_size),\n",
      "\u001b[0;32m<ipython-input-8-08cc8226ace7>\u001b[0m in \u001b[0;36mtarget_log_prob2\u001b[0;34m(self, x, h, y)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         fce = tf.nn.sigmoid_cross_entropy_with_logits(\n\u001b[0;32m---> 70\u001b[0;31m             labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mnlog_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits_v2\u001b[0;34m(labels, logits, name)\u001b[0m\n\u001b[1;32m    239\u001b[0m   \"\"\"\n\u001b[1;32m    240\u001b[0m   return sigmoid_cross_entropy_with_logits(\n\u001b[0;32m--> 241\u001b[0;31m       logits=logits, labels=labels, name=name)\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py\u001b[0m in \u001b[0;36msigmoid_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mneg_abs_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     return math_ops.add(\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mrelu_logits\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_abs_logits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         name=name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for bs, (x, y) in enumerate(train_ds):\n",
    "        \n",
    "        # only one mini-batch\n",
    "        model.update_weights(x, network[bs], y, 0.1)\n",
    "        res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n",
    "                   for (x, y), net, ker in zip(train_ds, network, kernels)]\n",
    "        network = res\n",
    "        loss += -1 * tf.reduce_mean(model.target_log_prob(x, network[bs], y))\n",
    "    \n",
    "    preds = [model.get_predictions(images) for images, labels in train_ds]\n",
    "    train_acc = accuracy_score(np.concatenate(preds), y_train)\n",
    "    print(\"Epoch %d/%d: - %.4fs/step - loss: %.4f - accuracy: %.4f\" \n",
    "          % (epoch + 1, epochs, (time.time() - start_time) / (epoch + 1), loss, train_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
