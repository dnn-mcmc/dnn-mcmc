{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.math as tm\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12665 training images.\n",
      "There are 2115 test images.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Select binary data\n",
    "label_sub = [0,1]\n",
    "x_train_sub = [x.reshape(-1) for x, y in zip(x_train, y_train) if y in label_sub]\n",
    "y_train_sub = [y.reshape(-1) for y in y_train if y in label_sub]\n",
    "x_test_sub = [x.reshape(-1) for x, y in zip(x_test, y_test) if y in label_sub]\n",
    "y_test_sub = [y.reshape(-1) for y in y_test if y in label_sub]\n",
    "\n",
    "\n",
    "print('There are', len(x_train_sub), 'training images.')\n",
    "print('There are', len(x_test_sub), 'test images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 training images.\n"
     ]
    }
   ],
   "source": [
    "x_train_sub = x_train_sub[:100]\n",
    "y_train_sub = y_train_sub[:100]\n",
    "\n",
    "print('There are', len(x_train_sub), 'training images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sub[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train_sub, y_train_sub)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test_sub, y_test_sub)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard BP\n",
    "model_bp = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(784,)),\n",
    "        layers.Dense(32, activation = \"sigmoid\"),\n",
    "        layers.Dense(1, activation = \"sigmoid\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 200\n",
    "opt = tf.keras.optimizers.SGD(learning_rate=.1)\n",
    "st = time.time()\n",
    "model_bp.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\", \"AUC\"])\n",
    "history = model_bp.fit(train_ds, batch_size=batch_size, epochs=epochs)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2_zero_one(x):\n",
    "    \n",
    "    t = [tf.math.sigmoid(i) for i in x]    \n",
    "    return t\n",
    "\n",
    "def cont_bern_log_norm(lam, l_lim=0.49, u_lim=0.51):\n",
    "    '''\n",
    "    computes the log normalizing constant of a continuous Bernoulli distribution in a numerically stable way.\n",
    "    returns the log normalizing constant for lam in (0, l_lim) U (u_lim, 1) and a Taylor approximation in\n",
    "    [l_lim, u_lim].\n",
    "    cut_y below might appear useless, but it is important to not evaluate log_norm near 0.5 as tf.where evaluates\n",
    "    both options, regardless of the value of the condition.\n",
    "    '''\n",
    "    \n",
    "    cut_lam = tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), lam, l_lim * tf.ones_like(lam))\n",
    "    log_norm = tm.log(tm.abs(2.0 * tm.atanh(1 - 2.0 * cut_lam))) - tm.log(tm.abs(1 - 2.0 * cut_lam))\n",
    "    taylor = tm.log(2.0) + 4.0 / 3.0 * tm.pow(lam - 0.5, 2) + 104.0 / 45.0 * tm.pow(lam - 0.5, 4)\n",
    "    return tf.where(tm.logical_or(tm.less(lam, l_lim), tm.greater(lam, u_lim)), log_norm, taylor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        #x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)\n",
    "\n",
    "        final_logits = self.output_layer(x) # initial the weight of output layer\n",
    "            \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        h_current = convert2_zero_one([tf.cast(h_i, dtype=tf.float32) for h_i in h])\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "    \n",
    "        nlog_prob = 0. # negative log probability\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            logits = layer(pv)\n",
    "            print(cont_bern_log_norm(tf.nn.sigmoid(logits)))\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=logits)\n",
    "            \n",
    "            ce += cont_bern_log_norm(tf.nn.sigmoid(logits))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "\n",
    "    def target_log_prob2(self, x, h, y):\n",
    "\n",
    "        h_current = convert2_zero_one(tf.split(h, self.hidden_layer_sizes, axis = 1))\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            logits = layer(pv)\n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                labels=cv, logits=logits)\n",
    "            \n",
    "            ce += cont_bern_log_norm(tf.nn.sigmoid(logits))\n",
    "            \n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "        \n",
    "        fce = tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.float32), logits=self.output_layer(h_current[-1]))\n",
    "        nlog_prob += tf.reduce_sum(fce, axis = -1)\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def generate_hmc_kernel(self, x, y, step_size = pow(1000, -1/4)):\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = step_size),\n",
    "            num_adaptation_steps=int(100 * 0.8))\n",
    "        \n",
    "        return adaptive_hmc\n",
    "    \n",
    "    # new proposing-state method with HamiltonianMonteCarlo\n",
    "    def propose_new_state_hamiltonian(self, x, h, y, hmc_kernel, is_update_kernel = True):\n",
    "    \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concat(h_current, axis = 1)\n",
    "\n",
    "        # run the chain (with burn-in)\n",
    "        num_burnin_steps = 0\n",
    "        num_results = 1\n",
    "\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "            num_results = num_results,\n",
    "            num_burnin_steps = num_burnin_steps,\n",
    "            current_state = h_current, # may need to be reshaped\n",
    "            kernel = hmc_kernel,\n",
    "            trace_fn = None,\n",
    "            return_final_kernel_results = True)\n",
    "    \n",
    "        # Generate new states of chains\n",
    "        #h_state = rerange(samples[0][0])\n",
    "        h_state = samples[0][0]\n",
    "        h_new = tf.split(h_state, self.hidden_layer_sizes, axis = 1) \n",
    "        \n",
    "        # Update the kernel if necesssary\n",
    "        if is_update_kernel:\n",
    "            new_step_size = samples[2].new_step_size.numpy()\n",
    "            ker_new = self.generate_hmc_kernel(x, y, new_step_size)\n",
    "            return(h_new, ker_new)\n",
    "        else:\n",
    "            return h_new\n",
    "    \n",
    "    def update_weights(self, x, h, y, lr = 0.1):\n",
    "        \n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate = lr)\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = -1 * tf.reduce_mean(self.target_log_prob(x, h, y))\n",
    "        \n",
    "        grads = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "    def get_predictions(self, x):\n",
    "\n",
    "        logits = 0.0\n",
    "        for layer in self.fc_layers:\n",
    "            logits = layer(x)\n",
    "            x = tm.sigmoid(logits)\n",
    "        \n",
    "        logits = self.output_layer(x)\n",
    "        probs = tm.sigmoid(logits)\n",
    "        #print(probs)\n",
    "        labels = tf.cast(tm.greater(probs, 0.5), tf.int32)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [32], n_outputs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [model.generate_hmc_kernel(images, labels) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bs, (x, y) in enumerate(train_ds):\n",
    "    if bs == 0:\n",
    "        xx = x\n",
    "        yy = y\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[      inf       inf       inf ...       inf       inf       inf]\n",
      " [      inf 1.2329103       inf ...       inf       inf       inf]\n",
      " [      inf       inf       inf ...       inf       inf       inf]\n",
      " ...\n",
      " [      inf       inf       inf ...       inf       inf       inf]\n",
      " [      inf       inf 1.9193465 ...       inf       inf       inf]\n",
      " [      inf       inf       inf ...       inf       inf       inf]], shape=(32, 32), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
       "array([-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "       -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n",
       "       -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.target_log_prob(xx, network[0], yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "Step 10\n",
      "Step 20\n",
      "Step 30\n",
      "Step 40\n"
     ]
    }
   ],
   "source": [
    "# Burn-in\n",
    "burnin = 50\n",
    "\n",
    "for i in range(burnin):\n",
    "\n",
    "    if(i % 10 == 0): print(\"Step %d\" % i)\n",
    "    network_new = []\n",
    "    kernels_new = []\n",
    "    \n",
    "    res = [model.propose_new_state_hamiltonian(x, net, y, ker) \n",
    "           for (x, y), net, ker in zip(train_ds, network, kernels)]\n",
    "    \n",
    "    network_new, kernels_new = zip(*res)\n",
    "    network = network_new\n",
    "    kernels = kernels_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor([nan nan nan nan], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for bs, (x, y) in enumerate(train_ds):\n",
    "    print(model.target_log_prob(x, network[bs], y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot values of nodes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#units = list(np.random.randint(100, size = 10))\n",
    "\n",
    "for j in range(200):\n",
    "\n",
    "    print(j)\n",
    "    k = j % 10\n",
    "    if(k == 0):\n",
    "        fig, ax = plt.subplots(nrows=5, ncols=2, figsize=(14, 20))\n",
    "    \n",
    "    ax[k // 2, k % 2].plot(np.arange(20000), [net_values[i][j] for i in range(20000)])\n",
    "    ax[k // 2, k % 2].set_title('Unit %i' % j)\n",
    "    ax[k // 2, k % 2].set_ylim([-6, 6])\n",
    "\n",
    "    if(k == 9):\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('plots/100_50_50/merge_20k_%d' % (j//10))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor([nan nan nan nan], shape=(4,), dtype=float32)\n",
      "Epoch 1/200: - 0.4906s/step - loss: nan - accuracy: 0.4300\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor([nan nan nan nan], shape=(4,), dtype=float32)\n",
      "Epoch 2/200: - 0.4632s/step - loss: nan - accuracy: 0.4300\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor([nan nan nan nan], shape=(4,), dtype=float32)\n",
      "Epoch 3/200: - 0.4581s/step - loss: nan - accuracy: 0.4300\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor([nan nan nan nan], shape=(4,), dtype=float32)\n",
      "Epoch 4/200: - 0.4623s/step - loss: nan - accuracy: 0.4300\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor([nan nan nan nan], shape=(4,), dtype=float32)\n",
      "Epoch 5/200: - 0.4653s/step - loss: nan - accuracy: 0.4300\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan], shape=(32,), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8y/v1j9n38n4ln56z5jhwrpnnyc0000gn/T/ipykernel_4260/2916482635.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# only one mini-batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n\u001b[0m\u001b[1;32m     16\u001b[0m                    for (x, y), net, ker in zip(train_ds, network, kernels)]\n\u001b[1;32m     17\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8y/v1j9n38n4ln56z5jhwrpnnyc0000gn/T/ipykernel_4260/2916482635.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# only one mini-batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n\u001b[0m\u001b[1;32m     16\u001b[0m                    for (x, y), net, ker in zip(train_ds, network, kernels)]\n\u001b[1;32m     17\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8y/v1j9n38n4ln56z5jhwrpnnyc0000gn/T/ipykernel_4260/1191922289.py\u001b[0m in \u001b[0;36mpropose_new_state_hamiltonian\u001b[0;34m(self, x, h, y, hmc_kernel, is_update_kernel)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mnum_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         samples = tfp.mcmc.sample_chain(\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0mnum_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mnum_burnin_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_burnin_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36msample_chain\u001b[0;34m(num_results, current_state, previous_kernel_results, kernel, num_burnin_steps, num_steps_between_results, trace_fn, return_final_kernel_results, parallel_iterations, seed, name)\u001b[0m\n\u001b[1;32m    360\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_kernel_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     (_, _, final_kernel_results), (all_states, trace) = mcmc_util.trace_scan(\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mloop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_trace_scan_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_kernel_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mtrace_scan\u001b[0;34m(loop_fn, initial_state, elems, trace_fn, trace_criterion_fn, static_trace_allocation_size, condition_fn, parallel_iterations, name)\u001b[0m\n\u001b[1;32m    451\u001b[0m       \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mcondition_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m     _, final_state, _, trace_arrays = tf.while_loop(\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 602\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m   \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2532\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_body\u001b[0;34m(i, state, num_steps_traced, trace_arrays)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps_traced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m       \u001b[0melem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melems_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m       trace_arrays, num_steps_traced = ps.cond(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36m_trace_scan_fn\u001b[0;34m(seed_state_and_results, num_steps)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_trace_scan_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_state_and_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m       seed, next_state, current_kernel_results = mcmc_util.smart_for_loop(\n\u001b[0m\u001b[1;32m    356\u001b[0m           \u001b[0mloop_num_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m           \u001b[0mbody_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_seeded_one_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36msmart_for_loop\u001b[0;34m(loop_num_iter, body_fn, initial_loop_vars, parallel_iterations, unroll_threshold, name)\u001b[0m\n\u001b[1;32m    322\u001b[0m       \u001b[0;31m# where while/LoopCond needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m       \u001b[0mloop_num_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_num_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m       return tf.while_loop(\n\u001b[0m\u001b[1;32m    325\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 602\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m   \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2532\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    324\u001b[0m       return tf.while_loop(\n\u001b[1;32m    325\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mloop_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minitial_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/sample.py\u001b[0m in \u001b[0;36m_seeded_one_step\u001b[0;34m(seed, *state_and_results)\u001b[0m\n\u001b[1;32m    350\u001b[0m       \u001b[0mone_step_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_seed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_seeded\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       return [passalong_seed] + list(\n\u001b[0;32m--> 352\u001b[0;31m           kernel.one_step(*state_and_results, **one_step_kwargs))\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_trace_scan_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_state_and_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/simple_step_size_adaptation.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[1;32m    345\u001b[0m       \u001b[0;31m# Step the inner kernel.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m       \u001b[0minner_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m       new_state, new_inner_results = self.inner_kernel.one_step(\n\u001b[0m\u001b[1;32m    348\u001b[0m           current_state, inner_results, **inner_kwargs)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprevious_step_size_assign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m       next_state, kernel_results = self._impl.one_step(\n\u001b[0m\u001b[1;32m    554\u001b[0m           current_state, previous_kernel_results, seed=seed)\n\u001b[1;32m    555\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_update_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[1;32m    193\u001b[0m           \u001b[0mproposed_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m           \u001b[0mproposed_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m           \u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m           \u001b[0mprevious_kernel_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccepted_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/hmc.py\u001b[0m in \u001b[0;36mone_step\u001b[0;34m(self, current_state, previous_kernel_results, seed)\u001b[0m\n\u001b[1;32m    741\u001b[0m           \u001b[0mnext_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m           \u001b[0mnext_target_log_prob_grad_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegrator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_momentum_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                      \u001b[0mcurrent_state_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                      \u001b[0mcurrent_target_log_prob\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, momentum_parts, state_parts, target, target_grad_parts, kinetic_energy_fn, name)\u001b[0m\n\u001b[1;32m    295\u001b[0m           \u001b[0mnext_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m           \u001b[0mnext_target_grad_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m                   \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'in a future version'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                   if date is None else ('after %s' % date), instructions)\n\u001b[0;32m--> 602\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     doc = _add_deprecated_arg_value_notice_to_docstring(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m   \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m   return while_loop(\n\u001b[0m\u001b[1;32m   2532\u001b[0m       \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m       \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2775\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2776\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, *args)\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhile_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m           \u001b[0mcond\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m           body=lambda i, *args: [i + 1] + list(_one_step(  # pylint: disable=no-value-for-parameter,g-long-lambda\n\u001b[0m\u001b[1;32m    300\u001b[0m               self.target_fn, self.step_sizes, get_velocity_parts, *args)),\n\u001b[1;32m    301\u001b[0m           loop_vars=[\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/leapfrog_integrator.py\u001b[0m in \u001b[0;36m_one_step\u001b[0;34m(target_fn, step_sizes, get_velocity_parts, half_next_momentum_parts, state_parts, target, target_grad_parts)\u001b[0m\n\u001b[1;32m    340\u001b[0m       next_state_parts.append(\n\u001b[1;32m    341\u001b[0m           state_part + _multiply(eps, velocity_part, dtype=state_part.dtype))\n\u001b[0;32m--> 342\u001b[0;31m     [next_target, next_target_grad_parts] = mcmc_util.maybe_call_fn_and_grads(\n\u001b[0m\u001b[1;32m    343\u001b[0m         target_fn, next_state_parts)\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnext_target_grad_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36mmaybe_call_fn_and_grads\u001b[0;34m(fn, fn_arg_list, result, grads, check_non_none_grads, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     fn_arg_list = (list(fn_arg_list) if is_list_like(fn_arg_list)\n\u001b[1;32m    266\u001b[0m                    else [fn_arg_list])\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_value_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn_arg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     if not all(dtype_util.is_floating(r.dtype)\n\u001b[1;32m    269\u001b[0m                for r in (result if is_list_like(result) else [result])):  # pylint: disable=superfluous-parens\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow_probability/python/mcmc/internal/util.py\u001b[0m in \u001b[0;36m_value_and_gradients\u001b[0;34m(fn, fn_arg_list, result, grads, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfn_arg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Ensure we disable bijector cacheing in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8y/v1j9n38n4ln56z5jhwrpnnyc0000gn/T/ipykernel_4260/1191922289.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mtarget_log_prob_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_log_prob2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mnum_leapfrog_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             step_size = step_size),\n",
      "\u001b[0;32m/var/folders/8y/v1j9n38n4ln56z5jhwrpnnyc0000gn/T/ipykernel_4260/1191922289.py\u001b[0m in \u001b[0;36mtarget_log_prob2\u001b[0;34m(self, x, h, y)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 labels=cv, logits=logits)\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mce\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcont_bern_log_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mnlog_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/8y/v1j9n38n4ln56z5jhwrpnnyc0000gn/T/ipykernel_4260/3534860227.py\u001b[0m in \u001b[0;36mcont_bern_log_norm\u001b[0;34m(lam, l_lim, u_lim)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlog_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcut_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcut_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtaylor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m4.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m104.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m45.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mless\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_lim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_lim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaylor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mwhere_v2\u001b[0;34m(condition, x, y, name)\u001b[0m\n\u001b[1;32m   4688\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4689\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4690\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4691\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4692\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must both be non-None or both be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mselect_v2\u001b[0;34m(condition, t, e, name)\u001b[0m\n\u001b[1;32m   8900\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8901\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8902\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   8903\u001b[0m         _ctx, \"SelectV2\", name, condition, t, e)\n\u001b[1;32m   8904\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 200\n",
    "loss_ls = []\n",
    "acc_ls = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for bs, (x, y) in enumerate(train_ds):\n",
    "        \n",
    "        # only one mini-batch\n",
    "        model.update_weights(x, network[bs], y, 0.1)\n",
    "        res = [model.propose_new_state_hamiltonian(x, net, y, ker, is_update_kernel = False) \\\n",
    "                   for (x, y), net, ker in zip(train_ds, network, kernels)]\n",
    "        network = res\n",
    "        loss += -1 * tf.reduce_sum(model.target_log_prob(x, network[bs], y))\n",
    "    \n",
    "    preds = [model.get_predictions(images) for images, labels in train_ds]\n",
    "    train_acc = accuracy_score(np.concatenate(preds), y_train_sub)\n",
    "    loss_ls.append(loss / len(x_train_sub))\n",
    "    acc_ls.append(train_acc)\n",
    "    \n",
    "    print(\"Epoch %d/%d: - %.4fs/step - loss: %.4f - accuracy: %.4f\" \n",
    "          % (epoch + 1, epochs, (time.time() - start_time) / (epoch + 1), loss / len(x_train_sub), train_acc))\n",
    "\n",
    "print(\"Time of HMC: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
