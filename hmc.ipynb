{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 training images.\n",
      "There are 10000 test images.\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST\n",
    "(x_dev, y_dev), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print('There are', len(x_dev), 'training images.')\n",
    "print('There are', len(x_test), 'test images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((x_dev, y_dev)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "class StochasticMLP(Model):\n",
    "    \n",
    "    def __init__(self, hidden_layer_sizes=[100], n_outputs=10):\n",
    "        super(StochasticMLP, self).__init__()\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.fc_layers = [Dense(layer_size) for layer_size in hidden_layer_sizes]\n",
    "        self.output_layer = Dense(n_outputs)\n",
    "\n",
    "    \n",
    "    def call(self, x):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        network = []\n",
    "        \n",
    "        for i, layer in enumerate(self.fc_layers):\n",
    "            \n",
    "            logits = layer(x)\n",
    "            x = tfp.distributions.Bernoulli(logits=logits).sample()\n",
    "            network.append(x)     \n",
    "            \n",
    "        final_logits = self.output_layer(x)\n",
    "        \n",
    "        return network\n",
    "    \n",
    "    def target_log_prob(self, x, h, y):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        print(h_current)\n",
    "        #print(np.asarray(h_current).shape)\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits( # only works for discretize version\n",
    "                labels=cv, logits=layer(pv))\n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "            \n",
    "        nlog_prob += tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.int32), logits=self.output_layer(h_current[-1]))\n",
    "            \n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def target_log_prob2(self, x, h, y):\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        #print(h)\n",
    "        h_current = tf.split(h, self.hidden_layer_sizes, axis = 1)\n",
    "        #print(h_current)\n",
    "        h_previous = [x] + h_current[:-1]\n",
    "        \n",
    "        nlog_prob = 0.\n",
    "        \n",
    "        for i, (cv, pv, layer) in enumerate(\n",
    "            zip(h_current, h_previous, self.fc_layers)):\n",
    "            \n",
    "            ce = tf.nn.sigmoid_cross_entropy_with_logits( # only works for discretize version\n",
    "                labels=cv, logits=layer(pv))\n",
    "            nlog_prob += tf.reduce_sum(ce, axis = -1)\n",
    "            \n",
    "        nlog_prob += tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=tf.cast(y, tf.int32), logits=self.output_layer(h_current[-1]))\n",
    "\n",
    "        #print(log_prob)\n",
    "        return -1 * nlog_prob\n",
    "    \n",
    "    def run_chain(self, x, h, y):\n",
    "        \n",
    "        #print(h)\n",
    "        \n",
    "        h_current = h\n",
    "        h_current = [tf.cast(h_i, dtype=tf.float32) for h_i in h_current]\n",
    "        h_current = tf.concat([h_current[0], h_current[1]], axis=1)\n",
    "        #print(h_current)\n",
    "        \n",
    "        #def tlp(args):\n",
    "        #    return self.target_log_prob2(x, args, y)\n",
    "        \n",
    "        adaptive_hmc = tfp.mcmc.SimpleStepSizeAdaptation(tfp.mcmc.HamiltonianMonteCarlo(\n",
    "            target_log_prob_fn = lambda v: self.target_log_prob2(x, v, y),\n",
    "            num_leapfrog_steps = 2,\n",
    "            step_size = 0.1), #pow(1000, -1/4)),\n",
    "            num_adaptation_steps = int(100 * 0.8))\n",
    "        \n",
    "        #print(tf.size(tlp(h_current)))\n",
    "        \n",
    "        # Run the chain (with burn-in).\n",
    "        samples = tfp.mcmc.sample_chain(\n",
    "          num_results=1, # need one step\n",
    "          num_burnin_steps=100, # set to 1000\n",
    "          current_state=h_current,\n",
    "          kernel=adaptive_hmc,\n",
    "          trace_fn = None,\n",
    "          #trace_fn = lambda _, pkr: pkr.inner_results.accepted_results.step_size)\n",
    "          return_final_kernel_results = True)\n",
    "        \n",
    "        print(samples)\n",
    "        # is_accepted = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32))\n",
    "        new_state = tf.math.sign(tf.math.sign(samples[0]) - 1) + 1\n",
    "        h_new = tf.split(new_state, self.hidden_layer_sizes, axis = 1)\n",
    "        \n",
    "        #print(h_new)\n",
    "        #print(is_accepted)\n",
    "        #print(samples)\n",
    "        \n",
    "        return h_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StochasticMLP(hidden_layer_sizes = [100, 50], n_outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [model.call(images) for images, labels in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointableStatesAndTrace(\n",
      "  all_states=<tf.Tensor: shape=(1, 32, 150), dtype=float32, numpy=\n",
      "    array([[[ 2.49343834e+01, -3.70349464e+01,  5.96246605e+01, ...,\n",
      "              1.35633886e-01, -7.43007660e-01,  4.56144857e+00],\n",
      "            [-1.18630180e+01, -1.71547661e+01,  2.02893143e+01, ...,\n",
      "              1.37810886e+00, -8.39252710e-01,  4.92110825e+00],\n",
      "            [ 1.34826088e+00, -1.32906685e+01,  3.29797134e+01, ...,\n",
      "              1.67644775e+00,  1.04760993e+00,  5.42276669e+00],\n",
      "            ...,\n",
      "            [-7.92915225e-01, -1.89870090e+01,  4.76548271e+01, ...,\n",
      "              4.88576055e-01,  2.92850518e+00,  5.71255445e+00],\n",
      "            [ 3.32595520e+01,  3.42668457e+01,  5.35454750e+01, ...,\n",
      "              2.24132204e+00,  6.78587914e+00,  1.99496672e-01],\n",
      "            [ 1.96138611e+01, -5.03597717e+01,  4.40457916e+01, ...,\n",
      "             -2.46609950e+00, -2.59272754e-04, -3.38173479e-01]]],\n",
      "          dtype=float32)>,\n",
      "  trace=(),\n",
      "  final_kernel_results=SimpleStepSizeAdaptationResults(\n",
      "      inner_results=MetropolisHastingsKernelResults(\n",
      "          accepted_results=UncalibratedHamiltonianMonteCarloKernelResults(\n",
      "              log_acceptance_correction=<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "                array([ -7118.814 ,  -3249.3633,  -5294.676 ,  -5579.076 ,  -2030.5651,\n",
      "                        -8527.791 ,  -3948.2893, -10584.297 ,  -4164.7534,  -4701.02  ,\n",
      "                        -4598.6387,  -4104.095 ,  -5326.891 ,  -3236.06  ,  -5015.719 ,\n",
      "                        -6642.434 ,  -6609.116 ,  -3074.1934,  -4960.61  ,  -4803.4575,\n",
      "                        -8396.584 ,  -4618.434 ,  -4430.73  ,  -4517.3125,  -5984.326 ,\n",
      "                        -6525.234 ,  -4911.4443,  -3870.445 ,  -3368.156 ,  -6180.9644,\n",
      "                        -6452.889 ,  -5006.1606], dtype=float32)>,\n",
      "              target_log_prob=<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "                array([365702.7 , 162821.61, 251333.16, 258767.84, 162108.06, 330708.72,\n",
      "                       212814.33, 403361.72, 225118.31, 235029.56, 226571.42, 220007.44,\n",
      "                       260065.86, 186201.3 , 292683.8 , 293635.38, 328871.84, 172031.89,\n",
      "                       293300.5 , 249955.84, 400737.34, 248849.61, 254415.  , 256375.9 ,\n",
      "                       319953.78, 229331.83, 217065.36, 182340.67, 169170.08, 263909.16,\n",
      "                       369954.22, 306537.75], dtype=float32)>,\n",
      "              grads_target_log_prob=[<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "                array([[ 1.10165436e+02, -1.70074097e+02,  2.63444458e+02, ...,\n",
      "                        -1.58038311e+01, -2.13756351e+01,  3.75745659e+01],\n",
      "                       [-4.87637749e+01, -8.53231735e+01,  8.75022507e+01, ...,\n",
      "                        -1.12821591e+00, -1.15449829e+01,  5.60328331e+01],\n",
      "                       [-5.83620071e-02, -6.55050125e+01,  1.57903778e+02, ...,\n",
      "                        -2.88271666e+00,  1.50674191e+01,  4.54303246e+01],\n",
      "                       ...,\n",
      "                       [-6.64101982e+00, -1.08718399e+02,  2.57922913e+02, ...,\n",
      "                        -4.77982378e+00,  2.51768570e+01,  5.52144852e+01],\n",
      "                       [ 1.25544388e+02,  1.24303017e+02,  1.97333496e+02, ...,\n",
      "                         2.27652502e+00,  5.13395462e+01, -9.05222893e+00],\n",
      "                       [ 7.16879501e+01, -1.91289932e+02,  1.61719208e+02, ...,\n",
      "                        -4.60757217e+01, -8.69088078e+00, -2.91856408e+00]], dtype=float32)>],\n",
      "              initial_momentum=[<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "                array([[ 1.9626786e+00,  9.1398701e-02,  3.6468682e-01, ...,\n",
      "                        -9.2869002e-01,  6.5973943e-01,  1.0440713e+00],\n",
      "                       [-1.0048072e+00,  1.5539883e+00,  6.6860604e-01, ...,\n",
      "                         5.5990126e-02, -6.9101030e-01,  5.8530259e-01],\n",
      "                       [ 1.6718568e+00, -3.7706602e-01, -2.7140775e-01, ...,\n",
      "                        -5.6332690e-01, -4.4166982e-01, -4.1250810e-02],\n",
      "                       ...,\n",
      "                       [ 1.2326488e+00,  8.9110386e-01, -6.0800129e-01, ...,\n",
      "                        -5.3931183e-01,  1.5405653e+00, -2.4072065e+00],\n",
      "                       [ 3.8166773e-01, -5.4220605e-01,  1.0711517e+00, ...,\n",
      "                        -5.0619692e-01, -6.3330466e-01, -2.1190605e+00],\n",
      "                       [ 1.8052969e+00, -1.8686894e+00,  1.7282787e-03, ...,\n",
      "                         9.9985945e-01, -5.1457953e-01, -3.3327782e-01]], dtype=float32)>],\n",
      "              final_momentum=[<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "                array([[ 12.103327  , -15.550432  ,  24.602951  , ...,  -2.3635402 ,\n",
      "                         -1.2867136 ,   4.4558587 ],\n",
      "                       [ -5.494138  ,  -6.2881236 ,   8.714007  , ...,  -0.04431267,\n",
      "                         -1.7485905 ,   5.6917267 ],\n",
      "                       [  1.6732687 ,  -6.4045587 ,  14.250302  , ...,  -0.8283457 ,\n",
      "                          0.92687607,   4.089225  ],\n",
      "                       ...,\n",
      "                       [  0.6280496 ,  -9.103366  ,  23.11749   , ...,  -0.9805054 ,\n",
      "                          3.8221292 ,   2.6063905 ],\n",
      "                       [ 11.932772  ,  10.885226  ,  19.233725  , ...,  -0.29643282,\n",
      "                          4.051722  ,  -2.9328802 ],\n",
      "                       [  8.409836  , -19.465359  ,  14.871357  , ...,  -3.1956744 ,\n",
      "                         -1.3081626 ,  -0.60122687]], dtype=float32)>],\n",
      "              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.046018604>,\n",
      "              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
      "              seed=[]\n",
      "            ),\n",
      "          is_accepted=<tf.Tensor: shape=(32,), dtype=bool, numpy=\n",
      "            array([False, False, False, False, False,  True, False,  True,  True,\n",
      "                   False,  True,  True,  True,  True,  True, False, False,  True,\n",
      "                    True, False,  True,  True,  True, False, False, False, False,\n",
      "                    True, False, False, False, False])>,\n",
      "          log_accept_ratio=<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "            array([-0.98291016, -0.78637695, -0.8666992 , -0.7895508 , -0.50341797,\n",
      "                   -1.1347656 , -0.46728516, -1.203125  , -0.72216797, -0.78515625,\n",
      "                   -0.6855469 , -0.75146484, -0.7036133 , -0.6538086 , -0.5629883 ,\n",
      "                   -0.87597656, -0.7607422 , -0.6308594 , -0.7348633 , -0.86083984,\n",
      "                   -0.9902344 , -0.77783203, -0.69873047, -0.6958008 , -0.6225586 ,\n",
      "                   -0.81347656, -0.80810547, -0.60131836, -0.7895508 , -0.7836914 ,\n",
      "                   -1.0537109 , -0.7871094 ], dtype=float32)>,\n",
      "          proposed_state=<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "            array([[ 2.5405708e+01, -3.7858574e+01,  6.0819855e+01, ...,\n",
      "                     1.4582486e-01, -8.7844920e-01,  4.8753586e+00],\n",
      "                   [-1.2071472e+01, -1.7550884e+01,  2.0726711e+01, ...,\n",
      "                     1.5214449e+00, -8.2334113e-01,  5.1001067e+00],\n",
      "                   [ 1.3350939e+00, -1.3569835e+01,  3.3679905e+01, ...,\n",
      "                     1.4834592e+00,  1.1977710e+00,  5.5529618e+00],\n",
      "                   ...,\n",
      "                   [-8.3954835e-01, -1.9490177e+01,  4.8743355e+01, ...,\n",
      "                     4.3629450e-01,  2.9725776e+00,  5.9542580e+00],\n",
      "                   [ 3.3735394e+01,  3.4815567e+01,  5.4520866e+01, ...,\n",
      "                     2.2308433e+00,  6.9907174e+00,  1.7625660e-01],\n",
      "                   [ 1.9919664e+01, -5.1183151e+01,  4.4675423e+01, ...,\n",
      "                    -2.6799414e+00, -1.9050216e-02, -3.0035233e-01]], dtype=float32)>,\n",
      "          proposed_results=UncalibratedHamiltonianMonteCarloKernelResults(\n",
      "              log_acceptance_correction=<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "                array([ -7382.0454,  -3341.3801,  -5226.2104,  -5264.196 ,  -2114.2847,\n",
      "                        -8527.791 ,  -3766.4673, -10584.297 ,  -4164.7534,  -4814.8945,\n",
      "                        -4598.6387,  -4104.095 ,  -5326.891 ,  -3236.06  ,  -5015.719 ,\n",
      "                        -6542.157 ,  -6691.448 ,  -3074.1934,  -4960.61  ,  -4709.7983,\n",
      "                        -8396.584 ,  -4618.434 ,  -4430.73  ,  -4636.3833,  -5836.5913,\n",
      "                        -6544.079 ,  -4903.933 ,  -3870.445 ,  -3330.227 ,  -6116.8774,\n",
      "                        -6364.7725,  -5064.8496], dtype=float32)>,\n",
      "              target_log_prob=<tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "                array([373083.75, 166162.2 , 256558.5 , 264031.25, 164221.84, 330708.72,\n",
      "                       216580.33, 403361.72, 225118.31, 239843.67, 226571.42, 220007.44,\n",
      "                       260065.86, 186201.3 , 292683.8 , 300176.66, 335562.53, 172031.89,\n",
      "                       293300.5 , 254664.78, 400737.34, 248849.61, 254415.  , 261011.6 ,\n",
      "                       325789.75, 235875.1 , 221968.48, 182340.67, 172499.52, 270025.25,\n",
      "                       376317.94, 311601.8 ], dtype=float32)>,\n",
      "              grads_target_log_prob=[<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "                array([[ 1.10124023e+02, -1.70112564e+02,  2.63537323e+02, ...,\n",
      "                        -1.59658203e+01, -2.17568378e+01,  3.84723511e+01],\n",
      "                       [-4.87924423e+01, -8.53920288e+01,  8.74061584e+01, ...,\n",
      "                        -1.18498135e+00, -1.18335896e+01,  5.69810944e+01],\n",
      "                       [-1.56075001e-01, -6.54828720e+01,  1.58094269e+02, ...,\n",
      "                        -2.90718961e+00,  1.54298525e+01,  4.61412926e+01],\n",
      "                       ...,\n",
      "                       [-6.76640129e+00, -1.08942268e+02,  2.58155762e+02, ...,\n",
      "                        -4.81538200e+00,  2.59142380e+01,  5.67450027e+01],\n",
      "                       [ 1.25551178e+02,  1.24395828e+02,  1.97356171e+02, ...,\n",
      "                         2.25089455e+00,  5.21070099e+01, -9.17112255e+00],\n",
      "                       [ 7.16576462e+01, -1.91436172e+02,  1.62009491e+02, ...,\n",
      "                        -4.67824783e+01, -8.74074268e+00, -3.30466986e+00]], dtype=float32)>],\n",
      "              initial_momentum=[<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "                array([[ 0.05175216, -1.1228625 ,  0.862621  , ...,  0.8383582 ,\n",
      "                        -0.48604792,  1.6753795 ],\n",
      "                       [-0.020634  , -0.37751943,  0.72724587, ...,  1.6100532 ,\n",
      "                         0.70617145, -0.6384805 ],\n",
      "                       [-0.14008205, -0.01914821,  0.34012553, ..., -1.9641435 ,\n",
      "                         0.93556696, -0.6789449 ],\n",
      "                       ...,\n",
      "                       [-0.20008999, -0.46221194, -0.0436824 , ..., -0.34814808,\n",
      "                        -0.6850438 ,  0.07493896],\n",
      "                       [-0.6071911 ,  0.24131316,  1.5166508 , ..., -0.2179746 ,\n",
      "                        -0.14101163,  0.16442966],\n",
      "                       [ 0.0236005 , -0.1421302 , -0.6031652 , ..., -0.19934902,\n",
      "                         0.19546796,  0.5492725 ]], dtype=float32)>],\n",
      "              final_momentum=[<tf.Tensor: shape=(32, 150), dtype=float32, numpy=\n",
      "                array([[ 1.01893864e+01, -1.67756882e+01,  2.51115017e+01, ...,\n",
      "                        -6.20632231e-01, -2.46591473e+00,  5.16665268e+00],\n",
      "                       [-4.50980711e+00, -8.23185349e+00,  8.77530098e+00, ...,\n",
      "                         1.50338197e+00, -3.67048234e-01,  4.55000019e+00],\n",
      "                       [-1.48288354e-01, -6.04671812e+00,  1.48796778e+01, ...,\n",
      "                        -2.23012662e+00,  2.33582282e+00,  3.52449417e+00],\n",
      "                       ...,\n",
      "                       [-8.16147923e-01, -1.04769745e+01,  2.37031097e+01, ...,\n",
      "                        -7.88766384e-01,  1.65971792e+00,  5.21256924e+00],\n",
      "                       [ 1.09475346e+01,  1.16847305e+01,  1.96793842e+01, ...,\n",
      "                        -1.03222728e-02,  4.60987663e+00, -6.72180176e-01],\n",
      "                       [ 6.62089920e+00, -1.77535515e+01,  1.42919378e+01, ...,\n",
      "                        -4.46377182e+00, -6.04948819e-01,  2.63709754e-01]], dtype=float32)>],\n",
      "              step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.046018604>,\n",
      "              num_leapfrog_steps=<tf.Tensor: shape=(), dtype=int32, numpy=2>,\n",
      "              seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([-1811337630,  -472131575], dtype=int32)>\n",
      "            ),\n",
      "          extra=[],\n",
      "          seed=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1278346163,  809037042], dtype=int32)>\n",
      "        ),\n",
      "      target_accept_prob=<tf.Tensor: shape=(), dtype=float32, numpy=0.75>,\n",
      "      adaptation_rate=<tf.Tensor: shape=(), dtype=float32, numpy=0.01>,\n",
      "      step=<tf.Tensor: shape=(), dtype=int32, numpy=101>,\n",
      "      new_step_size=<tf.Tensor: shape=(), dtype=float32, numpy=0.046018604>\n",
      "    )\n",
      ")\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Determined shape must either match input shape along split_dim exactly if fully specified, or be less than the size of the input along split_dim if not fully specified.  Got: 150 [Op:SplitV] name: split",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d64ef25d3522>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-d64ef25d3522>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-cd8c6f31df42>\u001b[0m in \u001b[0;36mrun_chain\u001b[0;34m(self, x, h, y)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# is_accepted = tf.reduce_mean(tf.cast(is_accepted, dtype=tf.float32))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mh_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m#print(h_new)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(value, num_or_size_splits, axis, num, name)\u001b[0m\n\u001b[1;32m   2062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m   return gen_array_ops.split_v(\n\u001b[0;32m-> 2064\u001b[0;31m       value=value, size_splits=size_splits, axis=axis, num_split=num, name=name)\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36msplit_v\u001b[0;34m(value, size_splits, axis, num_split, name)\u001b[0m\n\u001b[1;32m  10073\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10074\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10075\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10076\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10077\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6863\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6865\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6866\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Determined shape must either match input shape along split_dim exactly if fully specified, or be less than the size of the input along split_dim if not fully specified.  Got: 150 [Op:SplitV] name: split"
     ]
    }
   ],
   "source": [
    "hmc = [model.run_chain(images, net, labels) for (images, labels), net in zip(train_ds, network)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 1., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.08,2.0,-3.0],[-4,0,-1]])\n",
    "b = tf.math.sign(tf.math.sign(a)-1)+1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1778279410038923"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow(1000, -1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
